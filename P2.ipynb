{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy.stats as st\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_palette(\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the recipe for the perfect movie in **BOLLYWOOD** vs. in **HOLLYWOOD**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMU dataset\n",
    "\n",
    "| Column name          | Description                                                                                                                                                                                       |   |   |   |\n",
    "|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---|---|---|\n",
    "| wikipedia_movie_id | ID of the movie from wikipedia                                                                                                                                                 |   |   |   |\n",
    "| freebase_movie_id| ID of the movie from freebas                                                                                                                                            |   |   |   |\n",
    "| movie_name | Name of the movie                                                                                                                                                |   |   |   |\n",
    "| movie_release_date  | Date the movie was released                                                                                                                                      |   |   |   |\n",
    "| movie_box_office_revenue  | Revenue of the movie box office                                                                                                                           \n",
    "| movie_runtime  | Run time of the movie                                                                                                                                                 |   |   |   |\n",
    "| movie_languages | Languages of the movie                                                                                                                                                  |   |   |   |\n",
    "| movie_countries | Countries where the movie were created                                                                                                                                  |   |   |   |\n",
    "| movie_genres   | Genre of the movie                                                                                                                                              |   |   |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movie data set contains 81741 rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/'\n",
    "\n",
    "names = ['wikipedia_movie_id','freebase_movie_id', 'movie_name', 'movie_release_date', 'movie_box_office_revenue', \n",
    "        'movie_runtime', 'movie_languages', 'movie_countries', 'movie_genres']\n",
    "\n",
    "movies_data = pd.read_csv(data_folder + 'movie.metadata.tsv', names = names, sep = '\\t', )\n",
    "\n",
    "movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']]= movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].applymap(lambda x: str.lower(x))\n",
    "\n",
    "movies_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMdb datasets (ratings, runtimes, isAdult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating files loading\n",
    "ratings = pd.read_csv(data_folder + 'title.ratings.tsv.gz', sep='\\t', compression='gzip')\n",
    "titles = pd.read_csv(data_folder + 'title.basics.tsv.gz', sep='\\t', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMdb and CMU datasets merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging IMdb dataset with title, isAdult and runtimeMinutes with dataset with averageRating on movie ID (tconst)\n",
    "rates = titles.merge(ratings, how='left', on='tconst')[['averageRating', 'numVotes', 'originalTitle', 'isAdult', 'runtimeMinutes']]\n",
    "\n",
    "#putting all titles to lower case to match the CMU dataset movie names and dropping column with upper cases\n",
    "rates['movie_name'] = [ele.lower() for ele in rates['originalTitle'].astype(str)]\n",
    "rates=rates.drop(columns='originalTitle')\n",
    "\n",
    "#dropping all rows that have a movie name appearing multiple times so the merging on movie name with the CMU dataset is precise\n",
    "rates = rates.drop_duplicates('movie_name', keep=False)\n",
    "\n",
    "#converting runtimeMinutes to float and changing '\\\\N' to NaN to match the format in CMU dataset\n",
    "rates['runtimeMinutes']=list(map(lambda x: float(x) if x!='\\\\N' else None , rates['runtimeMinutes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging CMU dataset with the IMdb dataset\n",
    "movies_data_merged = movies_data.merge(rates, how = 'left', on='movie_name')\n",
    "\n",
    "#completing the NaN values in movie_runtime of the CMU dataset with the available ones of the IMdb dataset.\n",
    "#we trust more the CMU dataset than the IMdb one so we give priority to the runtime values of the CMU dataset\n",
    "# to the IMdb ones and use the IMdb only if the value is missing in the CMU.\n",
    "#finally we drop the column with the IMdb runtimes.\n",
    "movies_data_merged.loc[movies_data_merged['movie_runtime'].isna(), 'movie_runtime']=movies_data_merged.loc[movies_data_merged['movie_runtime'].isna(), 'runtimeMinutes']\n",
    "movies_data_merged=movies_data_merged.drop(columns='runtimeMinutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally creating the datasets with all indian movies and all american movies\n",
    "indian_movies = movies_data_merged[movies_data_merged['movie_countries'] == '{\"/m/03rk0\": \"india\"}'].reset_index()\n",
    "american_movies = movies_data_merged[movies_data_merged['movie_countries'] == '{\"/m/09c7w0\": \"united states of america\"}'].reset_index()\n",
    "\n",
    "print('There are %d indian films and %d american films in the dataset' % (len(indian_movies), len(american_movies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asserting purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('wiki ID, indian: ', len(indian_movies.drop_duplicates('wikipedia_movie_id')), '\\nfreebase ID, indian: ', len(indian_movies.drop_duplicates('freebase_movie_id')))\n",
    "print('wiki ID, american: ', len(american_movies.drop_duplicates('wikipedia_movie_id')), '\\nfreebase ID, american: ', len(american_movies.drop_duplicates('freebase_movie_id')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our indian and american movies data base both do not contain any duplicates on either wikipedia movie ID nor freebase ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the movie box office revenue is very often unavailable and present in very limited number in both datasets. Thus we probably won't use it for further analysis.\n",
    "\n",
    "The informations merged from the IMdb dataset (averageRating, numVotes and isAdult) are available in almost the half of the dataset which makes them still usable despite an important loss of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some global infos about ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.3f percent of indian movies have a rating and %.3f percent of american movies have a rating' %\n",
    "(100-np.sum(indian_movies['averageRating'].isna())/indian_movies.shape[0]*100, 100-np.sum(american_movies['averageRating'].isna())/american_movies.shape[0]*100))\n",
    "\n",
    "print('Average rating of indian movies : %.3f \\tAverage rating of american movies : %.3f' %\n",
    "(np.mean(indian_movies['averageRating']), np.mean(american_movies['averageRating'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions of movie ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,3))\n",
    "sns.histplot(x='averageRating', data=american_movies, alpha=0.5, label='American', stat = 'density', binrange=[0,10], bins = 20, kde=True)\n",
    "sns.histplot(x='averageRating', data=indian_movies, alpha=0.5, color='orange', stat = 'density', label='Indian', binrange=[0,10], bins = 20, kde=True)\n",
    "plt.title('Distribution of movies ratings')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('P-value for normality test of american ratings : %.10f \\tP-value for normality test of indian ratings : %.10f ' \n",
    "      % (st.normaltest(american_movies['averageRating'], nan_policy='omit').pvalue, st.normaltest(indian_movies['averageRating'], nan_policy='omit').pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indian and american movies get similar distributions of ratings. This will allow us to use more easily the ratings as an unbiased tool to estimate the success of a movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of number of votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(2,2,1)\n",
    "sns.histplot(american_movies['numVotes'], bins=np.logspace(0,7,50), alpha =.5, binrange=[0., 1e7], stat = 'density')\n",
    "sns.histplot(indian_movies['numVotes'], bins=np.logspace(0,7,50), alpha=.5, binrange=[0., 1e7], color = 'orange', stat = 'density')\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of votes')\n",
    "plt.title('Number of votes per film, differenciated by movie coutry')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(data = pd.DataFrame({'USA': american_movies['numVotes'], 'India': indian_movies['numVotes']}))\n",
    "plt.yscale('log')\n",
    "plt.title('Distribution of votes per film, differenciated by movie coutry')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot we can see that the distributions follow similar patterns, except in the extrems. Proportionally, indian movies have more films with few votes (less than 100 votes), and, inversly, american movies have a movies that exceed the maximum number of votes any indian film obtains\n",
    "\n",
    "In average, american films receive more votes, but Indian films receive enough votes so that we can deem their ratings reliable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centering the data around each means for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#center data on mean\n",
    "indian_movies.loc[:,'centeredRating']=indian_movies['averageRating'].copy()-np.mean(indian_movies['averageRating'])\n",
    "american_movies.loc[:,'centeredRating']=american_movies['averageRating'].copy()-np.mean(american_movies['averageRating'])\n",
    "print('Centered average rating of indian movies : %.3f \\tCentered average rating of american movies : %.3f' %\n",
    "(np.mean(indian_movies['centeredRating']), np.mean(american_movies['centeredRating'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtimes analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some global infos about runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.3f percent of indian movies have a runtime and %.3f percent of american movies have a runtime' %\n",
    "(100-np.sum(indian_movies['movie_runtime'].isna())/indian_movies.shape[0]*100, 100-np.sum(american_movies['movie_runtime'].isna())/american_movies.shape[0]*100))\n",
    "\n",
    "print('Average runtime of indian movies : %.3f \\tAverage runtime of american movies : %.3f' %\n",
    "(indian_movies['movie_runtime'].mean(), american_movies['movie_runtime'].mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of movie runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_runtime = pd.DataFrame({'USA': american_movies.query('movie_runtime < 10000')['movie_runtime'], 'India': indian_movies.query('movie_runtime < 10000')['movie_runtime']})\n",
    "sns.histplot(data = data_runtime)\n",
    "plt.yscale('log')\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.title(f'Distribution of runtimes (outlier of removed)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot we can see that we have a few outliers in both datasets. Looking at most of the films that are longer than 1000 minutes (16 hours), we decided that they could be discarted as they are either errors or not pertinent to our analysis (series of films instead of single film)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of films longer than 16 hours:', len(indian_movies.query('movie_runtime > 1000')) + len(american_movies.query('movie_runtime > 1000')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting 8 films that are very likely to be errors shouldn't make default to our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting films with runtime longer than 6 hours\n",
    "\n",
    "indian_movies = indian_movies.query('movie_runtime < 1000')\n",
    "american_movies = american_movies.query('movie_runtime < 1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining number of bins to get roughly equal width between the 2 histograms\n",
    "data_runtime = pd.DataFrame({'USA': american_movies['movie_runtime'], 'India': indian_movies['movie_runtime']})\n",
    "#plotting\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "sns.histplot(american_movies['movie_runtime'], alpha =.5, stat = 'density', bins = 100, binrange= [0,1000])\n",
    "sns.histplot(indian_movies['movie_runtime'], alpha=.5, color = 'orange', stat = 'density', bins = 100, binrange= [0,1000])\n",
    "plt.yscale('log')\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.xlabel('Movie runtime')\n",
    "plt.title('Movie runtime, differenciated by movie coutry')\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.violinplot(data = data_runtime)\n",
    "plt.ylabel('Minutes')\n",
    "plt.title(f'Distribution of runtimes (outlier of removed)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('median runtime difference:', np.nanmedian(american_movies['movie_runtime'] - indian_movies['movie_runtime']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that indian movies have a tendancy to be longer by ~56 minutes and that there are a lot of short american movies, perhaps the oldest films from the dataset.\n",
    "\n",
    "There could thus be a bias in our dataset, because early indian cinema might be under-represneted compared to early american cinema. We will investigate this bias when differentiating with respects to time.\n",
    "\n",
    "It would be interesting to further study the evolution of these tendancies through time and integrate runtime to our analysis. Do we tend to a global equilibrium in the runtimes between indian and american movies revealing a standardization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers of Indian vs American movies per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_movies_years = indian_movies.copy()\n",
    "\n",
    "#slice the movie release date column to only have the years, and transform them as integer again\n",
    "indian_movies_years['movie_release_date'] = indian_movies['movie_release_date'].dropna().astype('str').apply(lambda s: s[0:4]).astype('int')\n",
    "\n",
    "#count the numbers of movies per year there are for indian movies\n",
    "n_movie_per_year_indian = indian_movies_years.groupby('movie_release_date')['movie_name'].agg(['count'])\n",
    "\n",
    "#change the movie release date as a column\n",
    "n_movie_per_year_indian = pd.DataFrame(n_movie_per_year_indian).reset_index()\n",
    "\n",
    "#sort the values\n",
    "n_movie_per_year_indian['movie_release_date'] = n_movie_per_year_indian['movie_release_date'].sort_values()\n",
    "\n",
    "n_movie_per_year_indian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_movies_years = american_movies.copy()\n",
    "\n",
    "#slice the movie release date column to only have the years, and transform them as integer again\n",
    "american_movies_years['movie_release_date'] = american_movies['movie_release_date'].dropna().astype('str').apply(lambda s: s[0:4]).astype('int')\n",
    "\n",
    "#count the numbers of movies per year there are for american movies\n",
    "n_movie_per_year_american = american_movies_years.groupby('movie_release_date')['movie_name'].agg(['count'])\n",
    "\n",
    "#change the movie release date as a column\n",
    "n_movie_per_year_american = pd.DataFrame(n_movie_per_year_american).reset_index()\n",
    "\n",
    "#sort the values\n",
    "n_movie_per_year_american['movie_release_date'] = n_movie_per_year_american['movie_release_date'].sort_values()\n",
    "\n",
    "n_movie_per_year_american"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us slice the data to have the same time frame: from 1912 to 2014 for both Indian and American movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice the data to have same time frame for both Indian and American movies data sets\n",
    "n_movie_per_year_american = n_movie_per_year_american.query('movie_release_date <= 2014 & movie_release_date >= 1912')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot both Indian and American numbers of movies per year\n",
    "sns.lineplot(data= n_movie_per_year_indian, x='movie_release_date', y = 'count', label='indian')\n",
    "sns.lineplot(data= n_movie_per_year_american, x='movie_release_date', y = 'count', label='american')\n",
    "plt.title('Indian vs American movies per year ')\n",
    "plt.xlabel('Movie release year')\n",
    "plt.ylabel('Number of movies per year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe a peak starting to grow from the 2000 years for both Hollywood and Bollywood movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zoom in during the peak of Indian and American released movie years\n",
    "sns.lineplot(data= n_movie_per_year_indian, x='movie_release_date', y = 'count', label='indian')\n",
    "sns.lineplot(data= n_movie_per_year_american, x='movie_release_date', y = 'count', label='american')\n",
    "plt.title('Indian vs American movies per year, from the 2000s')\n",
    "plt.xlabel('Movie release year')\n",
    "plt.ylabel('Number of movies per year')\n",
    "plt.axis([2000, 2014, 0, 1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The peak of released movies are at 2006 for Hollywood and 2008 Bollywood respectively.\n",
    "\n",
    "At 2014 it goes back to nearly 0 films released, but we should investigate carefully the data set that explain this lack of data.\n",
    "\n",
    "Thus we begin the data set in 1950 for both Hollywood and Bollywood movies and cut the data set to 2006 for both Hollywood and Bollywood movies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the movie release date column to only have the years, and transform them as integer again\n",
    "indian_movies['movie_release_date'] = indian_movies['movie_release_date'].dropna().astype('str').apply(lambda s: s[0:4]).astype('int')\n",
    "american_movies['movie_release_date'] = american_movies['movie_release_date'].dropna().astype('str').apply(lambda s: s[0:4]).astype('int')\n",
    "\n",
    "# Cut the data from 1950 to 2006 to have the same time frame for both Indian and American movies data sets\n",
    "cut_american_movies = american_movies.query('movie_release_date <= 2010 & movie_release_date >= 1980')\n",
    "cut_indian_movies = indian_movies.query('movie_release_date <= 2010 & movie_release_date >= 1980')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie genre analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indian = indian_movies.copy()\n",
    "#remove {}\n",
    "test_indian['cleared_movie_genres'] = test_indian['movie_genres'].str[1:-1]\n",
    "#remove films without genre\n",
    "test_indian = test_indian.query(\"cleared_movie_genres != ''\")\n",
    "\n",
    "test_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all genres and count each genre number of apparation\n",
    "all_genres_listed_indian = test_indian['cleared_movie_genres'].str.split(pat=\",\")\n",
    "\n",
    "ls = []\n",
    "for i in all_genres_listed_indian:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_genres_indian = pd.Series(ls)\n",
    "all_genres_indian = all_genres_indian.str.strip().value_counts()\n",
    "all_genres_indian.index = [ele.split(':')[1][2:-1] for ele in all_genres_indian.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the first 50 genres\n",
    "first_genres_indian = all_genres_indian[:50]\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(y = first_genres_indian.index, x = first_genres_indian).set_title('Movie genres apparition in indian movies')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_american = american_movies.copy()\n",
    "#remove {}\n",
    "test_american['cleared_movie_genres'] = test_american['movie_genres'].str[1:-1]\n",
    "#remove films without genre\n",
    "test_american = test_american.query(\"cleared_movie_genres != ''\")\n",
    "test_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all genres and count each genre number of apparation\n",
    "all_genres_listed_american = test_american['cleared_movie_genres'].str.split(pat=\",\")\n",
    "\n",
    "ls = []\n",
    "for i in all_genres_listed_american:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_genres_american = pd.Series(ls)\n",
    "all_genres_american = all_genres_american.str.strip().value_counts()\n",
    "all_genres_american.index=[ele.split(':')[1][2:-1] for ele in all_genres_american.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the first 50 genres\n",
    "first_genres_american = all_genres_american[:50]\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(y = first_genres_american.index, x = first_genres_american).set_title('Movie genres apparition in American movies')\n",
    "sns.despine(left=True, bottom=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare them with each other, we calculate the frequency of movie genre in each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate frequencies of movie genre in each production\n",
    "all_genres_american_frequency = all_genres_american/len(american_movies)\n",
    "first_genres_american_frequency = all_genres_american_frequency[:50]\n",
    "all_genres_indian_frequency = all_genres_indian/len(indian_movies)\n",
    "first_genres_indian_frequency = all_genres_indian_frequency[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the first 50 genres\n",
    "fig, ax = plt.subplots(1,2,figsize=(10, 10),sharex = True, constrained_layout=True)\n",
    "fig.suptitle('Movie genres frequency in american and indian films')\n",
    "ax[0].set_title('America')\n",
    "ax[1].set_title('India')\n",
    "\n",
    "sns.barplot(ax = ax[0],y = first_genres_american_frequency.index, x = first_genres_american_frequency, label=\"American\", color=\"b\")\n",
    "sns.barplot(ax = ax[1], y = first_genres_indian_frequency.index, x = first_genres_indian_frequency, label=\"Indian\", color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Indian movies have a total of %d different movies genres and american have %d\" %(len(all_genres_indian.index), len(all_genres_american.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the plots show, \"drama\" is the prominent movie genre in both american and indian movies. However, american movies seems to have a better distribution of different genres than indian that are clearly more focused around \"drama\".\n",
    "\n",
    "Furthermore, both of them have a large number of different movie genres which can make the analysis difficult. Moreover, genres like \"silent film\" or \"world cinema\" are not specific theme to categorize the movies. In the other hand, it seems that some genres are similar to each other or some of them include other genres (e.g. \"action/aventure\" can include \"aventure\"). In conclusion, for further analysis, it could be interesting to select a restricted group of movie genres that allows better and more precises results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First analysis of movie genre across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_american['movie_release_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_american = cut_american_movies.copy()\n",
    "test_american = test_american.dropna(subset= 'movie_release_date')\n",
    "test_american['movie_release_date'] = test_american['movie_release_date'].astype(str)\n",
    "test_american['movie_release_date'] = test_american['movie_release_date'].str.slice(stop = 4)\n",
    "test_american['cleared_movie_genres'] = test_american['movie_genres'].str[1:-1]\n",
    "test_american = test_american.query(\"cleared_movie_genres != ''\")\n",
    "all_genre_american_time = pd.DataFrame(test_american['cleared_movie_genres'])\n",
    "all_genre_american_time.index = test_american['movie_release_date'] \n",
    "all_genre_american_time = pd.DataFrame(all_genre_american_time.groupby(['movie_release_date'])['cleared_movie_genres'].apply(','.join).apply(lambda x: x.split(','))).explode('cleared_movie_genres')\n",
    "all_genre_american_time['year'] = all_genre_american_time.index\n",
    "all_genre_american_time['cleared_movie_genres']=[ele.split(':')[1][2:-1] for ele in all_genre_american_time['cleared_movie_genres']]\n",
    "\n",
    "final = pd.crosstab(all_genre_american_time['year'], all_genre_american_time['cleared_movie_genres'])\n",
    "#taking the first 30 genres\n",
    "final = final[final.sum().sort_values(ascending= False)[:30].index]\n",
    "#normalize by the number of genres per year\n",
    "final = final.apply(lambda x: x/final.sum(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the 30 first prominent movie genres presence across time\n",
    "#a, f = plt.subplots(figsize = (10,10), constrained_layout=True)\n",
    "#plt.stackplot(final[70:].index, final[70:].to_dict(orient = 'list').values(), labels = final.keys())\n",
    "#f.legend(loc='upper left')\n",
    "#f.tick_params(axis = 'x', rotation = 90)\n",
    "#a.suptitle(\"30 first prominent movie genres presence across time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there a too much genres to correctly analyze this plot. This encourages to select the main genres to analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will investigate some disparities or resemblence of the available languages of the film."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indian movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_languages= indian_movies.copy()\n",
    "#remove the {} in each rows\n",
    "indian_languages['cleared_movie_languages'] = indian_languages['movie_languages'].str[1:-1]\n",
    "\n",
    "#remove the films without any languages\n",
    "indian_languages = indian_languages.query(\"cleared_movie_languages != ''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list with all languages\n",
    "all_languages_listed_indian = indian_languages['cleared_movie_languages'].str.split(pat=\",\")\n",
    "\n",
    "#Drop the NAs\n",
    "all_languages_listed_indian = all_languages_listed_indian.dropna()\n",
    "\n",
    "#Create a list with all the languages in it\n",
    "ls = []\n",
    "for i in all_languages_listed_indian:\n",
    "    ls.extend(i)\n",
    " \n",
    "#Count the total number of languages that are in the movies for each one of the languages\n",
    "all_languages_indian = pd.Series(ls)\n",
    "\n",
    "#Strip the strings and count the numbers of occurence of each languages\n",
    "all_languages_indian = all_languages_indian.str.strip().value_counts()\n",
    "\n",
    "all_languages_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_languages_indian_code = all_languages_indian.copy()\n",
    "\n",
    "#Put it as data frame\n",
    "all_languages_indian_code= pd.DataFrame(all_languages_indian_code)\n",
    "\n",
    "#Reset the index to have the index as column\n",
    "all_languages_indian_code = all_languages_indian_code.reset_index()\n",
    "\n",
    "#Rename the columns correctly\n",
    "all_languages_indian_code = all_languages_indian_code.rename(columns={\"index\": \"languages\", 0:\"count\"})\n",
    "\n",
    "#Remove the code part (that begins with \"/m\")\n",
    "all_languages_indian_code['languages'] = all_languages_indian_code['languages'].apply(lambda s: re.sub(r'/m.+ \"', '',s))\n",
    "\n",
    "#Only take the top 20 languages to plot it \n",
    "top_20_ind = all_languages_indian_code.iloc[:20]\n",
    "\n",
    "top_20_ind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting top 20 languages (39 in total for indian languages)\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(data = top_20_ind,y = 'languages', x = 'count').set_title('Languages apparition in Indian movies')\n",
    "ax.set_xscale('log')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### American films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_languages = american_movies.copy()\n",
    "#Remove the {} in the column\n",
    "american_languages['cleared_movie_languages'] = american_languages['movie_languages'].str[1:-1]\n",
    "\n",
    "#Remove films without languages\n",
    "american_languages = american_languages.query(\"cleared_movie_languages != ''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list with all languages\n",
    "all_languages_listed_american = american_languages['cleared_movie_languages'].str.split(pat=\",\")\n",
    "\n",
    "#Drop the NAs\n",
    "all_languages_listed_american = all_languages_listed_american.dropna()\n",
    "\n",
    "#Create a list with all the languages in it\n",
    "ls = []\n",
    "for i in all_languages_listed_american:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_languages_american = pd.Series(ls)\n",
    "\n",
    "#Count the total number of languages that are in the movies for each one of the languages\n",
    "all_languages_american = all_languages_american.str.strip().value_counts()\n",
    "\n",
    "all_languages_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_languages_american_code =  all_languages_american.copy()\n",
    "\n",
    "#Put it as data frame\n",
    "all_languages_american_code = pd.DataFrame(all_languages_american_code)\n",
    "\n",
    "#Reset the index to have the index as column\n",
    "all_languages_american_code = all_languages_american_code.reset_index()\n",
    "\n",
    "#Rename the columns correctly\n",
    "all_languages_american_code = all_languages_american_code.rename(columns={\"index\": \"languages\", 0:\"count\"})\n",
    "\n",
    "#Remove the code part (that begins with \"/m\")\n",
    "all_languages_american_code['languages'] = all_languages_american_code['languages'].apply(lambda s: re.sub(r'/m.+ \"', '',s))\n",
    "\n",
    "#Only take the top 20 languages to plot it \n",
    "top_20_american = all_languages_american_code.iloc[:20]\n",
    "\n",
    "top_20_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting top 20 languages (111 in total for American movies)\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(data = top_20_american, y = 'languages', x = 'count').set_title('Languages apparition in American movies')\n",
    "ax.set_xscale('log')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the frequency of top 20 for the American and Indian languages\n",
    "all_languages_american_code['frequency'] = all_languages_american_code['count'] / all_languages_american_code['count'].sum()\n",
    "first_languages_american_frequency = all_languages_american_code[:20]\n",
    "\n",
    "all_languages_indian_code['frequency'] = all_languages_indian_code['count']/all_languages_indian_code['count'].sum()\n",
    "first_languages_indian_frequency = all_languages_indian_code[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting taking the first 20 languages for American films and Indian movies\n",
    "fig, ax = plt.subplots(1,2,figsize=(10, 10),sharex = True, constrained_layout=True)\n",
    "fig.suptitle('Top 20 movie languages frequency in American and Indian movies')\n",
    "ax[0].set_title('American movies')\n",
    "ax[1].set_title('Indian movies')\n",
    "\n",
    "sns.barplot(ax = ax[0],data = first_languages_american_frequency, y = 'languages', x = 'frequency', label=\"American\", color=\"b\")\n",
    "\n",
    "sns.barplot(ax = ax[1], data = first_languages_indian_frequency, y = 'languages', x = 'frequency', label=\"Indian\", color=\"r\")\n",
    "\n",
    "#Setting logarithmic scale \n",
    "ax[0].set_xscale('log')\n",
    "ax[1].set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many languages per movies there are, on average ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the number of ':' that represent the number of languages there are in each row for American movies\n",
    "american_languages['n_languages'] = american_languages.cleared_movie_languages.str.count(':')\n",
    "\n",
    "#Compute the number of ':' that represent the number of languages there are in each row for Indian movies\n",
    "indian_languages['n_languages'] = indian_languages.cleared_movie_languages.str.count(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the movies that do not have any languages\n",
    "n_indian_lan = indian_languages['n_languages'].dropna()\n",
    "\n",
    "n_american_lan = american_languages['n_languages'].dropna()\n",
    "\n",
    "#Compute the t-test to compare the number of available languages per movies for Indian and American movies\n",
    "t_test_languages = st.ttest_ind(n_indian_lan, n_american_lan)\n",
    "\n",
    "t_test_languages.pvalue\n",
    "\n",
    "print('p-value for languages: ',t_test_languages.pvalue, '\\t', 'p-value is smaller than 0.05: ', t_test_languages.pvalue <0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant difference of the numbers of languages spoken in American vs Indian movies, so it could be that there are underlying effects, like Hollywood are more exported abroad than Bollywood movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characters data\n",
    "\n",
    "450'668 characters in raw data\n",
    "\n",
    "134079 differents actor \n",
    "\n",
    "5794 differents actor in indian movies\n",
    "\n",
    "59398 differents actors in american movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['wikipedia_movie_id', 'freebase_movie_id', 'movie_release_date', 'character_name', 'actor_dob', 'actor_gender', 'actor_height', 'actor_ethnicity', 'actor_name', 'actor_age_at_movie_release', 'char_act_id', 'freebase_character_id', 'freebase_actor_id']\n",
    "characters_data = pd.read_csv(data_folder + 'character.metadata.tsv', names = names, sep = '\\t')\n",
    "\n",
    "characters_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting every name in lower case\n",
    "characters_data[['character_name', 'actor_name']] = characters_data[['character_name', 'actor_name']].applymap(lambda x: x if type(x)!=str else x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including ethnicities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the automatic query system from wikidata, we are able to retrieve the ethnicity of the actors based on the freebase ID in the actor_ethnicity column. For that we just map the matching id to the string-representation of the ethnicity for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_ethnicities = pd.read_csv('data/ethnicities.csv')[['freebaseID', 'name']]\n",
    "actor_ethnicities = dict(zip(actor_ethnicities.freebaseID, actor_ethnicities.name))\n",
    "characters_data['actor_ethnicity'] = characters_data['actor_ethnicity'].map(actor_ethnicities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the dataset in two\n",
    "# all_american_actors can contain duplicate actors, it deals with the films \n",
    "# and who plays in it, the age they have when the film is produced\n",
    "#\n",
    "# all_indian_actors contains data about individual actors, it doesn't contain duplicates\n",
    "\n",
    "all_american_actors = characters_data[characters_data['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])]\n",
    "all_indian_actors = characters_data[characters_data['wikipedia_movie_id'].isin(indian_movies['wikipedia_movie_id'])]\n",
    "\n",
    "unique_american_actor = all_american_actors.drop_duplicates('actor_name')\n",
    "unique_indian_actor = all_indian_actors.drop_duplicates('actor_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add a column indicating the country the actor/actress works in before concatenating the datasets\n",
    "unique_american_actor = unique_american_actor.assign(country = np.full(len(unique_american_actor), 'USA'))\n",
    "unique_indian_actor = unique_indian_actor.assign(country = np.full(len(unique_indian_actor), 'India'))\n",
    "\n",
    "all_american_actors = all_american_actors.assign(country = np.full(len(all_american_actors), 'USA'))\n",
    "all_indian_actors = all_indian_actors.assign(country = np.full(len(all_indian_actors), 'India'))\n",
    "\n",
    "\n",
    "#unique_indian_actor['country'] = np.full(len(unique_indian_actor), 'India')\n",
    "\n",
    "# We make sure to only keep actors with positive age to get rid of the errors \n",
    "all_american_actors = all_american_actors[all_american_actors['actor_age_at_movie_release'] > 0.]\n",
    "all_indian_actors = all_indian_actors[all_indian_actors['actor_age_at_movie_release'] > 0.]\n",
    "\n",
    "feature_list_all_actors = ['actor_gender', 'actor_age_at_movie_release', 'country']\n",
    "all_actors_merged = pd.concat([all_american_actors[feature_list_all_actors], all_indian_actors[feature_list_all_actors]], axis = 0)\n",
    "\n",
    "feature_list_unique_actors = ['actor_name', 'actor_gender', 'actor_ethnicity', 'country']\n",
    "unique_actors_merged = pd.concat([unique_american_actor[feature_list_unique_actors], unique_indian_actor[feature_list_unique_actors]], axis = 0)\n",
    "\n",
    "# Adding a column to the dataset of the features of single actors for the number of films in our dataset they appear in\n",
    "dict_number_of_film = characters_data['actor_name'].value_counts().to_dict()\n",
    "unique_actors_merged['number_of_films'] = unique_actors_merged['actor_name'].map(dict_number_of_film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actors_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_actors_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actor Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do analysis on age, it makes sense to count the same actors multiple times as they play in different films, we will thus not drop the duplicates for this part of the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_american_actors.actor_age_at_movie_release.describe())\n",
    "print(all_indian_actors.actor_age_at_movie_release.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mean age is similar in both cases, as well as the standard deviation. Looking at the different quartiles we cannot see significant distribution difference between the two groups. \n",
    "\n",
    "We can note, however, that we have significantly more available ages available for actors in american films as for actors in indian films (137'073 versus 31'201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_ind(all_american_actors.actor_age_at_movie_release, all_indian_actors.actor_age_at_movie_release, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reject the null hypothesis, that is, that the mean actor age from american and indian movies are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = all_american_actors['actor_age_at_movie_release'], stat = 'density', discrete=True, color = 'blue', kde=True)\n",
    "sns.histplot(data = all_indian_actors['actor_age_at_movie_release'], stat = 'density',discrete=True, color='red', kde=True)\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.xlabel('Actor age')\n",
    "plt.title('Distribution of actor age in indian and american movies')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be more teenagers cast in american films, this can be due to the popularity of 'teen movies' in the western world, but is more likely to be simply due to a bias in quantity of information about american movies. The wikipedia pages of american movies might be more detailed about american films, containing even information about characters that may have relatively low screen time, like the daughter of a secondary character etc..\n",
    "\n",
    "Otherwise the distributions seem similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actor Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We separate the datasets containing all actors by gender\n",
    "# For american films\n",
    "american_film_female = all_american_actors[all_american_actors['actor_gender'] == 'F']\n",
    "american_film_male = all_american_actors[all_american_actors['actor_gender'] == 'M']\n",
    "\n",
    "# And for indian films\n",
    "indian_film_female = all_indian_actors[all_indian_actors['actor_gender'] == 'F']\n",
    "indian_film_male = all_indian_actors[all_indian_actors['actor_gender'] == 'M']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of american film actors we have the gender of is {0}, of which {1:.0%} are female'.format(\n",
    "    len(american_film_male) + len(american_film_female), len(american_film_female)/(len(american_film_male) + len(american_film_female))))\n",
    "\n",
    "print('Number of indian film actors we have the gender of is {0}, of which {1:.0%} are female'.format(\n",
    "    len(indian_film_male) + len(indian_film_female), len(indian_film_female)/(len(indian_film_male) + len(indian_film_female))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.suptitle('Comparaison of actor gender and age in American and Indian films', size = 'xx-large')\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "sns.histplot(data = all_american_actors, x = 'actor_age_at_movie_release', hue = 'actor_gender', stat = 'density', discrete=True, kde=True)\n",
    "plt.xlabel('Actor/actress age')\n",
    "plt.title('Distribution of american film actor age with respect to gender')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.histplot(data = all_indian_actors, x = 'actor_age_at_movie_release', hue = 'actor_gender', stat = 'density', discrete=True, kde=True)\n",
    "\n",
    "plt.xlabel('Actor/actress age')\n",
    "plt.title('Distribution of indian film actor age with respect to gender')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.histplot(data = all_american_actors[all_american_actors['actor_gender'] == 'F'], x = 'actor_age_at_movie_release', stat = 'density', discrete=True, color='orange', kde=True)\n",
    "sns.histplot(data = all_indian_actors[all_indian_actors['actor_gender'] == 'F'], x = 'actor_age_at_movie_release', stat = 'density', discrete=True, kde=True)\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.title('Distribution of actress age, differenciated by country')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "sns.histplot(data = all_american_actors[all_american_actors['actor_gender'] == 'M'], x = 'actor_age_at_movie_release', stat = 'density', discrete=True, color='orange', kde=True)\n",
    "sns.histplot(data = all_indian_actors[all_indian_actors['actor_gender'] == 'M'], x = 'actor_age_at_movie_release', stat = 'density', discrete=True, kde=True)\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.title('Distribution of actor age, differenciated by country')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the same phenomenon using boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = all_actors_merged, y = 'actor_age_at_movie_release', x = 'country', hue= 'actor_gender')\n",
    "plt.title('Other visualization of the differences in age distribution by gender and country of movie production')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are very little differences between the distributions of actor age between the two movie industries, but a big difference between the distribution of actresses' age. We can see that in indian movies there is a big density peak in the low twenties and a rapid decline from the thirties onward. \n",
    "\n",
    "This difference is very stark and should be investigated further in the rest of our analysis, regarding time-wise changes and the prediction of movie success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the significance of the difference between the mean age of actors and actresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st.ttest_ind(all_american_actors.loc[all_american_actors.actor_gender == 'F']['actor_age_at_movie_release'],all_american_actors.loc[all_american_actors.actor_gender == 'M']['actor_age_at_movie_release']))\n",
    "print(st.ttest_ind(all_indian_actors.loc[all_indian_actors.actor_gender == 'F']['actor_age_at_movie_release'],all_indian_actors.loc[all_indian_actors.actor_gender == 'M']['actor_age_at_movie_release']))\n",
    "print(st.ttest_ind(all_american_actors.loc[all_american_actors.actor_gender == 'F']['actor_age_at_movie_release'],all_indian_actors.loc[all_indian_actors.actor_gender == 'F']['actor_age_at_movie_release']))\n",
    "print(st.ttest_ind(all_american_actors.loc[all_american_actors.actor_gender == 'M']['actor_age_at_movie_release'],all_indian_actors.loc[all_indian_actors.actor_gender == 'M']['actor_age_at_movie_release']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All null hypotheses can be rejected at the alpha = 0.05 level, although the effects might mainly be driven by sample size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of films actors played in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.suptitle('Number of films an actor plays in', size = 'xx-large')\n",
    "plt.subplot(2,2,1)\n",
    "sns.histplot(data = unique_actors_merged[unique_actors_merged['country'] == 'India'], bins = np.logspace(0,2, 10), x = 'number_of_films', hue = 'actor_gender', kde = True, stat = 'density').set(xscale=\"log\")\n",
    "plt.title('Number of films per actor in indian movies, differenciated by gender')\n",
    "plt.subplot(2,2,2)\n",
    "sns.histplot(data = unique_actors_merged[unique_actors_merged['country'] == 'USA'], bins = np.logspace(0,2, 10), x = 'number_of_films', hue = 'actor_gender', kde = True, stat = 'density').set(xscale=\"log\")\n",
    "plt.title('Number of films per actor in american movies, differenciated by gender')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.barplot(data = unique_actors_merged, y = 'number_of_films', x = 'country', hue= 'actor_gender')\n",
    "plt.title('Resume of the differences in film numbers between countries, differentiated by gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the number of actors/actresses\n",
    "unique_actors_merged[unique_actors_merged['number_of_films'] > 100].groupby(['country', 'actor_gender']).agg({'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably have a bias in our dataset in the quantity of information we have in our dataset regarding the american films. We are far more likely to have the names of actors that make a single brief aparition in an american film. However regarding the other extreme, we can see that there a lot more ultra-prolific indian film actors than american film actors.\n",
    "\n",
    "In both film industries we see however that most of the hyper-prolific actors are males, which is probably linked to the difference in carreer prospects with age.\n",
    "\n",
    "This is once again a angle that could be included in further analysis regarding trends through time and film succes (ratings) prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actor ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_data = unique_actors_merged.groupby(['actor_ethnicity', 'country'], as_index=False)['actor_name'].agg({'count'})\n",
    "ethnicity_data = pd.DataFrame(ethnicity_data.to_records())\n",
    "ethnicity_data = ethnicity_data.set_index('actor_ethnicity')\n",
    "\n",
    "#separate the dataset per country\n",
    "ethnicity_data_india = ethnicity_data[ethnicity_data['country'] == 'India']\n",
    "ethnicity_data_usa = ethnicity_data[ethnicity_data['country'] == 'USA']\n",
    "\n",
    "# converting count into density\n",
    "ethnicity_data_india['count'] = ethnicity_data_india.loc[:,'count'].div(len(ethnicity_data_india)).copy(deep=True)\n",
    "ethnicity_data_usa['count'] = ethnicity_data_usa.loc[:,'count'].div(len(ethnicity_data_usa)).copy(deep=True)\n",
    "\n",
    "ethnicity_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,80))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Ethnicity of actors ranked per frequency for movies produced in India')\n",
    "sns.barplot(data = ethnicity_data_india, y = ethnicity_data_india.index,  x = 'count', orient='h', order=ethnicity_data_india.sort_values(by = 'count', ascending=False).index)\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('Density')\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Ethnicity of actors ranked per frequency for movies produced in the USA')\n",
    "sns.barplot(data = ethnicity_data_usa, y = ethnicity_data_usa.index,  x = 'count', orient='h', order=ethnicity_data_usa.sort_values(by = 'count', ascending=False).index)\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, most ethnicities represented in the american films are descendent of immigrants, and most ethnicities represented in indian films are indian or more generally south-Asian. Also unsurprisingly, There are a lot more different ethnicities represented in films produced in the US compared to films produced in India. This might be due to the US being a more cosmopolite country, and to the difference in amout of information we have in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try investigate further the differences in representations in the industies, looking at the ethnicities represented in both industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative values represent ethnicities more represented in the indian film industry, and vice versa\n",
    "compared_ethnicities = (ethnicity_data_usa['count'] - ethnicity_data_india['count']).dropna()\n",
    "\n",
    "plt.title('Relative difference in proportion of ethnicities between indian and american films')\n",
    "sns.barplot(y = compared_ethnicities.index,  x = compared_ethnicities.values, orient='h', order=compared_ethnicities.sort_values(ascending=False).index)\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('Relative density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of character data: conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of indian film actors we have every features for:', unique_actors_merged[unique_actors_merged['country'] == 'India'].dropna().shape[0])\n",
    "print('Number of american film actors we have every features for:', unique_actors_merged[unique_actors_merged['country'] == 'USA'].dropna().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of indian film actors we have everything but ethnicity for:', unique_actors_merged[unique_actors_merged['country'] == 'India']['actor_gender'].shape[0])\n",
    "print('Number of american film actors we have everything but ethnicity for:', unique_actors_merged[unique_actors_merged['country'] == 'USA']['actor_gender'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we consider only actors where we have all the available informations (gender, country the actors plays in, and ethnicity) we only get 354 indian film actors and 1967 american film actors. This is not enough to perform an analysis through time while taking into account actor ethnicity.\n",
    "\n",
    "On the other hand, we have substantially more data on gender so taking it into account could be interesting for time-wise analysis for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name clusters data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['character_name', 'actor_reference']\n",
    "name_clusters_data = pd.read_csv(data_folder + 'name.clusters.txt', names = names, sep = '\\t', )\n",
    "\n",
    "name_clusters_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tvtropes clusters data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read tv tropes data\n",
    "tv_trope = pd.read_csv(data_folder + 'tvtropes.clusters.txt', sep='\\t', names= ['character_type', 'instances'])\n",
    "\n",
    "tv_trope.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove {} strings\n",
    "tv_trope['instances'] = tv_trope['instances'].str[1:-1]\n",
    "\n",
    "split_tv = tv_trope.copy()\n",
    "\n",
    "#Split on , and : to separate into different columns\n",
    "split_tv = tv_trope['instances'].str.split('[,:]', expand=True)\n",
    "\n",
    "#Name the columns accordingly\n",
    "cleaned_tv = split_tv.rename(columns={split_tv.columns[1]: 'character_name', split_tv.columns[3]: 'movie_name', split_tv.columns[5]: 'char_act_id',split_tv.columns[7]: 'actor_name'})\n",
    "\n",
    "#Drop the un-necessary columns\n",
    "cleaned_tv = cleaned_tv.drop(columns=[0,2,4,6,8,9,10])\n",
    "\n",
    "#Remove the \"\"\n",
    "cleaned_tv = cleaned_tv.applymap(lambda s : re.sub(r'\"', \" \", s))\n",
    "\n",
    "#Make everything lowercases \n",
    "cleaned_tv = cleaned_tv.applymap(lambda x: str.casefold(x))\n",
    "\n",
    "characters = tv_trope.character_type\n",
    "\n",
    "#Join to have the characters too \n",
    "final_tv = cleaned_tv.join(characters, how= 'left')\n",
    "\n",
    "final_tv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there is any movies in the tv tropes present in our movie data set\n",
    "list_ = final_tv['movie_name']\n",
    "\n",
    "movies_data['movie_name'].where(movies_data['movie_name'].isin(list_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there is any actors in the tv tropes present in our movie data set\n",
    "list_1 = final_tv['actor_name']\n",
    "\n",
    "movies_data['movie_name'].where(movies_data['movie_name'].isin(list_1)).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating features based on summaries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = pd.read_csv(data_folder + 'plot_summaries.txt', sep = '\\r', names = ['summaries'])\n",
    "summaries = summaries['summaries'].str.split(\"\\t\", expand = True)\n",
    "summaries = summaries.rename(columns= {0:'wikipedia_movie_id',1: 'summaries'})\n",
    "summaries['summaries'] = summaries['summaries'].str.lower()\n",
    "summaries['summaries'] = summaries['summaries'].str.replace('{{plot}}', '')\n",
    "summaries['wikipedia_movie_id'] = summaries['wikipedia_movie_id'].astype(int)\n",
    "summaries.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_summaries = summaries[summaries['wikipedia_movie_id'].isin(indian_movies['wikipedia_movie_id'])]\n",
    "indian_summaries = indian_summaries.reset_index(drop = True)\n",
    "indian_summaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_summaries = summaries[summaries['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])]\n",
    "american_summaries = american_summaries.reset_index(drop = True)\n",
    "american_summaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Topic Detection Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each NLP task requires some sort of data pre-processing to make data eligible for modeling. We will perform the following steps:\n",
    "\n",
    "- Removing punctuation\n",
    "- Tokenization: Splitting sentences into word-sized chunks, called tokens.\n",
    "- Stopwords removal: Stopwords are English words that dont add any value to the analysis. Removing them will help the model to find patterns more easily.\n",
    "- Words with fewer than three letters are removed.\n",
    "- Lemmatization: Converting words to their base using morphological analysis.\n",
    "- Make bigrams: a bigram is a sequence of two adjacent elements from a string that combines to generate a more understandable form (e.g., [data , science] => [data science]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in python console\n",
    "import nltk; nltk.download('stopwords')\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_words = list(sent_to_words(summaries['summaries']))\n",
    "\n",
    "print(summaries_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram model\n",
    "bigram = gensim.models.Phrases(summaries_words, min_count=15, threshold=100) # higher threshold fewer phrases.\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags and len(token)>3])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "summaries_words_no_stopwords = remove_stopwords(summaries_words)\n",
    "\n",
    "# Form Bigrams\n",
    "summaries_words_bigrams = make_bigrams(summaries_words_no_stopwords)\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "summaries_words_lemmatized = lemmatization(summaries_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(summaries_words_lemmatized)\n",
    "\n",
    "# Remove rare and common tokens.\n",
    "# Filter out words that occur too frequently or too rarely.\n",
    "max_freq = 0.5\n",
    "min_wordcount = 15\n",
    "id2word.filter_extremes(no_below=min_wordcount, no_above=max_freq)\n",
    "\n",
    "# Create Corpus\n",
    "texts = summaries_words_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to choose the number of topics ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel # spaCy for preprocessing\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    seed = 80699\n",
    "    base_models = dict()\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics, random_state=seed)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary = id2word, corpus = corpus, texts = texts, start=2, limit=20, step=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=20; start=2; step=3\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics for American and Indian Films\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the coherence score seems to keep increasing, it may make better sense to pick the model that gave the highest CV before flattening out.\n",
    "So here, we choose 14 as the optimal numbers of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[4]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "data = pyLDAvis.gensim_models.prepare(topic_model = optimal_model, corpus = corpus, dictionary = id2word)\n",
    "pyLDAvis.display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=optimal_model, corpus=corpus):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['document_no', 'dominant_topic', 'topic_perc_contrib', 'keywords']\n",
    "\n",
    "#add original text\n",
    "df_dominant_topic = df_dominant_topic.merge(summaries, how = 'left', right_index=True, left_on='document_no')\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lda = optimal_model[corpus]\n",
    "topic_scores = [[topic_score[1] for topic_score in sent] for sent in doc_lda]\n",
    "\n",
    "df_topics = pd.DataFrame(topic_scores)\n",
    "\n",
    "df_topics = df_topics.join(summaries['wikipedia_movie_id'])\n",
    "\n",
    "df_topics = df_topics.replace(np.nan, 0)\n",
    "\n",
    "df_topics = df_topics.rename(columns={0: \"topic_0\", 1: \"topic_1\", 2: \"topic_2\", 3: \"topic_3\", 4: \"topic_4\", 5: \"topic_5\", 6: \"topic_6\", 7: \"topic_7\", 8: \"topic_8\", 9: \"topic_9\", 10: \"topic_10\", 11: \"topic_11\", 12: \"topic_12\", 13: \"topic_13\", 14: \"topic_14\"})\n",
    "\n",
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_features_indian = df_topics.copy()\n",
    "\n",
    "topic_features_indian = df_topics[df_topics['wikipedia_movie_id'].isin(indian_movies['wikipedia_movie_id'])]\n",
    "\n",
    "topic_features_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_features_american= df_topics.copy()\n",
    "\n",
    "topic_features_american = df_topics[df_topics['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])]\n",
    "\n",
    "topic_features_american.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The mean length of american summaries is {1:.2f} words and for indian summaries it is {0:.2f} words.'.format(\n",
    "    np.mean([len(ele.split(' ')) for ele in indian_summaries['summaries']]),\n",
    "    np.mean([len(ele.split(' ')) for ele in american_summaries['summaries']])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can take up to 3min to run\n",
    "\n",
    "#defining analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#computing sentiments for each summary\n",
    "indian_sentiments = pd.DataFrame([analyzer.polarity_scores(summary) for summary in indian_summaries['summaries']])\n",
    "american_sentiments = pd.DataFrame([analyzer.polarity_scores(summary) for summary in american_summaries['summaries']])\n",
    "\n",
    "#adding wikipedia id for future merges\n",
    "indian_sentiments['wikipedia_movie_id']=indian_summaries['wikipedia_movie_id']\n",
    "american_sentiments['wikipedia_movie_id']=american_summaries['wikipedia_movie_id']\n",
    "indian_sentiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "sns.histplot(american_sentiments['compound'], alpha =.5, stat = 'density', bins = 10)\n",
    "sns.histplot(indian_sentiments['compound'], alpha=.5, color = 'orange', stat = 'density', bins = 10)\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.xlabel('Movie sentiments\\nnegative value indicates negative sentiments ; positive value indicates positive sentiments')\n",
    "plt.title('Movie sentiments, differenciated by movie coutry')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating features based on actor data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the output datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_indian_actors = pd.DataFrame({'wikipedia_movie_id':[]})\n",
    "df_features_american_actors = pd.DataFrame({'wikipedia_movie_id':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ids of the movies from the summaries\n",
    "df_features_indian_actors['wikipedia_movie_id']=cut_indian_movies['wikipedia_movie_id']\n",
    "df_features_american_actors['wikipedia_movie_id']=cut_american_movies['wikipedia_movie_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the mean actor age per gender for each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the mean age per gender for indian and american films\n",
    "mean_male_actor_age_india = indian_film_male.groupby('wikipedia_movie_id', as_index=False)['actor_age_at_movie_release'].agg({'mean_male_actor_age': np.mean})\n",
    "mean_female_actor_age_india = indian_film_female.groupby('wikipedia_movie_id', as_index=False)['actor_age_at_movie_release'].agg({'mean_female_actor_age': np.mean})\n",
    "\n",
    "mean_male_actor_age_america = american_film_male.groupby('wikipedia_movie_id', as_index=False)['actor_age_at_movie_release'].agg({'mean_male_actor_age': np.mean})\n",
    "mean_female_actor_age_america = american_film_female.groupby('wikipedia_movie_id', as_index=False)['actor_age_at_movie_release'].agg({'mean_female_actor_age': np.mean})\n",
    "\n",
    "\n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, mean_male_actor_age_india, on = 'wikipedia_movie_id', how = 'left') \n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, mean_female_actor_age_india, on = 'wikipedia_movie_id', how = 'left')\n",
    "\n",
    "df_features_american_actors = pd.merge(df_features_american_actors, mean_male_actor_age_america, on = 'wikipedia_movie_id', how = 'left')\n",
    "df_features_american_actors = pd.merge(df_features_american_actors, mean_female_actor_age_america, on = 'wikipedia_movie_id', how = 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the mean number of films actors in each movie played in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the number of films an actor played in with the rest of the film data\n",
    "all_american_actors_ext = all_american_actors.merge(all_american_actors.actor_name.value_counts().reset_index(), left_on = 'actor_name', right_on = 'index', how = 'left')\n",
    "all_american_actors_ext = all_american_actors_ext.groupby('wikipedia_movie_id', as_index=False)['actor_name_y'].agg({'average_number_of_films_actors_played_in': np.mean})\n",
    "\n",
    "all_indian_actors_ext = all_indian_actors.merge(all_indian_actors.actor_name.value_counts().reset_index(), left_on = 'actor_name', right_on = 'index', how = 'left')\n",
    "all_indian_actors_ext = all_indian_actors_ext.groupby('wikipedia_movie_id', as_index=False)['actor_name_y'].agg({'average_number_of_films_actors_played_in': np.mean})\n",
    "\n",
    "# merging with features\n",
    "df_features_american_actors = pd.merge(df_features_american_actors, all_american_actors_ext[['wikipedia_movie_id', 'average_number_of_films_actors_played_in']], on = 'wikipedia_movie_id', how = 'left')\n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, all_indian_actors_ext[['wikipedia_movie_id', 'average_number_of_films_actors_played_in']], on = 'wikipedia_movie_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the percent of actress in each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_female(x):\n",
    "    try:\n",
    "        return x.value_counts().to_dict()['F']/len(x)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "percent_female_american_films = all_american_actors.groupby('wikipedia_movie_id', as_index=False)['actor_gender'].apply(percent_female)\n",
    "percent_female_american_films.rename(columns = {'actor_gender':'percent_female_cast'}, inplace = True)\n",
    "percent_female_indian_films = all_indian_actors.groupby('wikipedia_movie_id', as_index=False)['actor_gender'].apply(percent_female)\n",
    "percent_female_indian_films.rename(columns = {'actor_gender':'percent_female_cast'}, inplace = True)\n",
    "\n",
    "# merging with features\n",
    "df_features_american_actors = pd.merge(df_features_american_actors, percent_female_american_films, on = 'wikipedia_movie_id', how = 'left')\n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, percent_female_indian_films, on = 'wikipedia_movie_id', how = 'left')\n",
    "\n",
    "# drop the rows with no wikipedia_movie_id\n",
    "df_features_american_actors.dropna(subset = ['wikipedia_movie_id'], inplace = True)\n",
    "df_features_indian_actors.dropna(subset = ['wikipedia_movie_id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging with the sentiment data\n",
    "df_features_american_actors = pd.merge(df_features_american_actors, american_sentiments[['wikipedia_movie_id', 'compound']], on = 'wikipedia_movie_id', how = 'left')\n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, indian_sentiments[['wikipedia_movie_id', 'compound']], on = 'wikipedia_movie_id', how = 'left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the average rating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indian = cut_indian_movies.copy()\n",
    "#remove {}\n",
    "test_indian['cleared_movie_genres'] = test_indian['movie_genres'].str[1:-1]\n",
    "\n",
    "#remove films without genre\n",
    "test_indian = test_indian.query(\"cleared_movie_genres != ''\")\n",
    "#test_indian['cleared_movie_genres'] = [ele.split(':')[1] for ele in test_indian['cleared_movie_genres']]\n",
    "\n",
    "test_american = cut_american_movies.copy()\n",
    "#remove {}\n",
    "test_american['cleared_movie_genres'] = test_american['movie_genres'].str[1:-1]\n",
    "#remove films without genre\n",
    "test_american = test_american.query(\"cleared_movie_genres != ''\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genre_imdb =  pd.Series(['action','adventure','animation','biography','comedy','crime','documentary','drama','family',\n",
    "                              'fantasy','noir','history', 'horror','musical','mystery','romance','sci-fi','short Film',\n",
    "                              'sport','superhero','thriller','war','western'])\n",
    "spec_chars = [':', '\"', ',', '/m/', 'film']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for char in spec_chars:\n",
    "    test_indian['cleared_movie_genres'] = test_indian['cleared_movie_genres'].str.replace(char, '')\n",
    "    test_indian['cleared_movie_genres'] = test_indian['cleared_movie_genres'].str.replace('  ', ' ')\n",
    "    test_american['cleared_movie_genres'] = test_american['cleared_movie_genres'].str.replace(char, '')\n",
    "    test_american['cleared_movie_genres'] = test_american['cleared_movie_genres'].str.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dummies_indian = pd.DataFrame()\n",
    "for char in movie_genre_imdb:\n",
    "    genre_dummies_indian[char] = pd.Series(test_indian['cleared_movie_genres'].apply(lambda x: pd.Series(x).str.contains(char[:3]).any().astype('int')))\n",
    "    \n",
    "genre_dummies_american = pd.DataFrame()\n",
    "for char in movie_genre_imdb:\n",
    "    genre_dummies_american[char] = pd.Series(test_american['cleared_movie_genres'].apply(lambda x: pd.Series(x).str.contains(char[:3]).any().astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dummies_indian['wikipedia_movie_id'] = test_indian['wikipedia_movie_id']\n",
    "genre_dummies_american['wikipedia_movie_id'] = test_american['wikipedia_movie_id']\n",
    "features_indian = pd.merge(genre_dummies_indian, df_features_indian_actors, on= 'wikipedia_movie_id', how = 'right')\n",
    "features_american = pd.merge(genre_dummies_american, df_features_american_actors, on= 'wikipedia_movie_id', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_indian = cut_indian_movies.dropna(subset = 'averageRating')[['wikipedia_movie_id', 'averageRating']]\n",
    "rating_american = cut_american_movies.dropna(subset = 'averageRating')[['wikipedia_movie_id', 'averageRating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian = pd.merge(features_indian, topic_features_indian, on= 'wikipedia_movie_id', how = 'left')\n",
    "features_american = pd.merge(features_american, topic_features_american, on= 'wikipedia_movie_id', how = 'left')\n",
    "features_indian = pd.merge(features_indian, rating_indian, on= 'wikipedia_movie_id', how = 'right')\n",
    "features_american = pd.merge(features_american, rating_american, on= 'wikipedia_movie_id', how = 'right')\n",
    "features_indian = pd.merge(features_indian, test_indian[['wikipedia_movie_id', 'movie_release_date']], on= 'wikipedia_movie_id', how = 'left')\n",
    "features_american = pd.merge(features_american, test_american[['wikipedia_movie_id', 'movie_release_date']], on= 'wikipedia_movie_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian.iloc[:,0:23] = features_indian.iloc[:,0:23].fillna(0) ; features_indian.iloc[:,24:40] = features_indian.iloc[:,24:40].fillna(features_indian.iloc[:,24:40].mean())\n",
    "features_american.iloc[:,0:23] = features_american.iloc[:,0:23].fillna(0) ; features_american.iloc[:,24:40] = features_american.iloc[:,24:40].fillna(features_american.iloc[:,24:40].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "\"\"\"features_indian.to_csv('features_indian.csv', index = False)\n",
    "features_american.to_csv('features_american.csv', index = False)\"\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If you don't want to run everything start here !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian = pd.read_csv('features_indian.csv')\n",
    "features_american = pd.read_csv('features_american.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian_train = features_indian.drop(['wikipedia_movie_id', 'movie_release_date', 'averageRating'], axis = 1).copy()\n",
    "features_american_train = features_american.drop(['wikipedia_movie_id', 'movie_release_date', 'averageRating'], axis = 1).copy()\n",
    "\n",
    "american_ratings = features_american[['averageRating', 'movie_release_date']]\n",
    "indian_ratings = features_indian[['averageRating', 'movie_release_date']]\n",
    "#standardize the data\n",
    "features_indian_train.iloc[:,23:] = (features_indian_train.iloc[:,23:] - features_indian_train.iloc[:,23:].mean())/features_indian_train.iloc[:,23:].std()\n",
    "features_american_train.iloc[:,23:] = (features_american_train.iloc[:,23:] - features_american_train.iloc[:,23:].mean())/features_american_train.iloc[:,23:].std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression (for p-values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian_train.rename(columns={'short Film': 'short', 'sci-fi':'scifi'}, inplace=True)\n",
    "features_american_train.rename(columns={'short Film': 'short', 'sci-fi':'scifi'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form = 'averageRating ~ ' + ' + '.join('C(' + features_indian_train.columns[:23] + ')') + ' + ' + ' + '.join(features_indian_train.columns[23:])\n",
    "form2 = 'averageRating ~ ' + ' + '.join('C(' + features_american_train.columns[:23] + ')') + ' + ' + ' + '.join(features_american_train.columns[23:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols(formula=form, data=pd.concat([indian_ratings['averageRating'], features_indian_train], axis = 1)).fit()\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod2 = smf.ols(formula=form2, data=pd.concat([american_ratings['averageRating'], features_american_train], axis = 1)).fit()\n",
    "mod2.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support-Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the data\n",
    "features_indian_train = (features_indian_train - features_indian_train.mean())/features_indian_train.std()\n",
    "features_american_train = (features_american_train - features_american_train.mean())/features_american_train.std()\n",
    "\n",
    "# drop the 'noir' column from both datasets because of a lack of data\n",
    "features_indian_train.drop('noir', axis = 1, inplace = True)\n",
    "features_american_train.drop('noir', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn import model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_indian = SVR(kernel='linear', C=1.0)\n",
    "svr_indian.fit(features_indian_train, indian_ratings['averageRating'])\n",
    "print('Mean negative squared error : {:.3f}'.format(np.mean(model_selection.cross_val_score(svr_indian, features_indian_train, indian_ratings['averageRating'], scoring = 'neg_mean_squared_error', cv=5))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the feature 'noir' because it always 0 for Indian movies and thus lead to NaN when standardizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(features_indian_train.columns, svr_indian.coef_[0])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Feature weights for Indian Movies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_american = SVR(kernel='linear', C=1.0)\n",
    "svr_american.fit(features_american_train, american_ratings['averageRating'])\n",
    "print('Mean negative squared error : {:.3f}'.format(np.mean(model_selection.cross_val_score(svr_american, features_american_train, american_ratings['averageRating'], scoring = 'neg_mean_squared_error', cv=5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(features_american_train.columns, svr_american.coef_[0])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Feature weights for American Movies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the coefficients\n",
    "svr_indian_coef = (svr_indian.coef_[0] - svr_indian.coef_[0].mean())/svr_indian.coef_[0].std()\n",
    "svr_american_coef = (svr_american.coef_[0] - svr_american.coef_[0].mean())/svr_american.coef_[0].std()\n",
    "\n",
    "df_diff_features = pd.DataFrame({'feature': features_american_train.columns, 'difference': np.abs(svr_indian_coef) - np.abs(svr_american_coef)})\n",
    "\n",
    "# bar plot of the difference in feature weights\n",
    "plt.figure(figsize=(7,10))\n",
    "plt.title('Difference in feature weights between Indian and American movies')\n",
    "sns.barplot(x = 'difference', y = 'feature', data = df_diff_features ,order = df_diff_features.sort_values('difference')['feature'], palette = 'Blues_d')\n",
    "plt.xlim(-1.3, 1.3)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative values indicate features that are more important in predicting IMDb rating in american films than in Indian films, and positive values indicate the opposite.\n",
    "\n",
    "We can see that romance and drama are the genre features that have the biggest impact on IMDb rating in indian films, while horror and adventure have the biggest impact on IMDb rating in american films."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing American and Indian movies in lower dimension spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.append(np.repeat(1, len(features_indian_train)), np.repeat(0, len(features_american_train)))\n",
    "features = pd.concat([features_indian_train, features_american_train], axis = 0)\n",
    "years = np.append(features_indian['movie_release_date'], features_american['movie_release_date'])\n",
    "# standardize the data\n",
    "features = (features - features.mean())/features.std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection, metrics, utils\n",
    "features_shuffled, labels_shuffled, years_shuffled = utils.shuffle(features, labels, years)\n",
    "svc = SVC()\n",
    "train_count = 2500\n",
    "svc.fit(features_shuffled.iloc[:train_count, :], labels_shuffled[:train_count])\n",
    "print('We can predict with an F1-score of {:.3f} if a movie is Indian or American'.format(np.mean(model_selection.cross_val_score(svc, features, labels, scoring = 'f1', cv=5))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This accuracy shows that there is a structure in the data that can be used to predict the country of the movie. We should see this structure in the PCA plot but we don't. Maybe by selecting the most important features we can reveal it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=8)\n",
    "features_red = pca.fit_transform(features)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(features_red[len(features_indian):,0], features_red[len(features_indian):,1], c = 'blue', s=3, alpha = 0.5, label = 'USA')\n",
    "plt.scatter(features_red[:len(features_indian),0], features_red[:len(features_indian),1], c = 'orange', s=3, alpha = 0.5, label = 'India')\n",
    "plt.legend()\n",
    "plt.title('PCA')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=1)\n",
    "features_red_lda = lda.fit_transform(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(range(len(features_red_lda)), features_red_lda[:,0], 'o', markersize=3, c='grey')\n",
    "plt.vlines(x = len(features_indian_train), ymin = min(features_red_lda[:,0]), ymax = max(features_red_lda[:,0]), color = 'red')\n",
    "plt.text(len(features_indian_train)/2, max(features_red_lda[:,0])*0.9, 'India', fontsize=15)\n",
    "plt.text(len(features_indian_train) + (len(features_american_train) - len(features_indian_train))/2, max(features_red_lda[:,0])*0.9, 'USA', fontsize=15)\n",
    "plt.xticks([])\n",
    "plt.title('LDA')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian_year = features_indian.drop(columns=['wikipedia_movie_id', 'averageRating', 'noir']).groupby('movie_release_date').mean()\n",
    "features_american_year = features_american.drop(columns=['wikipedia_movie_id', 'averageRating', 'noir']).groupby('movie_release_date').mean()\n",
    "features_indian_year.rename(columns={'short Film': 'short', 'sci-fi':'scifi'}, inplace=True)\n",
    "features_american_year.rename(columns={'short Film': 'short', 'sci-fi':'scifi'}, inplace=True)\n",
    "\n",
    "#standardize the data\n",
    "features_indian_year = (features_indian_year - features_indian_year.mean())/features_indian_year.std()\n",
    "features_american_year = (features_american_year - features_american_year.mean())/features_american_year.std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series analysis with Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_dist = np.linalg.norm(features_american_year.loc[features_indian_year.index,:] - features_indian_year, axis=1)\n",
    "dist_mod = smf.ols('euclidean_dist ~ features_indian_year.index', data=locals()).fit()\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(features_indian_year.index, euclidean_dist, 'o', markersize=3)\n",
    "plt.plot(features_indian_year.index, dist_mod.predict(), 'r')\n",
    "plt.xlabel('Year\\nR^2 = {:.2f}   p-value = {:.3e}   coef = {:.3f}'.format(dist_mod.rsquared ,dist_mod.f_pvalue, dist_mod.params[1]))\n",
    "plt.ylabel('Euclidean distance')\n",
    "plt.title('Euclidean distance between Indian and American movies features decreases with time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_features_indian_train = pd.concat([features_indian_train.drop(columns='noir').mul(features_indian['averageRating'].values, axis='rows', ), features_indian['movie_release_date']], axis=1)\n",
    "weighted_features_american_train = pd.concat([features_american_train.drop(columns='noir').mul(features_american['averageRating'].values, axis='rows'), features_american['movie_release_date']], axis=1)\n",
    "\n",
    "#group per year\n",
    "weighted_features_indian_train_year = weighted_features_indian_train.groupby('movie_release_date').mean()\n",
    "weighted_features_american_train_year = weighted_features_american_train.groupby('movie_release_date').mean()\n",
    "weighted_features_indian_train_year.rename(columns={'short Film': 'short', 'sci-fi':'scifi'}, inplace=True)\n",
    "weighted_features_american_train_year.rename(columns={'short Film': 'short', 'sci-fi':'scifi'}, inplace=True)\n",
    "\n",
    "#standardize the data\n",
    "weighted_features_indian_train_year = (weighted_features_indian_train_year - weighted_features_indian_train_year.mean())/weighted_features_indian_train_year.std()\n",
    "weighted_features_american_train_year = (weighted_features_american_train_year - weighted_features_american_train_year.mean())/weighted_features_american_train_year.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_dist_weighted = np.linalg.norm(weighted_features_american_train_year.loc[weighted_features_indian_train_year.index,:] - weighted_features_indian_train_year, axis=1)\n",
    "dist_mod_weighted = smf.ols('euclidean_dist_weighted ~ weighted_features_indian_train_year.index', data=locals()).fit()\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(weighted_features_indian_train_year.index, euclidean_dist_weighted, 'o', markersize=3)\n",
    "plt.plot(weighted_features_indian_train_year.index, dist_mod_weighted.predict(), 'r')\n",
    "plt.xlabel('Year\\nR^2 = {:.2f}   p-value = {:.3e}   coef = {:.3f}'.format(dist_mod_weighted.rsquared ,dist_mod_weighted.f_pvalue, dist_mod_weighted.params[1]))\n",
    "plt.ylabel('Euclidean distance')\n",
    "plt.title('Euclidean distance between Indian and American movies features weighted with ratings decreases with time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_features_indian_train_year_genre = weighted_features_indian_train_year.iloc[:,:22]\n",
    "weighted_features_american_train_year_genre = weighted_features_american_train_year.iloc[:,:22]\n",
    "euclidean_dist_weighted_genre = np.linalg.norm(weighted_features_american_train_year_genre.loc[weighted_features_indian_train_year_genre.index,:] - weighted_features_indian_train_year_genre, axis=1)\n",
    "dist_mod_weighted_genre = smf.ols('euclidean_dist_weighted_genre ~ weighted_features_indian_train_year_genre.index', data=locals()).fit()\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(weighted_features_indian_train_year_genre.index, euclidean_dist_weighted_genre, 'o', markersize=3)\n",
    "plt.plot(weighted_features_indian_train_year_genre.index, dist_mod_weighted_genre.predict(), 'r')\n",
    "plt.xlabel('Year\\nR^2 = {:.2f}   p-value = {:.3e}   coef = {:.3f}'.format(dist_mod_weighted_genre.rsquared ,dist_mod_weighted_genre.f_pvalue, dist_mod_weighted_genre.params[1]))\n",
    "plt.ylabel('Euclidean distance')\n",
    "plt.title('Euclidean distance between Indian and American movies genres weighted with ratings decreases with time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_features_indian_train_year_actor = weighted_features_indian_train_year.iloc[:,22:26]\n",
    "weighted_features_american_train_year_actor = weighted_features_american_train_year.iloc[:,22:26]\n",
    "euclidean_dist_weighted_actor = np.linalg.norm(weighted_features_american_train_year_actor.loc[weighted_features_indian_train_year_actor.index,:] - weighted_features_indian_train_year_actor, axis=1)\n",
    "dist_mod_weighted_actor = smf.ols('euclidean_dist_weighted_actor ~ weighted_features_indian_train_year_actor.index', data=locals()).fit()\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(weighted_features_indian_train_year_actor.index, euclidean_dist_weighted_actor, 'o', markersize=3)\n",
    "plt.plot(weighted_features_indian_train_year_actor.index, dist_mod_weighted_actor.predict(), 'r')\n",
    "plt.xlabel('Year\\nR^2 = {:.2f}   p-value = {:.3e}   coef = {:.3f}'.format(dist_mod_weighted_actor.rsquared ,dist_mod_weighted_actor.f_pvalue, dist_mod_weighted_actor.params[1]))\n",
    "plt.ylabel('Euclidean distance')\n",
    "plt.title('Euclidean distance between Indian and American movies actors weighted with ratings decreases with time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_features_indian_train_year_topic = weighted_features_indian_train_year.iloc[:,27:]\n",
    "weighted_features_american_train_year_topic = weighted_features_american_train_year.iloc[:,27:]\n",
    "euclidean_dist_weighted_topic = np.linalg.norm(weighted_features_american_train_year_topic.loc[weighted_features_indian_train_year_topic.index,:] - weighted_features_indian_train_year_topic, axis=1)\n",
    "dist_mod_weighted_topic = smf.ols('euclidean_dist_weighted_topic ~ weighted_features_indian_train_year_topic.index', data=locals()).fit()\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(weighted_features_indian_train_year_topic.index, euclidean_dist_weighted_topic, 'o', markersize=3)\n",
    "plt.plot(weighted_features_indian_train_year_topic.index, dist_mod_weighted_topic.predict(), 'r')\n",
    "plt.xlabel('Year\\nR^2 = {:.2f}   p-value = {:.3e}   coef = {:.3f}'.format(dist_mod_weighted_topic.rsquared ,dist_mod_weighted_topic.f_pvalue, dist_mod_weighted_topic.params[1]))\n",
    "plt.ylabel('Euclidean distance')\n",
    "plt.title('Euclidean distance between Indian and American movies topics weighted with ratings decreases with time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_weighted_features = PCA(n_components=10)\n",
    "pca_weighted_features.fit(pd.concat([weighted_features_indian_train_year, weighted_features_american_train_year]))\n",
    "weighted_features_indian_red = pca_weighted_features.transform(weighted_features_indian_train_year)\n",
    "weighted_features_american_red = pca_weighted_features.transform(weighted_features_american_train_year)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(weighted_features_american_train_year.index, weighted_features_indian_red[:,0], 'o', markersize=3, label = 'India')\n",
    "plt.plot(weighted_features_american_train_year.index, weighted_features_american_red[:,0], 'o', markersize=3, label = 'USA')\n",
    "plt.legend()\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('PCA component 1')\n",
    "plt.title('PCA component 1 between Indian and American movies features weighted with ratings explains {:.2f}% of the variance'.format(pca_weighted_features.explained_variance_ratio_[0]*100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.bar(weighted_features_american_train_year.columns, pca_weighted_features.components_[0])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('?????????????')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : This effect of convergence completely disappears when we don't use the ratings as weights. Moreover the weights are very hardly interpretable here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segregating the genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = features_indian.columns[:22]\n",
    "weighted_reg_genre_data = []\n",
    "w = 1\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "for genre in genres:\n",
    "    weighted_features_indian_train_genre = weighted_features_indian_train.drop(columns='movie_release_date').mul(features_indian[genre], axis='rows')\n",
    "    weighted_features_american_train_genre = weighted_features_american_train.drop(columns='movie_release_date').mul(features_american[genre], axis='rows')\n",
    "\n",
    "    \n",
    "    weighted_features_indian_train_year_genre = weighted_features_indian_train_genre.groupby(features_indian['movie_release_date']).mean()\n",
    "    weighted_features_american_train_year_genre = weighted_features_american_train_genre.groupby(features_indian['movie_release_date']).mean()\n",
    "    \n",
    "    euclidean_dist_weighted_genre = np.linalg.norm(weighted_features_american_train_year_genre.iloc[:,:22] - weighted_features_indian_train_year_genre.iloc[:,:22], axis=1)\n",
    "    euclid_idx = weighted_features_indian_train_year_genre.index[(weighted_features_american_train_year_genre.iloc[:,:22].sum(axis=1) != 0) & (weighted_features_indian_train_year_genre.iloc[:,:22].sum(axis=1) != 0)]\n",
    "    euclidean_dist_weighted_genre = np.delete(euclidean_dist_weighted_genre, (weighted_features_american_train_year_genre.iloc[:,:22].sum(axis=1) == 0) | (weighted_features_indian_train_year_genre.iloc[:,:22].sum(axis=1) == 0))\n",
    "    \n",
    "    \n",
    "    if (sum(features_indian[genre]==1)<100 or sum(features_american[genre]==1)<100):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    if (len(euclid_idx)>1):\n",
    "        plt.subplot(2,4,w)\n",
    "        plt.title(genre)\n",
    "        plt.plot(euclid_idx, euclidean_dist_weighted_genre, 'o', markersize=3)\n",
    "        dist_mod_weighted_genre = smf.ols('euclidean_dist_weighted_genre ~ euclid_idx', data=locals()).fit()\n",
    "        weighted_reg_genre_data.append([genre, dist_mod_weighted_genre.rsquared ,dist_mod_weighted_genre.f_pvalue, dist_mod_weighted_genre.params[1], sum(features_indian[genre]==1), sum(features_american[genre]==1)])\n",
    "\n",
    "        plt.plot(euclid_idx, dist_mod_weighted_genre.predict(), 'r')\n",
    "        plt.xlabel('Year\\nR^2 = {:.2f}   p-value = {:.3e}   coef = {:.3f}'.format(dist_mod_weighted_genre.rsquared ,dist_mod_weighted_genre.f_pvalue, dist_mod_weighted_genre.params[1]))\n",
    "        w+=1\n",
    "    plt.ylabel('Euclidean distance')\n",
    "plt.show()\n",
    "\n",
    "weighted_reg_genre_data = pd.DataFrame(weighted_reg_genre_data, columns=['genre', 'R^2', 'p-value', 'coef', 'India', 'USA'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidean distance between Indian and American movies weighted with ratings decreases with time in all genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_reg_genre_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = features_indian.columns[:22]\n",
    "reg_genre_data = []\n",
    "w = 1\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "for genre in genres:\n",
    "    features_indian_train_genre = features_indian_train.mul(features_indian[genre], axis='rows')\n",
    "    features_american_train_genre = features_american_train.mul(features_american[genre], axis='rows')\n",
    "\n",
    "    features_indian_train_year_genre = features_indian_train_genre.groupby(features_indian['movie_release_date']).mean()\n",
    "    features_american_train_year_genre = features_american_train_genre.groupby(features_indian['movie_release_date']).mean()\n",
    "\n",
    "    euclidean_dist_genre = np.linalg.norm(features_american_train_year_genre.iloc[:,:22] - features_indian_train_year_genre.iloc[:,:22], axis=1)\n",
    "    euclid_idx = features_indian_train_year_genre.index[(features_american_train_year_genre.iloc[:,:22].sum(axis=1) != 0) & (features_indian_train_year_genre.iloc[:,:22].sum(axis=1) != 0)]\n",
    "    euclidean_dist_genre = np.delete(euclidean_dist_genre, (features_american_train_year_genre.iloc[:,:22].sum(axis=1) == 0) | (features_indian_train_year_genre.iloc[:,:22].sum(axis=1) == 0))\n",
    "    \n",
    "    \n",
    "    if (sum(features_indian[genre]==1)<100 or sum(features_american[genre]==1)<100):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    if (len(euclid_idx)>1):\n",
    "        plt.subplot(2,4,w)\n",
    "        plt.title(genre)\n",
    "        plt.plot(euclid_idx, euclidean_dist_genre, 'o', markersize=3)\n",
    "        dist_mod_genre = smf.ols('euclidean_dist_genre ~ euclid_idx', data=locals()).fit()\n",
    "        reg_genre_data.append([genre, dist_mod_genre.rsquared ,dist_mod_genre.f_pvalue, dist_mod_genre.params[1], sum(features_indian[genre]==1), sum(features_american[genre]==1)])\n",
    "\n",
    "        plt.plot(euclid_idx, dist_mod_genre.predict(), 'r')\n",
    "        plt.xlabel('Year\\nR^2 = {:.2f}   p-value = {:.3e}   coef = {:.3f}'.format(dist_mod_genre.rsquared ,dist_mod_genre.f_pvalue, dist_mod_genre.params[1]))\n",
    "        w+=1\n",
    "    plt.ylabel('Euclidean distance')\n",
    "plt.show()\n",
    "\n",
    "reg_genre_data = pd.DataFrame(reg_genre_data, columns=['genre', 'R^2', 'p-value', 'coef', 'India', 'USA'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighting with ratings does not change the trend of the decrease of the euclidean distance between Indian and American movies in all genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_genre_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the american dataset to the same size as the indian dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_american_features_year = pd.DataFrame(index=features_indian_year.index, columns=features_indian_train.columns)\n",
    "for i in features_indian['movie_release_date'].unique():\n",
    "    sampled_american_features_year.loc[i,:] = features_american_train[features_american['movie_release_date']==i].sample(sum(features_indian['movie_release_date']==i)).mean()\n",
    "sampled_american_features_year.dropna(inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_dist_sampled = np.linalg.norm(sampled_american_features_year.to_numpy().astype(float) - features_indian_year.to_numpy().astype(float), axis=1)\n",
    "dist_mod_sampled = smf.ols('euclidean_dist_sampled ~ features_indian_year.index', data=locals()).fit()\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(features_indian_year.index, euclidean_dist_sampled, 'o', markersize=3)\n",
    "plt.plot(features_indian_year.index, dist_mod_sampled.predict(), 'r')\n",
    "plt.xlabel('Year\\nR^2 = {:.2f}   p-value = {:.3e}   coef = {:.3f}'.format(dist_mod_sampled.rsquared ,dist_mod_sampled.f_pvalue, dist_mod_sampled.params[1]))\n",
    "plt.ylabel('Euclidean distance')\n",
    "plt.title('The decreasing distance between Indian and American movies is also kept when we sample American movies to match the number of Indian movies')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the variance is increased when we reduce the number of American movies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series analysis with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "features_indian_year_red = pca.transform(features_indian_year)\n",
    "features_american_year_red = pca.transform(features_american_year)\n",
    "plt.plot(features_indian_year.index, features_indian_year_red[:,0], 'o', markersize=3, c='orange', label = 'India')\n",
    "plt.plot(features_american_year.index, features_american_year_red[:,0], 'o', markersize=3, c='blue', label = 'USA')\n",
    "plt.legend()\n",
    "plt.title('PCA')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('PC1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(features_indian_year_red[:,0], features_indian_year_red[:,1], 'o', markersize=3, c='orange', label = 'India')\n",
    "plt.plot(features_american_year_red[:,0], features_american_year_red[:,1], 'o', markersize=3, c='blue', label = 'USA')\n",
    "plt.legend()\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_features_year = np.abs(pca.transform(features_american_year.loc[features_indian_year.index,:])[:,0] - features_indian_year_red[:,0])\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(features_indian_year.index, diff_features_year, 'o', markersize=3)\n",
    "plt.title('Difference between PC1 of Indian and American movies features across time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('PC1 difference')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series analysis with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "features_indian_year_lda = lda.transform(features_indian_year)\n",
    "features_american_year_lda = lda.transform(features_american_year)\n",
    "plt.plot(features_indian_year.index, features_indian_year_lda[:,0], 'o', markersize=3, c='orange', label = 'India')\n",
    "plt.plot(features_american_year.index, features_american_year_lda[:,0], 'o', markersize=3, c='blue', label = 'USA')\n",
    "plt.legend()\n",
    "plt.title('LDA')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('LDA1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_features_year_lda = np.abs(lda.transform(features_american_year.loc[features_indian_year.index,:])[:,0] - features_indian_year_lda[:,0])\n",
    "lda_mod = smf.ols('diff_features_year_lda ~ features_indian_year.index', data=locals()).fit()\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(features_indian_year.index, diff_features_year_lda, 'o', markersize=3)\n",
    "plt.plot(features_indian_year.index, lda_mod.predict(), 'r')\n",
    "plt.xlabel('Year\\nR^2 = {:.2f}   p-value = {:.3e}   coef = {:.3f}'.format(lda_mod.rsquared ,lda_mod.f_pvalue, lda_mod.params[1]))\n",
    "plt.title('Difference between LDA1 of Indian and American movies features across time')\n",
    "plt.ylabel('LDA1 difference')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of feature importances across 3 periodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts = [1960, 1970, 1980, 1990, 2000, 2005]\n",
    "\n",
    "svr = SVR(kernel='linear', C=1.0)\n",
    "\n",
    "def compute_coefs(feats, rats, cuts):\n",
    "    coefs = np.zeros((len(cuts)+1, feats.shape[1]))\n",
    "    counts=[sum(rats['movie_release_date'] < cuts[0])]\n",
    "    svr.fit(feats.loc[rats['movie_release_date'] < cuts[0] ,:], rats.loc[rats['movie_release_date'] < cuts[0], 'averageRating'])\n",
    "    coefs[0,:] = svr.coef_\n",
    "    for i in range(len(cuts)-1):\n",
    "        svr.fit(feats.loc[(rats['movie_release_date'] >= cuts[i]) & (rats['movie_release_date'] < cuts[i+1]) ,:], rats.loc[(rats['movie_release_date'] >= cuts[i]) & (rats['movie_release_date'] < cuts[i+1]), 'averageRating'])\n",
    "        coefs[i+1,:] = svr.coef_\n",
    "        counts.append(sum((rats['movie_release_date'] >= cuts[i]) & (rats['movie_release_date'] < cuts[i+1])))\n",
    "    svr.fit(feats.loc[rats['movie_release_date'] >= cuts[1] ,:], rats.loc[rats['movie_release_date'] >= cuts[1], 'averageRating'])\n",
    "    coefs[-1,:] = svr.coef_\n",
    "    counts.append(sum(rats['movie_release_date'] >= cuts[1]))\n",
    "    return coefs, counts\n",
    "\n",
    "indian_coef, indian_counts = compute_coefs(features_indian_train, indian_ratings, cuts)\n",
    "american_coef, american_counts = compute_coefs(features_american_train, american_ratings, cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_diff = np.linalg.norm(american_coef - indian_coef, axis=1)\n",
    "x = np.append('1950-'+str(cuts[0]), [str(cuts[i]) + '-' + str(cuts[i+1]) for i in range(len(cuts)-1)])\n",
    "x = np.append(x, str(cuts[-1]) + '-2010')\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(x, coef_diff, markersize=3)\n",
    "plt.title('Euclidean distance in SVR coefficients between Indian and American movies features does not seem to decrease with time')\n",
    "plt.xlabel('Time period')\n",
    "plt.ylabel('Euclidean distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(x, indian_counts, markersize=3, c='orange', label = 'India')\n",
    "plt.plot(x, american_counts, markersize=3, c='blue', label = 'USA')\n",
    "plt.legend()\n",
    "plt.xlabel('Time period')\n",
    "plt.ylabel('Number of movies')\n",
    "plt.title('Number of movies in each time period is very unequal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(x, np.abs(indian_coef-american_coef), markersize=3, label = features_indian_train.columns)\n",
    "plt.xlabel('Time period')\n",
    "plt.ylabel('Absolute difference in SVR coefficients')\n",
    "plt.title('Absolute difference in SVR coefficients between Indian and American movies features does not seem to converge')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87259b15c3afccf059722440ab90a1874d985996384e98fcc7aa5e93528035d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
