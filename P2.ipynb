{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movies Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data description**\n",
    "\n",
    "| Column name          | Description                                                                                                                                                                                       |   |   |   |\n",
    "|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---|---|---|\n",
    "| wikipedia_movie_id | ID of the movie from wikipedia                                                                                                                                                 |   |   |   |\n",
    "| freebase_movie_id| ID of the movie from freebas                                                                                                                                            |   |   |   |\n",
    "| movie_name | Name of the movie                                                                                                                                                |   |   |   |\n",
    "| movie_release_date  | Date the movie was released                                                                                                                                      |   |   |   |\n",
    "| movie_box_office_revenue  | Revenue of the movie box office                                                                                                                           \n",
    "| movie_runtime  | Run time of the movie                                                                                                                                                 |   |   |   |\n",
    "| movie_languages | Languages of the movie                                                                                                                                                  |   |   |   |\n",
    "| movie_countries | Countries where the movie were created                                                                                                                                  |   |   |   |\n",
    "| movie_genres   | Genre of the movie                                                                                                                                              |   |   |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movie data set contains 81741 rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/'\n",
    "\n",
    "names = ['wikipedia_movie_id','freebase_movie_id', 'movie_name', 'movie_release_date', 'movie_box_office_revenue', \n",
    "        'movie_runtime', 'movie_languages', 'movie_countries', 'movie_genres']\n",
    "\n",
    "movies_data = pd.read_csv(data_folder + 'movie.metadata.tsv', names = names, sep = '\\t', )\n",
    "\n",
    "movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']]= movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].applymap(lambda x: str.lower(x))\n",
    "\n",
    "movies_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_movies = movies_data[movies_data['movie_countries'] == '{\"/m/03rk0\": \"india\"}']\n",
    "\n",
    "american_movies = movies_data[movies_data['movie_countries'] == '{\"/m/09c7w0\": \"united states of america\"}']\n",
    "\n",
    "print(len(indian_movies), len(american_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see that movie_box_office_revenue column contain loads of missing data in both indian and american movies, followed by movie runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our indian and american movies data base both do not contain any duplicates on either wikipedia movie ID nor freebase ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('wiki ID, indian: ', len(indian_movies.drop_duplicates('wikipedia_movie_id')), '\\nfreebase ID, indian: ', len(indian_movies.drop_duplicates('freebase_movie_id')))\n",
    "print('wiki ID, american: ', len(american_movies.drop_duplicates('wikipedia_movie_id')), '\\nfreebase ID, american: ', len(american_movies.drop_duplicates('freebase_movie_id')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characters data\n",
    "\n",
    "450'668 characters in raw data\n",
    "\n",
    "134079 differents actor \n",
    "\n",
    "5794 differents actor in indian movies\n",
    "\n",
    "59398 differents actors in american movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['wikipedia_movie_id', 'freebase_movie_id', 'movie_release_date', 'character_name', 'actor_dob', 'actor_gender', 'actor_height', 'actor_ethnicity', 'actor_name', 'actor_age_at_movie_release', 'char_act_id', 'freebase_character_id', 'freebase_actor_id']\n",
    "characters_data = pd.read_csv(data_folder + 'character.metadata.tsv', names = names, sep = '\\t')\n",
    "\n",
    "characters_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_data[['character_name', 'actor_name']] = characters_data[['character_name', 'actor_name']].applymap(lambda x: x if type(x)!=str else x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_american_actor = characters_data[characters_data['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])].drop_duplicates('actor_name')\n",
    "unique_indian_actor = characters_data[characters_data['wikipedia_movie_id'].isin(indian_movies['wikipedia_movie_id'])].drop_duplicates('actor_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_american_actor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_character =characters_data[characters_data['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])]\n",
    "american_character =characters_data[characters_data['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name clusters data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['character_name', 'actor_reference']\n",
    "name_clusters_data = pd.read_csv(data_folder + 'name.clusters.txt', names = names, sep = '\\t', )\n",
    "\n",
    "name_clusters_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tvtropes clusters data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvt_rope = pd.read_csv(data_folder + 'tvtropes.clusters.txt', sep='\\t', names= ['character_type', 'instances'])\n",
    "\n",
    "print(len(tvt_rope))\n",
    "tvt_rope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvt_rope['instances'] = tvt_rope['instances'].str.replace('{','').str.replace('}', '').str.replace('\"', '')\n",
    "\n",
    "split_tvt = tvt_rope.copy()\n",
    "\n",
    "split_tvt = tvt_rope['instances'].str.split('[,:]', expand=True)\n",
    "\n",
    "cleaned_tvt = split_tvt.rename(columns={split_tvt.columns[1]: 'character_name', split_tvt.columns[3]: 'movie_name', split_tvt.columns[5]: 'char_act_id',split_tvt.columns[7]: 'actor_name'})\n",
    "\n",
    "cleaned_tvt = cleaned_tvt.drop(columns=[0,2,4,6,8,9,10])\n",
    "\n",
    "characters = tvt_rope.character_type\n",
    "\n",
    "final_tvt = cleaned_tvt.join(characters, how= 'left')\n",
    "\n",
    "final_tvt[['character_name', 'movie_name', 'actor_name', 'character_type']] = final_tvt[['character_name', 'movie_name', 'actor_name', 'character_type']].applymap(lambda x: str.casefold(x))\n",
    "\n",
    "final_tvt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_actors = unique_american_actor.copy()\n",
    "american_actors['actor_name'] = unique_american_actor['actor_name'].astype('str')\n",
    "\n",
    "american_actors = american_actors['actor_name']\n",
    "\n",
    "final_tvt.actor_name = final_tvt.actor_name.dropna()\n",
    "\n",
    "american_tvt = final_tvt.merge(american_actors, on = 'actor_name')\n",
    "\n",
    "american_tvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_tvt2 = final_tvt[final_tvt['actor_name'].isin(unique_american_actor['actor_name'])]\n",
    "\n",
    "american_tvt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_tvt2 = final_tvt[final_tvt['movie_name'].isin(american_movies['movie_name'])]\n",
    "\n",
    "american_tvt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87259b15c3afccf059722440ab90a1874d985996384e98fcc7aa5e93528035d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
