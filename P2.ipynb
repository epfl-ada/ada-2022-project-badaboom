{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the recipe for the perfect movie in **BOLLYWOOD** vs. in **HOLLYWOOD**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMU dataset\n",
    "\n",
    "| Column name          | Description                                                                                                                                                                                       |   |   |   |\n",
    "|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---|---|---|\n",
    "| wikipedia_movie_id | ID of the movie from wikipedia                                                                                                                                                 |   |   |   |\n",
    "| freebase_movie_id| ID of the movie from freebas                                                                                                                                            |   |   |   |\n",
    "| movie_name | Name of the movie                                                                                                                                                |   |   |   |\n",
    "| movie_release_date  | Date the movie was released                                                                                                                                      |   |   |   |\n",
    "| movie_box_office_revenue  | Revenue of the movie box office                                                                                                                           \n",
    "| movie_runtime  | Run time of the movie                                                                                                                                                 |   |   |   |\n",
    "| movie_languages | Languages of the movie                                                                                                                                                  |   |   |   |\n",
    "| movie_countries | Countries where the movie were created                                                                                                                                  |   |   |   |\n",
    "| movie_genres   | Genre of the movie                                                                                                                                              |   |   |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movie data set contains 81741 rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/'\n",
    "\n",
    "names = ['wikipedia_movie_id','freebase_movie_id', 'movie_name', 'movie_release_date', 'movie_box_office_revenue', \n",
    "        'movie_runtime', 'movie_languages', 'movie_countries', 'movie_genres']\n",
    "\n",
    "movies_data = pd.read_csv(data_folder + 'movie.metadata.tsv', names = names, sep = '\\t', )\n",
    "\n",
    "movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']]= movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].applymap(lambda x: str.lower(x))\n",
    "\n",
    "movies_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMdb datasets (ratings, runtimes, isAdult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating files loading\n",
    "ratings = pd.read_csv(data_folder + 'title.ratings.tsv.gz', sep='\\t', compression='gzip')\n",
    "titles = pd.read_csv(data_folder + 'title.basics.tsv.gz', sep='\\t', compression='gzip')\n",
    "\n",
    "#removing tv episodes that are not included in CMU dataset\n",
    "titles=titles[titles['titleType'] != 'tvEpisode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMdb and CMU datasets merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging IMdb dataset with title, isAdult and runtimeMinutes with dataset with averageRating on movie ID (tconst)\n",
    "rates = titles.merge(ratings, how='left', on='tconst')[['averageRating', 'numVotes', 'originalTitle', 'isAdult', 'runtimeMinutes']]\n",
    "\n",
    "#putting all titles to lower case to match the CMU dataset movie names and dropping column with upper cases\n",
    "rates['movie_name'] = [ele.lower() for ele in rates['originalTitle'].astype(str)]\n",
    "rates=rates.drop(columns='originalTitle')\n",
    "\n",
    "#dropping all rows that have a movie name appearing multiple times so the merging on movie name with the CMU dataset is precise\n",
    "rates = rates.drop_duplicates('movie_name', keep=False)\n",
    "\n",
    "#converting runtimeMinutes to float and changing '\\\\N' to NaN to match the format in CMU dataset\n",
    "rates['runtimeMinutes']=list(map(lambda x: float(x) if x!='\\\\N' else None , rates['runtimeMinutes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging CMU dataset with the IMdb dataset\n",
    "movies_data_merged = movies_data.merge(rates, how = 'left', on='movie_name')\n",
    "\n",
    "#completing the NaN values in movie_runtime of the CMU dataset with the available ones of the IMdb dataset.\n",
    "#we trust more the CMU dataset than the IMdb one so we give priority to the runtime values of the CMU dataset\n",
    "# to the IMdb ones and use the IMdb only if the value is missing in the CMU.\n",
    "#finally we drop the column with the IMdb runtimes.\n",
    "movies_data_merged.loc[movies_data_merged['movie_runtime'].isna(), 'movie_runtime']=movies_data_merged.loc[movies_data_merged['movie_runtime'].isna(), 'runtimeMinutes']\n",
    "movies_data_merged=movies_data_merged.drop(columns='runtimeMinutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally creating the datasets with all indian movies and all american movies\n",
    "indian_movies = movies_data_merged[movies_data_merged['movie_countries'] == '{\"/m/03rk0\": \"india\"}'].reset_index()\n",
    "american_movies = movies_data_merged[movies_data_merged['movie_countries'] == '{\"/m/09c7w0\": \"united states of america\"}'].reset_index()\n",
    "\n",
    "print('There are %d indian films and %d american films in the dataset' % (len(indian_movies), len(american_movies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the movie box office revenue if very often unavailable and present in very limited number in both datasets. Thus we probably won't further use it.\n",
    "\n",
    "The informations merged from the IMdb dataset (averageRating, numVotes and isAdult) are available in almost the half of the dataset which makes them still usable despite an important loss of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some global infos about ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.3f percent of indian movies have a rating and %.3f percent of american movies have a rating' %\n",
    "(100-np.sum(indian_movies['averageRating'].isna())/indian_movies.shape[0]*100, 100-np.sum(american_movies['averageRating'].isna())/american_movies.shape[0]*100))\n",
    "\n",
    "print('Average rating of indian movies : %.3f \\tAverage rating of american movies : %.3f' %\n",
    "(np.mean(indian_movies['averageRating']), np.mean(american_movies['averageRating'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions of movie ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "sns.histplot(x='averageRating', data=american_movies, alpha=0.5, bins=25, label='American')\n",
    "sns.histplot(x='averageRating', data=indian_movies, alpha=0.5, bins=25, color='orange', label='Indian')\n",
    "plt.title('Distribution of movies ratings')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('P-value for normality test of american ratings : %.3f \\tP-value for normality test of indian ratings : %.3f ' \n",
    "      % (st.normaltest(american_movies['averageRating'], nan_policy='omit').pvalue, st.normaltest(indian_movies['averageRating'], nan_policy='omit').pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indian and american movies get similar distributions of ratings. This will allow us to use more easily the ratings as an unbiased tool to estimate the success of a movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of number of votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "#creating adapted bins for log-log plot\n",
    "hist1, bins1 = np.histogram(indian_movies['numVotes'].dropna(), bins=30)\n",
    "logbins1 = np.logspace(np.log10(bins1[0]),np.log10(bins1[-1]),len(bins1))\n",
    "hist2, bins2 = np.histogram(american_movies['numVotes'].dropna(), bins=40)\n",
    "logbins2 = np.logspace(np.log10(bins2[0]),np.log10(bins2[-1]),len(bins2))\n",
    "\n",
    "#plotting\n",
    "plt.hist(american_movies['numVotes'], bins=logbins2, label='American', alpha =.5)\n",
    "plt.hist(indian_movies['numVotes'], bins=logbins1, label='Indian', alpha=.5)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of votes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('American movies get more votes than Indians')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centering the data around each means for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#center data on mean\n",
    "indian_movies.loc[:,'centeredRating']=indian_movies['averageRating'].copy()-np.mean(indian_movies['averageRating'])\n",
    "american_movies.loc[:,'centeredRating']=american_movies['averageRating'].copy()-np.mean(american_movies['averageRating'])\n",
    "print('Centered average rating of indian movies : %.3f \\tCentered average rating of american movies : %.3f' %\n",
    "(np.mean(indian_movies['centeredRating']), np.mean(american_movies['centeredRating'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtimes analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some global infos about runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.3f percent of indian movies have a runtime and %.3f percent of american movies have a runtime' %\n",
    "(100-np.sum(indian_movies['movie_runtime'].isna())/indian_movies.shape[0]*100, 100-np.sum(american_movies['movie_runtime'].isna())/american_movies.shape[0]*100))\n",
    "\n",
    "print('Average runtime of indian movies : %.3f \\tAverage runtime of american movies : %.3f' %\n",
    "(indian_movies['movie_runtime'].mean(), american_movies['movie_runtime'].mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of movie runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining number of bins to get roughly equal width between the 2 histograms\n",
    "b = 75\n",
    "b2 = int(b*indian_movies['movie_runtime'].max()/american_movies['movie_runtime'].drop(index=np.argmax(american_movies['movie_runtime'])).max())\n",
    "\n",
    "#plotting\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(american_movies['movie_runtime'].drop(index=np.argmax(american_movies['movie_runtime'])), density=True, bins = b, alpha = 0.4, label='american')\n",
    "plt.hist(indian_movies['movie_runtime'], density=True, bins = b2, alpha=.4, label='indian')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('minutes')\n",
    "plt.ylabel('frequency')\n",
    "plt.title(f'Distribution of runtimes (outlier of removed)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : We found an outlier in the runtimes coming from the CMU dataset of a film of more than 1 million minutes. We think that this outlier is due to an error of the people that made the CMU dataset so we can reasonably remove it from our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the high density range of runtimes (0 to 500 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced datasets with movies that have a runtime <500 min\n",
    "runred_indian = indian_movies[indian_movies['movie_runtime']<500]\n",
    "runred_american = american_movies[american_movies['movie_runtime']<500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining number of bins to get roughly equal width between the 2 histograms\n",
    "b = 50\n",
    "b2 = int(b*indian_movies['movie_runtime'].max()/american_movies['movie_runtime'].drop(index=np.argmax(american_movies['movie_runtime'])).max())\n",
    "\n",
    "#plotting\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(runred_indian['movie_runtime'], density=True, bins = b2, alpha=.4, label='indian')\n",
    "plt.hist(runred_american['movie_runtime'].drop(np.argmax(runred_american['movie_runtime'])), density=True, bins = b, alpha = 0.4, label='american')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('minutes')\n",
    "plt.ylabel('frequency')\n",
    "plt.title(f'Distribution of runtimes (zoom on films between 0 and 500 minutes)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that indian movies have a tendancy to be slightly longer by ~20 minutes. It would be interesting to further study if this tendancy comes from recent movies or more older ones. Do we tend to a global equilibrium in the runtimes between indian and american movies revealing a standardization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indian = indian_movies.copy()\n",
    "#remove {}\n",
    "test_indian['cleared_movie_genres'] = test_indian['movie_genres'].str[1:-1]\n",
    "#remove films without genre\n",
    "test_indian = test_indian.query(\"cleared_movie_genres != ''\")\n",
    "\n",
    "test_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all genres\n",
    "all_genres_listed_indian = test_indian['cleared_movie_genres'].str.split(pat=\",\")\n",
    "#all_genres_listed_indian=[ele[0].split(':') for ele in all_genres_listed_indian]\n",
    "ls = []\n",
    "for i in all_genres_listed_indian:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_genres_indian = pd.Series(ls)\n",
    "all_genres_indian = all_genres_indian.str.strip().value_counts()\n",
    "all_genres_indian.index = [ele.split(':')[1] for ele in all_genres_indian.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting taking the first 50 genres\n",
    "first_genres_indian = all_genres_indian[:50]\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(y = first_genres_indian.index, x = first_genres_indian).set_title('Movie genres apparition in indian movies')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_american = american_movies.copy()\n",
    "#remove {}\n",
    "test_american['cleared_movie_genres'] = test_american['movie_genres'].str[1:-1]\n",
    "#remove films without genre\n",
    "test_american = test_american.query(\"cleared_movie_genres != ''\")\n",
    "test_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all genres\n",
    "all_genres_listed_american = test_american['cleared_movie_genres'].str.split(pat=\",\")\n",
    "#all_genres_listed_american=[ele[0].split(':') for ele in all_genres_listed_american]\n",
    "\n",
    "ls = []\n",
    "for i in all_genres_listed_american:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_genres_american = pd.Series(ls)\n",
    "all_genres_american = all_genres_american.str.strip().value_counts()\n",
    "all_genres_american.index=[ele.split(':')[1] for ele in all_genres_american.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting taking the first 50 genres\n",
    "first_genres_american = all_genres_american[:50]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(y = first_genres_american.index, x = first_genres_american).set_title('Movie genres apparition in American movies')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres_american_frequency = all_genres_american/len(american_movies)\n",
    "first_genres_american_frequency = all_genres_american_frequency[:50]\n",
    "all_genres_indian_frequency = all_genres_indian/len(indian_movies)\n",
    "first_genres_indian_frequency = all_genres_indian_frequency[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting taking the first 50 genres\n",
    "fig, ax = plt.subplots(1,2,figsize=(10, 16),sharex = True, constrained_layout=True)\n",
    "fig.suptitle('Movie genres frequency in american and indian films')\n",
    "ax[0].set_title('America')\n",
    "ax[1].set_title('India')\n",
    "sns.barplot(ax = ax[0],y = first_genres_american_frequency.index, x = first_genres_american_frequency, label=\"American\", color=\"b\")\n",
    "\n",
    "sns.barplot(ax = ax[1], y = first_genres_indian_frequency.index, x = first_genres_indian_frequency, label=\"Indian\", color=\"r\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our indian and american movies data base both do not contain any duplicates on either wikipedia movie ID nor freebase ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('wiki ID, indian: ', len(indian_movies.drop_duplicates('wikipedia_movie_id')), '\\nfreebase ID, indian: ', len(indian_movies.drop_duplicates('freebase_movie_id')))\n",
    "print('wiki ID, american: ', len(american_movies.drop_duplicates('wikipedia_movie_id')), '\\nfreebase ID, american: ', len(american_movies.drop_duplicates('freebase_movie_id')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characters data\n",
    "\n",
    "450'668 characters in raw data\n",
    "\n",
    "134079 differents actor \n",
    "\n",
    "5794 differents actor in indian movies\n",
    "\n",
    "59398 differents actors in american movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['wikipedia_movie_id', 'freebase_movie_id', 'movie_release_date', 'character_name', 'actor_dob', 'actor_gender', 'actor_height', 'actor_ethnicity', 'actor_name', 'actor_age_at_movie_release', 'char_act_id', 'freebase_character_id', 'freebase_actor_id']\n",
    "characters_data = pd.read_csv(data_folder + 'character.metadata.tsv', names = names, sep = '\\t')\n",
    "\n",
    "characters_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_data[['character_name', 'actor_name']] = characters_data[['character_name', 'actor_name']].applymap(lambda x: x if type(x)!=str else x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_american_actor = characters_data[characters_data['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])].drop_duplicates('actor_name')\n",
    "unique_indian_actor = characters_data[characters_data['wikipedia_movie_id'].isin(indian_movies['wikipedia_movie_id'])].drop_duplicates('actor_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_american_actor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_character =characters_data[characters_data['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])]\n",
    "american_character =characters_data[characters_data['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name clusters data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['character_name', 'actor_reference']\n",
    "name_clusters_data = pd.read_csv(data_folder + 'name.clusters.txt', names = names, sep = '\\t', )\n",
    "\n",
    "name_clusters_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tvtropes clusters data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvt_rope = pd.read_csv(data_folder + 'tvtropes.clusters.txt', sep='\\t', names= ['character_type', 'instances'])\n",
    "\n",
    "print(len(tvt_rope))\n",
    "tvt_rope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvt_rope['instances'] = tvt_rope['instances'].str.replace('{','').str.replace('}', '').str.replace('\"', '')\n",
    "\n",
    "split_tvt = tvt_rope.copy()\n",
    "\n",
    "split_tvt = tvt_rope['instances'].str.split('[,:]', expand=True)\n",
    "\n",
    "cleaned_tvt = split_tvt.rename(columns={split_tvt.columns[1]: 'character_name', split_tvt.columns[3]: 'movie_name', split_tvt.columns[5]: 'char_act_id',split_tvt.columns[7]: 'actor_name'})\n",
    "\n",
    "cleaned_tvt = cleaned_tvt.drop(columns=[0,2,4,6,8,9,10])\n",
    "\n",
    "characters = tvt_rope.character_type\n",
    "\n",
    "final_tvt = cleaned_tvt.join(characters, how= 'left')\n",
    "\n",
    "final_tvt[['character_name', 'movie_name', 'actor_name', 'character_type']] = final_tvt[['character_name', 'movie_name', 'actor_name', 'character_type']].applymap(lambda x: str.casefold(x))\n",
    "\n",
    "final_tvt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_actors = unique_american_actor.copy()\n",
    "american_actors['actor_name'] = unique_american_actor['actor_name'].astype('str')\n",
    "\n",
    "american_actors = american_actors['actor_name']\n",
    "\n",
    "final_tvt.actor_name = final_tvt.actor_name.dropna()\n",
    "\n",
    "american_tvt = final_tvt.merge(american_actors, on = 'actor_name')\n",
    "\n",
    "american_tvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_tvt2 = final_tvt[final_tvt['actor_name'].isin(unique_american_actor['actor_name'])]\n",
    "\n",
    "american_tvt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_tvt2 = final_tvt[final_tvt['movie_name'].isin(american_movies['movie_name'])]\n",
    "\n",
    "american_tvt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = pd.read_csv(data_folder + 'plot_summaries.txt', sep = '\\r', names = ['summaries'])\n",
    "summaries = summaries['summaries'].str.split(\"\\t\", expand = True)\n",
    "summaries = summaries.rename(columns= {0:'wikipedia_movie_id',1: 'summaries'})\n",
    "summaries['summaries'] = summaries['summaries'].str.lower()\n",
    "summaries['wikipedia_movie_id'] = summaries['wikipedia_movie_id'].astype(int)\n",
    "summaries.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_summaries = summaries[summaries['wikipedia_movie_id'].isin(indian_movies['wikipedia_movie_id'])]\n",
    "indian_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_summaries = summaries[summaries['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])]\n",
    "american_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_separated_words = indian_summaries['summaries'].str.split()\n",
    "\n",
    "ls = []\n",
    " \n",
    "for i in indian_separated_words:\n",
    "    ls.extend(i)\n",
    "\n",
    "indian_separated_words = pd.Series(ls)\n",
    "indian_separated_words = indian_separated_words[indian_separated_words.str.len() > 4]\n",
    "indian_separated_words = indian_separated_words.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_separated_words = indian_separated_words[:100]\n",
    "f, ax = plt.subplots(figsize=(6, 20))\n",
    "sns.barplot(y = indian_separated_words.index, x = indian_separated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_separated_words = american_summaries['summaries'].str.split()\n",
    "\n",
    "ls = []\n",
    " \n",
    "for i in american_separated_words:\n",
    "    ls.extend(i)\n",
    "\n",
    "    \n",
    "american_separated_words = pd.Series(ls)\n",
    "american_separated_words = american_separated_words[american_separated_words.str.len() > 4]\n",
    "american_separated_words = american_separated_words.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_separated_words = american_separated_words[:100]\n",
    "f, ax = plt.subplots(figsize=(6, 20))\n",
    "sns.barplot(y = american_separated_words.index, x = american_separated_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6ff92366812eff0585597bdff8203f3dca47fc152c7f8518e1cf16bc394b74b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
