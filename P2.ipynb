{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movies Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data description**\n",
    "\n",
    "| Column name          | Description                                                                                                                                                                                       |   |   |   |\n",
    "|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---|---|---|\n",
    "| wikipedia_movie_id | ID of the movie from wikipedia                                                                                                                                                 |   |   |   |\n",
    "| freebase_movie_id| ID of the movie from freebas                                                                                                                                            |   |   |   |\n",
    "| movie_name | Name of the movie                                                                                                                                                |   |   |   |\n",
    "| movie_release_date  | Date the movie was released                                                                                                                                      |   |   |   |\n",
    "| movie_box_office_revenue  | Revenue of the movie box office                                                                                                                           \n",
    "| movie_runtime  | Run time of the movie                                                                                                                                                 |   |   |   |\n",
    "| movie_languages | Languages of the movie                                                                                                                                                  |   |   |   |\n",
    "| movie_countries | Countries where the movie were created                                                                                                                                  |   |   |   |\n",
    "| movie_genres   | Genre of the movie                                                                                                                                              |   |   |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movie data set contains 81741 rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/'\n",
    "\n",
    "names = ['wikipedia_movie_id','freebase_movie_id', 'movie_name', 'movie_release_date', 'movie_box_office_revenue', \n",
    "        'movie_runtime', 'movie_languages', 'movie_countries', 'movie_genres']\n",
    "\n",
    "movies_data = pd.read_csv(data_folder + 'movie.metadata.tsv', names = names, sep = '\\t', )\n",
    "\n",
    "movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']]= movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].applymap(lambda x: str.lower(x))\n",
    "\n",
    "movies_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_movies = movies_data[movies_data['movie_countries'] == '{\"/m/03rk0\": \"india\"}']\n",
    "\n",
    "american_movies = movies_data[movies_data['movie_countries'] == '{\"/m/09c7w0\": \"united states of america\"}']\n",
    "\n",
    "print(len(indian_movies), len(american_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indian = indian_movies.copy()\n",
    "#remove {}\n",
    "test_indian['cleared_movie_genres'] = test_indian['movie_genres'].str[1:-1]\n",
    "#remove films without genre\n",
    "test_indian = test_indian.query(\"cleared_movie_genres != ''\")\n",
    "\n",
    "test_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all genres\n",
    "all_genres_listed_indian = test_indian['cleared_movie_genres'].str.split(pat=\",\")\n",
    "\n",
    "ls = []\n",
    "for i in all_genres_listed_indian:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_genres_indian = pd.Series(ls)\n",
    "all_genres_indian = all_genres_indian.str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting taking the first 50 genres\n",
    "first_genres_indian = all_genres_indian[:50]\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(y = first_genres_indian.index, x = first_genres_indian).set_title('Movie genres apparition in indian movies')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_american = american_movies.copy()\n",
    "#remove {}\n",
    "test_american['cleared_movie_genres'] = test_american['movie_genres'].str[1:-1]\n",
    "#remove films without genre\n",
    "test_american = test_american.query(\"cleared_movie_genres != ''\")\n",
    "test_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all genres\n",
    "all_genres_listed_american = test_american['cleared_movie_genres'].str.split(pat=\",\")\n",
    "\n",
    "ls = []\n",
    "for i in all_genres_listed_american:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_genres_american = pd.Series(ls)\n",
    "all_genres_american = all_genres_american.str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting taking the first 50 genres\n",
    "first_genres_american = all_genres_american[:50]\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(y = first_genres_american.index, x = first_genres_american).set_title('Movie genres apparition in American movies')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres_american_frequency = all_genres_american/all_genres_american.sum()\n",
    "first_genres_american_frequency = all_genres_american_frequency[:50]\n",
    "all_genres_indian_frequency = all_genres_indian/all_genres_indian.sum()\n",
    "first_genres_indian_frequency = all_genres_indian_frequency[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting taking the first 50 genres\n",
    "fig, ax = plt.subplots(1,2,figsize=(10, 16),sharex = True, constrained_layout=True)\n",
    "fig.suptitle('Movie genres frequency in american and indian films')\n",
    "ax[0].set_title('America')\n",
    "ax[1].set_title('India')\n",
    "sns.barplot(ax = ax[0],y = first_genres_american_frequency.index, x = first_genres_american_frequency, label=\"American\", color=\"b\")\n",
    "\n",
    "sns.barplot(ax = ax[1], y = first_genres_indian_frequency.index, x = first_genres_indian_frequency, label=\"Indian\", color=\"r\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see that movie_box_office_revenue column contain loads of missing data in both indian and american movies, followed by movie runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our indian and american movies data base both do not contain any duplicates on either wikipedia movie ID nor freebase ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('wiki ID, indian: ', len(indian_movies.drop_duplicates('wikipedia_movie_id')), '\\nfreebase ID, indian: ', len(indian_movies.drop_duplicates('freebase_movie_id')))\n",
    "print('wiki ID, american: ', len(american_movies.drop_duplicates('wikipedia_movie_id')), '\\nfreebase ID, american: ', len(american_movies.drop_duplicates('freebase_movie_id')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characters data\n",
    "\n",
    "450'668 characters in raw data\n",
    "\n",
    "134079 differents actor \n",
    "\n",
    "5794 differents actor in indian movies\n",
    "\n",
    "59398 differents actors in american movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['wikipedia_movie_id', 'freebase_movie_id', 'movie_release_date', 'character_name', 'actor_dob', 'actor_gender', 'actor_height', 'actor_ethnicity', 'actor_name', 'actor_age_at_movie_release', 'char_act_id', 'freebase_character_id', 'freebase_actor_id']\n",
    "characters_data = pd.read_csv(data_folder + 'character.metadata.tsv', names = names, sep = '\\t')\n",
    "\n",
    "characters_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_data[['character_name', 'actor_name']] = characters_data[['character_name', 'actor_name']].applymap(lambda x: x if type(x)!=str else x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_american_actor = characters_data[characters_data['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])].drop_duplicates('actor_name')\n",
    "unique_indian_actor = characters_data[characters_data['wikipedia_movie_id'].isin(indian_movies['wikipedia_movie_id'])].drop_duplicates('actor_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_american_actor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_character =characters_data[characters_data['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])]\n",
    "american_character =characters_data[characters_data['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name clusters data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['character_name', 'actor_reference']\n",
    "name_clusters_data = pd.read_csv(data_folder + 'name.clusters.txt', names = names, sep = '\\t', )\n",
    "\n",
    "name_clusters_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tvtropes clusters data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvt_rope = pd.read_csv(data_folder + 'tvtropes.clusters.txt', sep='\\t', names= ['character_type', 'instances'])\n",
    "\n",
    "print(len(tvt_rope))\n",
    "tvt_rope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvt_rope['instances'] = tvt_rope['instances'].str.replace('{','').str.replace('}', '').str.replace('\"', '')\n",
    "\n",
    "split_tvt = tvt_rope.copy()\n",
    "\n",
    "split_tvt = tvt_rope['instances'].str.split('[,:]', expand=True)\n",
    "\n",
    "cleaned_tvt = split_tvt.rename(columns={split_tvt.columns[1]: 'character_name', split_tvt.columns[3]: 'movie_name', split_tvt.columns[5]: 'char_act_id',split_tvt.columns[7]: 'actor_name'})\n",
    "\n",
    "cleaned_tvt = cleaned_tvt.drop(columns=[0,2,4,6,8,9,10])\n",
    "\n",
    "characters = tvt_rope.character_type\n",
    "\n",
    "final_tvt = cleaned_tvt.join(characters, how= 'left')\n",
    "\n",
    "final_tvt[['character_name', 'movie_name', 'actor_name', 'character_type']] = final_tvt[['character_name', 'movie_name', 'actor_name', 'character_type']].applymap(lambda x: str.casefold(x))\n",
    "\n",
    "final_tvt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_actors = unique_american_actor.copy()\n",
    "american_actors['actor_name'] = unique_american_actor['actor_name'].astype('str')\n",
    "\n",
    "american_actors = american_actors['actor_name']\n",
    "\n",
    "final_tvt.actor_name = final_tvt.actor_name.dropna()\n",
    "\n",
    "american_tvt = final_tvt.merge(american_actors, on = 'actor_name')\n",
    "\n",
    "american_tvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_tvt2 = final_tvt[final_tvt['actor_name'].isin(unique_american_actor['actor_name'])]\n",
    "\n",
    "american_tvt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_tvt2 = final_tvt[final_tvt['movie_name'].isin(american_movies['movie_name'])]\n",
    "\n",
    "american_tvt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = pd.read_csv(data_folder + 'plot_summaries.txt', sep = '\\r', names = ['summaries'])\n",
    "summaries = summaries['summaries'].str.split(\"\\t\", expand = True)\n",
    "summaries = summaries.rename(columns= {0:'wikipedia_movie_id',1: 'summaries'})\n",
    "summaries['summaries'] = summaries['summaries'].str.lower()\n",
    "summaries['wikipedia_movie_id'] = summaries['wikipedia_movie_id'].astype(int)\n",
    "summaries.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_summaries = summaries[summaries['wikipedia_movie_id'].isin(indian_movies['wikipedia_movie_id'])]\n",
    "indian_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_summaries = summaries[summaries['wikipedia_movie_id'].isin(american_movies['wikipedia_movie_id'])]\n",
    "american_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_separated_words = indian_summaries['summaries'].str.split()\n",
    "\n",
    "ls = []\n",
    " \n",
    "for i in indian_separated_words:\n",
    "    ls.extend(i)\n",
    "\n",
    "indian_separated_words = pd.Series(ls)\n",
    "indian_separated_words = indian_separated_words[indian_separated_words.str.len() > 4]\n",
    "indian_separated_words = indian_separated_words.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_separated_words = indian_separated_words[:100]\n",
    "f, ax = plt.subplots(figsize=(6, 20))\n",
    "sns.barplot(y = indian_separated_words.index, x = indian_separated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_separated_words = american_summaries['summaries'].str.split()\n",
    "\n",
    "ls = []\n",
    " \n",
    "for i in american_separated_words:\n",
    "    ls.extend(i)\n",
    "\n",
    "    \n",
    "american_separated_words = pd.Series(ls)\n",
    "american_separated_words = american_separated_words[american_separated_words.str.len() > 4]\n",
    "american_separated_words = american_separated_words.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_separated_words = american_separated_words[:100]\n",
    "f, ax = plt.subplots(figsize=(6, 20))\n",
    "sns.barplot(y = american_separated_words.index, x = american_separated_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91b5001b16508dda0f4f92aa6e63c44b5fe55e6bf8f18d5f0cedbd82e7669dbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
