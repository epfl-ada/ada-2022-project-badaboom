{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy.stats as st\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "\n",
    "# Run in python console\n",
    "import nltk; nltk.download('stopwords')\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the recipe for the perfect movie in **BOLLYWOOD** vs. in **HOLLYWOOD**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the loading, we do a simple pre-processing work where we remove punctuation and capitalization from words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie metadata\n",
    "This dataset contains the basics informations of differents movies. Here, you have the name of the differents informations and their definition.\n",
    "\n",
    "| Column name          | Description                                                                                                                                                                                       |\n",
    "|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| wikipedia_movie_id | ID of the movie from wikipedia                                                                                                                                                 |\n",
    "| freebase_movie_id| ID of the movie from freebase                                                                                                                                             |\n",
    "| movie_name | Name of the movie                                                                                                                                                |\n",
    "| movie_release_date  | Date the movie was released                                                                                                                                      |\n",
    "| movie_box_office_revenue  | Revenue of the movie box office                                                                                                                           \n",
    "| movie_runtime  | Run time of the movie                                                                                                                                                 |\n",
    "| movie_languages | Languages of the movie                                                                                                                                                  |\n",
    "| movie_countries | Countries where the movie were created                                                                                                                                  |   |   |   |\n",
    "| movie_genres   | Genre of the movie                                                                                                                                              |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/'\n",
    "\n",
    "names = ['wikipedia_movie_id','freebase_movie_id', 'movie_name', 'movie_release_date', 'movie_box_office_revenue', \n",
    "        'movie_runtime', 'movie_languages', 'movie_countries', 'movie_genres']\n",
    "\n",
    "movies_data = pd.read_csv(data_folder + 'movie.metadata.tsv', names = names, sep = '\\t', )\n",
    "\n",
    "movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']]= movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].applymap(lambda x: str.lower(x))\n",
    "\n",
    "#character that we delete\n",
    "#note: we don't delete ',' because we use it to split our columns\n",
    "spec_char = ['{', '}', '\"', ':']\n",
    "\n",
    "for char in spec_char:\n",
    "        movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']] = movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].replace(char, '', regex = True)\n",
    "\n",
    "#removing the reference where we already have the info we need\n",
    "movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']] = movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].applymap(lambda s: re.sub('\\B\\/\\w+', '',s))\n",
    "movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']] = movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].applymap(lambda s: re.sub('\\B\\/\\w+', '',s))\n",
    "movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']] = movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].applymap(lambda s: s.strip())\n",
    "movies_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the dataset is complete except for the categories move_box_office_revenue that are often unavailable and the movie_runtime.\n",
    "\n",
    "To complete our data, we will use the title.ratings.tsv.gz and title.basics.tsv.gz datasets from IMDb that contain respectivly the ratings  and informations (like the runtime) about them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMdb datasets (ratings, runtimes, isAdult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(data_folder + 'title.ratings.tsv.gz', sep='\\t', compression='gzip')\n",
    "titles = pd.read_csv(data_folder + 'title.basics.tsv.gz', sep='\\t', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging IMdb dataset with title, isAdult and runtimeMinutes with dataset with averageRating on movie ID (tconst)\n",
    "rates = titles.merge(ratings, how='left', on='tconst')[['averageRating', 'numVotes', 'originalTitle', 'isAdult', 'runtimeMinutes']]\n",
    "\n",
    "#putting all titles to lower case to match the CMU dataset movie names and dropping column with upper cases\n",
    "rates['movie_name'] = [ele.lower() for ele in rates['originalTitle'].astype(str)]\n",
    "rates=rates.drop(columns='originalTitle')\n",
    "\n",
    "#dropping all rows that have a movie name appearing multiple times so the merging on movie name with the CMU dataset is precise\n",
    "rates = rates.drop_duplicates('movie_name', keep=False)\n",
    "\n",
    "#converting runtimeMinutes to float and changing '\\\\N' to NaN to match the format in CMU dataset\n",
    "rates['runtimeMinutes']=list(map(lambda x: float(x) if x!='\\\\N' else None , rates['runtimeMinutes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging CMU dataset with the IMdb dataset\n",
    "movies_data_merged = movies_data.merge(rates, how = 'left', on='movie_name')\n",
    "\n",
    "# Completing the NaN values in movie_runtime of the CMU dataset with the available ones of the IMdb dataset.\n",
    "# We trust more the CMU dataset than the IMdb one so we give priority to the runtime values of the CMU dataset\n",
    "# to the IMdb ones, hence we use the IMdb only if the value is missing in the CMU.\n",
    "movies_data_merged.loc[movies_data_merged['movie_runtime'].isna(), 'movie_runtime']=movies_data_merged.loc[movies_data_merged['movie_runtime'].isna(), 'runtimeMinutes']\n",
    "\n",
    "# Finally, we drop the column with the IMdb runtimes.\n",
    "movies_data_merged=movies_data_merged.drop(columns='runtimeMinutes')\n",
    "movies_data_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further analysis, as we want to analyze indian and american movies, we will select the films that are only from both countries and separate them into two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_indian = movies_data_merged[movies_data_merged['movie_countries'] == 'india'].reset_index()\n",
    "movies_american = movies_data_merged[movies_data_merged['movie_countries'] == 'united states of america'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are %d indian films and %d american films in the dataset.' % (len(movies_indian), len(movies_american)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Film summaries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read file\n",
    "summaries = pd.read_csv(data_folder + 'plot_summaries.txt', sep = '\\r', names = ['summaries'])\n",
    "#Split \n",
    "summaries = summaries['summaries'].str.split(\"\\t\", expand = True)\n",
    "#Rename the columns\n",
    "summaries = summaries.rename(columns= {0:'wikipedia_movie_id',1: 'summaries'})\n",
    "#Lowercase\n",
    "summaries['summaries'] = summaries['summaries'].str.lower()\n",
    "#Wiki movie id as integer\n",
    "summaries['wikipedia_movie_id'] = summaries['wikipedia_movie_id'].astype(int)\n",
    "summaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characters metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column name          | Description                                                                                                                                                                                       |\n",
    "|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| wikipedia_movie_id | ID of the movie from wikipedia                                                                                                                                                 |\n",
    "| freebase_movie_id| ID of the movie from freebase                                                                                                                                            |\n",
    "| movie_release_date | Date the movie was released                                                                                                                                                |\n",
    "| character_name  | Name of the character played                                                                                                                        \n",
    "| actor_dob  | Date of birth of the actor                                                                                                                                                 |\n",
    "| actor_gender | Actor gender (F or M)                                                                                                                                                  |\n",
    "| actor_height | Actor height (in [m])                                                                                                                                  |   |   |   |\n",
    "| actor_ethnicity   | Actor ethnicity (in freebase ID)                                                                                                                                             |\n",
    "| actor_name | Actor name                                                                                                                                                 |\n",
    "| actor_age_at_movie_release | Age of the actor at the movie release                                                                                                                                                 |\n",
    "| char_act_id | Actor ID                                                                                                                                                 |\n",
    "| freebase_character_id | ID of the character from freebase                                                                                                                                                  |\n",
    "| freebase_actor_id | ID of the actor from freebase                                                                                                                                                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare names for the colums\n",
    "names = ['wikipedia_movie_id', 'freebase_movie_id', 'movie_release_date', 'character_name', 'actor_dob', 'actor_gender', 'actor_height', 'actor_ethnicity', 'actor_name', 'actor_age_at_movie_release', 'char_act_id', 'freebase_character_id', 'freebase_actor_id']\n",
    "#Read file\n",
    "characters_data = pd.read_csv(data_folder + 'character.metadata.tsv', names = names, sep = '\\t')\n",
    "#Lower case \n",
    "characters_data[['character_name', 'actor_name']] = characters_data[['character_name', 'actor_name']].applymap(lambda x: x if type(x)!=str else x.lower())\n",
    "characters_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including ethnicities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the automatic query system from wikidata, we were able to retrieve the ethnicity of the actors based on the freebase ID in the actor_ethnicity column. \n",
    "\n",
    "We then map the matching id to the string-representation of the ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read file\n",
    "actor_ethnicities = pd.read_csv('data/ethnicities.csv')[['freebaseID', 'name']]\n",
    "actor_ethnicities = dict(zip(actor_ethnicities.freebaseID, actor_ethnicities.name))\n",
    "#Map the ethnicity id to the ethnicity name\n",
    "characters_data['actor_ethnicity'] = characters_data['actor_ethnicity'].map(actor_ethnicities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of American and Indian movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers of Indian vs American movies per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_years_indian = movies_indian.copy()\n",
    "\n",
    "#slice the movie release date column to only have the years, and transform them as integer again\n",
    "movies_years_indian['movie_release_date'] = movies_indian['movie_release_date'].dropna().astype('str').apply(lambda s: s[0:4]).astype('int')\n",
    "\n",
    "#count the numbers of movies per year there are for indian movies\n",
    "n_movie_per_year_indian = movies_years_indian.groupby('movie_release_date')['movie_name'].agg(['count'])\n",
    "\n",
    "#change the movie release date as a column\n",
    "n_movie_per_year_indian = pd.DataFrame(n_movie_per_year_indian).reset_index()\n",
    "\n",
    "#sort the values\n",
    "n_movie_per_year_indian['movie_release_date'] = n_movie_per_year_indian['movie_release_date'].sort_values()\n",
    "\n",
    "n_movie_per_year_indian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_years_american = movies_american.copy()\n",
    "\n",
    "#slice the movie release date column to only have the years, and transform them as integer again\n",
    "movies_years_american['movie_release_date'] = movies_years_american['movie_release_date'].dropna().astype('str').apply(lambda s: s[0:4]).astype('int')\n",
    "\n",
    "#count the numbers of movies per year there are for american movies\n",
    "n_movie_per_year_american = movies_years_american.groupby('movie_release_date')['movie_name'].agg(['count'])\n",
    "\n",
    "#change the movie release date as a column\n",
    "n_movie_per_year_american = pd.DataFrame(n_movie_per_year_american).reset_index()\n",
    "\n",
    "#sort the values\n",
    "n_movie_per_year_american['movie_release_date'] = n_movie_per_year_american['movie_release_date'].sort_values()\n",
    "\n",
    "n_movie_per_year_american"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us slice the data to have the same time frame: from 1912 to 2014 for both Indian and American movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice the data to have same time frame for both Indian and American movies data sets\n",
    "n_movie_per_year_american = n_movie_per_year_american.query('movie_release_date <= 2014 & movie_release_date >= 1912')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot both Indian and American numbers of movies per year\n",
    "sns.lineplot(data= n_movie_per_year_indian, x='movie_release_date', y = 'count', label='indian', color = 'orange', alpha = .5)\n",
    "sns.lineplot(data= n_movie_per_year_american, x='movie_release_date', y = 'count', label='american', color = 'blue', alpha = .5)\n",
    "plt.title('Indian vs American movies per year ')\n",
    "plt.xlabel('Movie release year')\n",
    "plt.ylabel('Number of movies per year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe a peak starting to grow from the 2000 years for both Hollywood and Bollywood movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zoom in during the peak of Indian and American released movie years\n",
    "sns.lineplot(data= n_movie_per_year_indian, x='movie_release_date', y = 'count', label='indian', color = 'orange', alpha = .5)\n",
    "sns.lineplot(data= n_movie_per_year_american, x='movie_release_date', y = 'count', label='american',color = 'blue', alpha = .5)\n",
    "plt.title('Indian vs American movies per year, from the 2000s')\n",
    "plt.xlabel('Movie release year')\n",
    "plt.ylabel('Number of movies per year')\n",
    "plt.axis([2000, 2014, 0, 1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The peak of released movies are at 2006 for Hollywood and 2008 Bollywood respectively.\n",
    "\n",
    "At 2014 it goes back to nearly 0 films released, so the CMU movie data base could have lacked data from this period on, as according to https://stephenfollows.com/how-many-films-are-released-each-year/, movies should keep being produced and growing from the 2008 years for the USA industry.\n",
    "\n",
    "We decided for consistency to begin the data set in the 1980 to 2010 time frame for both Hollywood and Bollywood movies.\n",
    "\n",
    "It was convenient to cut to 2010 instead of 2006 to create equal bins with the same number of points, in a 10 year period for our subsequent analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the movie release date column to only have the years, and transform them as integer again\n",
    "movies_indian['movie_release_date'] = movies_indian['movie_release_date'].dropna().astype('str').apply(lambda s: s[0:4]).astype('int')\n",
    "movies_american['movie_release_date'] = movies_american['movie_release_date'].dropna().astype('str').apply(lambda s: s[0:4]).astype('int')\n",
    "\n",
    "# Cut the data from 1980 to 2010 to have the same time frame for both Indian and American movies data sets\n",
    "cut_movies_american = movies_american.query('movie_release_date <= 2010 & movie_release_date >= 1980')\n",
    "cut_movies_indian = movies_indian.query('movie_release_date <= 2010 & movie_release_date >= 1980')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.3f percent of indian movies have a runtime and %.3f percent of american movies have a runtime' %\n",
    "(100-np.sum(cut_movies_indian['movie_runtime'].isna())/cut_movies_indian.shape[0]*100, 100-np.sum(cut_movies_american['movie_runtime'].isna())/cut_movies_american.shape[0]*100))\n",
    "\n",
    "print('Average runtime of indian movies : %.3f \\tAverage runtime of american movies : %.3f' %\n",
    "(cut_movies_indian['movie_runtime'].mean(), cut_movies_american['movie_runtime'].mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of movie runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_runtime = pd.DataFrame({'USA': cut_movies_american.query('movie_runtime < 10000')['movie_runtime'], 'India': cut_movies_indian.query('movie_runtime < 10000')['movie_runtime']})\n",
    "sns.histplot(data = data_runtime, palette = 'pastel')\n",
    "plt.yscale('log')\n",
    "plt.title(f'Distribution of runtimes (outlier of more than 10000 minutes removed)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot we can see that we have a few outliers in both datasets. \n",
    "\n",
    "Let us look at the plot again without the films that are longer than 1000 minutes (16 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of films longer than 16 hours:', len(cut_movies_indian.query('movie_runtime > 1000')) + len(cut_movies_american.query('movie_runtime > 1000')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the movie runtime without the outliers (only 4 films are longer than 16 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining number of bins to get roughly equal width between the 2 histograms\n",
    "data_runtime = pd.DataFrame({'USA': cut_movies_american.query('movie_runtime <1000')['movie_runtime'], 'India': cut_movies_indian.query('movie_runtime<1000')['movie_runtime']})\n",
    "#plotting\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "sns.histplot(cut_movies_american['movie_runtime'], alpha =.5, color = 'blue', stat = 'density', bins = 100, binrange= [0,1000], label = 'American movies')\n",
    "sns.histplot(cut_movies_indian['movie_runtime'], alpha=.5, color = 'orange', stat = 'density', bins = 100, binrange= [0,1000], label = 'Indian movies')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Movie runtime')\n",
    "plt.title('Movie runtime, differenciated by movie coutry')\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.violinplot(data = data_runtime, palette='pastel')\n",
    "plt.ylabel('Minutes')\n",
    "plt.title(f'Distribution of runtimes (outliers of movies more than 1000 minutes removed)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('median runtime difference:', np.nanmedian(cut_movies_american.query('movie_runtime <1000')['movie_runtime'] - cut_movies_indian.query('movie_runtime <1000')['movie_runtime']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that indian movies have a tendancy to be longer by ~48 minutes and that there are a lot of short american movies.\n",
    "\n",
    "There could be a bias in our dataset, because early indian cinema might be under-represented compared to early american cinema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some global informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.3f percent of indian movies have a rating and %.3f percent of american movies have a rating' %\n",
    "(100-np.sum(cut_movies_indian['averageRating'].isna())/cut_movies_indian.shape[0]*100, 100-np.sum(cut_movies_american['averageRating'].isna())/cut_movies_american.shape[0]*100))\n",
    "\n",
    "print('Average rating of indian movies : %.3f \\tAverage rating of american movies : %.3f' %\n",
    "(np.mean(cut_movies_indian['averageRating']), np.mean(cut_movies_american['averageRating'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions of movie ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,3))\n",
    "sns.histplot(x='averageRating', data=cut_movies_american, alpha=0.5, color = 'blue', label='American', stat = 'density', binrange=[0,10], bins = 20, kde=True)\n",
    "sns.histplot(x='averageRating', data=cut_movies_indian, alpha=0.5, color='orange', stat = 'density', label='Indian', binrange=[0,10], bins = 20, kde=True)\n",
    "plt.title('Distribution of movies ratings')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('P-value for normality test of american ratings : %.10f \\tP-value for normality test of indian ratings : %.10f ' \n",
    "      % (st.normaltest(cut_movies_american['averageRating'], nan_policy='omit').pvalue, st.normaltest(cut_movies_indian['averageRating'], nan_policy='omit').pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indian and american movies get similar distributions of ratings. This will allow us to use more easily the ratings as an unbiased tool to estimate the success of a movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of number of votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(2,2,1)\n",
    "sns.histplot(cut_movies_american['numVotes'], bins=np.logspace(0,7,50), alpha =.5, binrange=[0., 1e7], color = 'blue', stat = 'density', label = 'American movies')\n",
    "sns.histplot(cut_movies_indian['numVotes'], bins=np.logspace(0,7,50), alpha=.5, binrange=[0., 1e7], color = 'orange', stat = 'density', label = 'Indian movies')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of votes')\n",
    "plt.title('Number of votes per film, differenciated by movie coutry')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(data = pd.DataFrame({'USA': cut_movies_american['numVotes'], 'India': cut_movies_indian['numVotes']}), palette = 'pastel')\n",
    "plt.yscale('log')\n",
    "plt.title('Distribution of votes per film, differenciated by movie coutry')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot we can see that the distributions follow similar patterns, except in the extremes. \n",
    "\n",
    "Proportionally, Indian movies have more films with few votes (less than 100 votes), and inversely, American movies have movies that exceed the maximum number of votes any indian film obtains.\n",
    "\n",
    "In average, American films receive more votes but Indian films receive enough votes so that we can deem their ratings reliably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centering the data around each means for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#center data on mean\n",
    "cut_movies_indian.loc[:,'centeredRating']=cut_movies_indian['averageRating'].copy()-np.mean(cut_movies_indian['averageRating'])\n",
    "cut_movies_american.loc[:,'centeredRating']=cut_movies_american['averageRating'].copy()-np.mean(cut_movies_american['averageRating'])\n",
    "print('Centered average rating of indian movies : %.3f \\tCentered average rating of american movies : %.3f' %\n",
    "(np.mean(cut_movies_indian['centeredRating']), np.mean(cut_movies_american['centeredRating'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_indian = cut_movies_indian.copy()\n",
    "\n",
    "#remove films without genres\n",
    "genre_indian = genre_indian.query(\"movie_genres != ''\")\n",
    "\n",
    "genre_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all genres and count each genre number of apparation\n",
    "all_genres_listed_indian = genre_indian['movie_genres'].str.split(pat=\",\")\n",
    "\n",
    "ls = []\n",
    "for i in all_genres_listed_indian:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_genres_indian = pd.Series(ls)\n",
    "all_genres_indian = all_genres_indian.str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the first 50 genres\n",
    "first_genres_indian = all_genres_indian[:50]\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(y = first_genres_indian.index, x = first_genres_indian).set_title('Movie genres apparition in indian movies')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_american = cut_movies_american.copy()\n",
    "\n",
    "#remove films without genres\n",
    "genre_american = genre_american.query(\"movie_genres != ''\")\n",
    "genre_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all genres and count each genre number of apparation\n",
    "all_genres_listed_american = genre_american['movie_genres'].str.split(pat=\",\")\n",
    "\n",
    "ls = []\n",
    "for i in all_genres_listed_american:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_genres_american = pd.Series(ls)\n",
    "all_genres_american = all_genres_american.str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the first 50 genres\n",
    "first_genres_american = all_genres_american[:50]\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(y = first_genres_american.index, x = first_genres_american).set_title('Movie genres apparition in American movies')\n",
    "sns.despine(left=True, bottom=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare them with each other, we calculate the frequency of movie genre in each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate frequencies of movie genre in each country\n",
    "all_genres_american_frequency = all_genres_american/len(cut_movies_american)\n",
    "first_genres_american_frequency = all_genres_american_frequency[:50]\n",
    "all_genres_indian_frequency = all_genres_indian/len(cut_movies_indian)\n",
    "first_genres_indian_frequency = all_genres_indian_frequency[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the first 50 genres\n",
    "fig, ax = plt.subplots(1,2,figsize=(10, 10),sharex = True, constrained_layout=True)\n",
    "fig.suptitle('Movie genres frequency in American and Indian movies')\n",
    "ax[0].set_title('America')\n",
    "ax[1].set_title('India')\n",
    "\n",
    "sns.barplot(ax = ax[0],y = first_genres_american_frequency.index, x = first_genres_american_frequency, label=\"American\", color=\"blue\", alpha = 0.5)\n",
    "sns.barplot(ax = ax[1], y = first_genres_indian_frequency.index, x = first_genres_indian_frequency, label=\"Indian\", color=\"orange\", alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Indian movies have a total of %d different movie genres and American have %d movie genres.\"  %(len(all_genres_indian.index), len(all_genres_american.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the plot shows, \"drama\" is the prominent movie genre in both American and Indian movies. \n",
    "American movies seems to have a better distribution of different genres than Indian movies, that are more focused around \"drama\".\n",
    "\n",
    "Both of Indian and American movies have a large number of movie genres which can make the analysis hard to consise. \n",
    "Genre like \"world cinema\" seems rather not specific enough to categorize the movies. \n",
    "Furthermore, some genres are similar to each other or some of them include other genres (e.g. \"action/aventure\"). \n",
    "\n",
    "It could therefore be interesting to select a restricted group of movie genres that allows better and more precises results for our further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Languagues in Indian movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_languages= cut_movies_indian.copy()\n",
    "\n",
    "#remove the films without any languages\n",
    "indian_languages = indian_languages.query(\"movie_languages != ''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list with all languages\n",
    "all_languages_listed_indian = indian_languages['movie_languages'].str.split(pat=\",\")\n",
    "\n",
    "#Drop the NAs\n",
    "all_languages_listed_indian = all_languages_listed_indian.dropna()\n",
    "\n",
    "#Create a list with all the languages in it\n",
    "ls = []\n",
    "for i in all_languages_listed_indian:\n",
    "    ls.extend(i)\n",
    " \n",
    "#Count the total number of languages that are in the movies for each one of the languages\n",
    "all_languages_indian = pd.Series(ls)\n",
    "\n",
    "#Strip the strings and count the numbers of occurence of each languages\n",
    "all_languages_indian = all_languages_indian.str.strip().value_counts()\n",
    "\n",
    "all_languages_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_languages_indian_code = all_languages_indian.copy()\n",
    "\n",
    "#Put it as data frame\n",
    "all_languages_indian_code= pd.DataFrame(all_languages_indian_code)\n",
    "\n",
    "#Reset the index to have the index as column\n",
    "all_languages_indian_code = all_languages_indian_code.reset_index()\n",
    "\n",
    "#Rename the columns correctly\n",
    "all_languages_indian_code = all_languages_indian_code.rename(columns={\"index\": \"languages\", 0:\"count\"})\n",
    "\n",
    "#Only take the top 20 languages to plot it \n",
    "top_20_ind = all_languages_indian_code.iloc[:20]\n",
    "\n",
    "top_20_ind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting top 20 languages (39 in total for indian languages)\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(data = top_20_ind,y = 'languages', x = 'count').set_title('Languages apparition in Indian movies')\n",
    "ax.set_xscale('log')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Languagues in American movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_languages = cut_movies_american.copy()\n",
    "\n",
    "#Remove films without languages\n",
    "american_languages = american_languages.query(\"movie_languages != ''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list with all languages\n",
    "all_languages_listed_american = american_languages['movie_languages'].str.split(pat=\",\")\n",
    "\n",
    "#Drop the NAs\n",
    "all_languages_listed_american = all_languages_listed_american.dropna()\n",
    "\n",
    "#Create a list with all the languages in it\n",
    "ls = []\n",
    "for i in all_languages_listed_american:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_languages_american = pd.Series(ls)\n",
    "\n",
    "#Count the total number of languages that are in the movies for each one of the languages\n",
    "all_languages_american = all_languages_american.str.strip().value_counts()\n",
    "\n",
    "all_languages_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_languages_american_code =  all_languages_american.copy()\n",
    "\n",
    "#Put it as data frame\n",
    "all_languages_american_code = pd.DataFrame(all_languages_american_code)\n",
    "\n",
    "#Reset the index to have the index as column\n",
    "all_languages_american_code = all_languages_american_code.reset_index()\n",
    "\n",
    "#Rename the columns correctly\n",
    "all_languages_american_code = all_languages_american_code.rename(columns={\"index\": \"languages\", 0:\"count\"})\n",
    "\n",
    "#Only take the top 20 languages to plot it \n",
    "top_20_american = all_languages_american_code.iloc[:20]\n",
    "\n",
    "top_20_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting top 20 languages (111 in total for American movies)\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(data = top_20_american, y = 'languages', x = 'count').set_title('Languages apparition in American movies')\n",
    "ax.set_xscale('log')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison of languages between Indian and American movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the frequency of top 20 for the American and Indian languages\n",
    "all_languages_american_code['frequency'] = all_languages_american_code['count'] / all_languages_american_code['count'].sum()\n",
    "first_languages_american_frequency = all_languages_american_code[:20]\n",
    "\n",
    "all_languages_indian_code['frequency'] = all_languages_indian_code['count']/all_languages_indian_code['count'].sum()\n",
    "first_languages_indian_frequency = all_languages_indian_code[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting taking the first 20 languages for American films and Indian movies\n",
    "fig, ax = plt.subplots(1,2,figsize=(10, 10),sharex = True, constrained_layout=True)\n",
    "fig.suptitle('Top 20 movie languages frequency in American and Indian movies')\n",
    "ax[0].set_title('American movies')\n",
    "ax[1].set_title('Indian movies')\n",
    "\n",
    "sns.barplot(ax = ax[0],data = first_languages_american_frequency, y = 'languages', x = 'frequency', label=\"American\", color=\"blue\", alpha = 0.5)\n",
    "\n",
    "sns.barplot(ax = ax[1], data = first_languages_indian_frequency, y = 'languages', x = 'frequency', label=\"Indian\", color=\"orange\", alpha = 0.5)\n",
    "\n",
    "#Setting logarithmic scale \n",
    "ax[0].set_xscale('log')\n",
    "ax[1].set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different languages spoken in Indian movies are mostly the official languages spoken in India. \n",
    "American movies tends to have more languages that are spoken around the world.\n",
    "\n",
    "This could be a sign that American movies tend to be more international and are more exported abroad that Indian movies, in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many languages per movies there are, on average ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the number of ':' that represent the number of languages there are in each row for American movies\n",
    "american_languages['n_languages'] = american_languages.movie_languages.str.count(',')\n",
    "\n",
    "#Compute the number of ':' that represent the number of languages there are in each row for Indian movies\n",
    "indian_languages['n_languages'] = indian_languages.movie_languages.str.count(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the movies that do not have any languages\n",
    "n_indian_lan = indian_languages['n_languages'].dropna()\n",
    "\n",
    "n_american_lan = american_languages['n_languages'].dropna()\n",
    "\n",
    "#Compute the t-test to compare the number of available languages per movies for Indian and American movies\n",
    "t_test_languages = st.ttest_ind(n_indian_lan, n_american_lan)\n",
    "\n",
    "print('p-value for languages: ',t_test_languages.pvalue, '\\t', 'p-value is smaller than 0.05: ', t_test_languages.pvalue <0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant difference of the numbers of languages spoken in American vs Indian movies, but it is hard to pinpoint the underlying effect of this latter.\n",
    "\n",
    "Maybe since India has loads of different spoken languages in the country, the movies have several languages, more than the USA. \n",
    "Or, the USA movie industry has more languages spoken in their movies since it could be exported more in the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the dataset in two:\n",
    "# 1. all_american_actors which can contain duplicate actors. It contains information about the movies\n",
    "# and who plays in it and the age of the actors when the film is produced\n",
    "#\n",
    "# 2. all_indian_actors that contains data about individual actors. It doesn't contain duplicates,\n",
    "\n",
    "all_american_actors = characters_data[characters_data['wikipedia_movie_id'].isin(cut_movies_american['wikipedia_movie_id'])]\n",
    "all_indian_actors = characters_data[characters_data['wikipedia_movie_id'].isin(cut_movies_indian['wikipedia_movie_id'])]\n",
    "\n",
    "unique_american_actor = all_american_actors.drop_duplicates('actor_name')\n",
    "unique_indian_actor = all_indian_actors.drop_duplicates('actor_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add a column indicating the country the actor/actress works in before concatenating the datasets\n",
    "unique_american_actor = unique_american_actor.assign(country = np.full(len(unique_american_actor), 'USA'))\n",
    "unique_indian_actor = unique_indian_actor.assign(country = np.full(len(unique_indian_actor), 'India'))\n",
    "\n",
    "all_american_actors = all_american_actors.assign(country = np.full(len(all_american_actors), 'USA'))\n",
    "all_indian_actors = all_indian_actors.assign(country = np.full(len(all_indian_actors), 'India'))\n",
    "\n",
    "# We make sure to only keep actors with positive age to get rid of the errors \n",
    "all_american_actors = all_american_actors[all_american_actors['actor_age_at_movie_release'] > 0.]\n",
    "all_indian_actors = all_indian_actors[all_indian_actors['actor_age_at_movie_release'] > 0.]\n",
    "\n",
    "feature_list_all_actors = ['actor_gender', 'actor_age_at_movie_release', 'country']\n",
    "all_actors_merged = pd.concat([all_american_actors[feature_list_all_actors], all_indian_actors[feature_list_all_actors]], axis = 0)\n",
    "\n",
    "feature_list_unique_actors = ['actor_name', 'actor_gender', 'actor_ethnicity', 'country']\n",
    "unique_actors_merged = pd.concat([unique_american_actor[feature_list_unique_actors], unique_indian_actor[feature_list_unique_actors]], axis = 0)\n",
    "\n",
    "# Adding a column to the dataset of the features of single actors for the number of films in our dataset they appear in\n",
    "dict_number_of_film = characters_data['actor_name'].value_counts().to_dict()\n",
    "unique_actors_merged['number_of_films'] = unique_actors_merged['actor_name'].map(dict_number_of_film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actors_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_actors_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the analysis on age, it makes sense to count the same actors multiple times as they play in different films, we will thus not drop the duplicates for this part of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_american_actors.actor_age_at_movie_release.describe())\n",
    "print(all_indian_actors.actor_age_at_movie_release.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mean age is similar in both cases, as well as the standard deviation. Looking at the different quartiles we cannot see significant distribution difference between the two groups. \n",
    "\n",
    "We can note, however, that we have significantly more available ages available for actors in American films as for actors in Indian films (86'633 versus 22'858)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_ind(all_american_actors.actor_age_at_movie_release, all_indian_actors.actor_age_at_movie_release, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reject the null hypothesis, that is, that the mean actor age from American and Indian movies are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = all_american_actors['actor_age_at_movie_release'], stat = 'density', discrete=True, color = 'blue', kde=True, alpha = 0.5)\n",
    "sns.histplot(data = all_indian_actors['actor_age_at_movie_release'], stat = 'density',discrete=True, color='orange', kde=True, alpha = 0.5)\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.xlabel('Actor age')\n",
    "plt.title('Distribution of actor age in indian and american movies')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be more teenagers cast in american films, this can be due to the popularity of 'teen movies' in the western world, but is more likely to be simply due to a bias in quantity of information about american movies. \n",
    "\n",
    "The wikipedia pages of American movies might be more detailed about American films, containing even information about characters that may have relatively low screen time, like the daughter of a secondary character etc..\n",
    "\n",
    "Otherwise the distributions seem similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We separate the datasets containing all actors by gender\n",
    "# For american films\n",
    "american_film_female = all_american_actors[all_american_actors['actor_gender'] == 'F']\n",
    "american_film_male = all_american_actors[all_american_actors['actor_gender'] == 'M']\n",
    "\n",
    "# And for indian films\n",
    "indian_film_female = all_indian_actors[all_indian_actors['actor_gender'] == 'F']\n",
    "indian_film_male = all_indian_actors[all_indian_actors['actor_gender'] == 'M']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of american film actors we have the gender of is {0}, of which {1:.0%} are female'.format(\n",
    "    len(american_film_male) + len(american_film_female), len(american_film_female)/(len(american_film_male) + len(american_film_female))))\n",
    "\n",
    "print('Number of indian film actors we have the gender of is {0}, of which {1:.0%} are female'.format(\n",
    "    len(indian_film_male) + len(indian_film_female), len(indian_film_female)/(len(indian_film_male) + len(indian_film_female))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.suptitle('Comparaison of actor gender and age in American and Indian films', size = 'xx-large')\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "sns.histplot(data = all_american_actors, x = 'actor_age_at_movie_release', hue = 'actor_gender', stat = 'density', discrete=True, kde=True, palette = 'pastel')\n",
    "plt.xlabel('Actor/actress age')\n",
    "plt.title('Distribution of american film actor age with respect to gender')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.histplot(data = all_indian_actors, x = 'actor_age_at_movie_release', hue = 'actor_gender', stat = 'density', discrete=True, kde=True, palette = 'pastel')\n",
    "\n",
    "plt.xlabel('Actor/actress age')\n",
    "plt.title('Distribution of indian film actor age with respect to gender')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.histplot(data = all_american_actors[all_american_actors['actor_gender'] == 'F'], x = 'actor_age_at_movie_release', stat = 'density', discrete=True, color='blue', kde=True, alpha = 0.5)\n",
    "sns.histplot(data = all_indian_actors[all_indian_actors['actor_gender'] == 'F'], x = 'actor_age_at_movie_release', stat = 'density', discrete=True, kde=True, color = 'orange', alpha = 0.5)\n",
    "plt.xlabel('Actress age')\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.title('Distribution of actress age, differenciated by country')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "sns.histplot(data = all_american_actors[all_american_actors['actor_gender'] == 'M'], x = 'actor_age_at_movie_release', stat = 'density', discrete=True, color='blue', kde=True, alpha = 0.5)\n",
    "sns.histplot(data = all_indian_actors[all_indian_actors['actor_gender'] == 'M'], x = 'actor_age_at_movie_release', stat = 'density', discrete=True, kde=True, color = 'orange', alpha = 0.5)\n",
    "plt.xlabel('Actor age')\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.title('Distribution of actor age, differenciated by country')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the same phenomenon using boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = all_actors_merged, y = 'actor_age_at_movie_release', x = 'country', hue= 'actor_gender', palette = 'pastel')\n",
    "plt.title('Other visualization of the differences in age distribution by gender and country of movie production')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are very little differences between the distributions of actor age between the two movie industries, but a big difference between the distribution of actresses' age. We can see that in indian movies there is a big density peak in the low twenties and a rapid decline from the thirties onward. \n",
    "\n",
    "This difference is very stark and should be investigated further in the rest of our analysis, regarding time-wise changes and the prediction of movie success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the significance of the difference between the mean age of actors and actresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st.ttest_ind(all_american_actors.loc[all_american_actors.actor_gender == 'F']['actor_age_at_movie_release'],all_american_actors.loc[all_american_actors.actor_gender == 'M']['actor_age_at_movie_release']))\n",
    "print(st.ttest_ind(all_indian_actors.loc[all_indian_actors.actor_gender == 'F']['actor_age_at_movie_release'],all_indian_actors.loc[all_indian_actors.actor_gender == 'M']['actor_age_at_movie_release']))\n",
    "print(st.ttest_ind(all_american_actors.loc[all_american_actors.actor_gender == 'F']['actor_age_at_movie_release'],all_indian_actors.loc[all_indian_actors.actor_gender == 'F']['actor_age_at_movie_release']))\n",
    "print(st.ttest_ind(all_american_actors.loc[all_american_actors.actor_gender == 'M']['actor_age_at_movie_release'],all_indian_actors.loc[all_indian_actors.actor_gender == 'M']['actor_age_at_movie_release']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use the Bonferroni correction since we are doing multi-hypothesis testing: our p value is equal to p/4 = 0.05/4 = 0.0125.\n",
    "As we can see, all the p-value are significant except the t-test that compares the male ages of actors in Indian and American movies.\n",
    "\n",
    "The difference between actress in Indian and in American is significant, it could have thus underlying effects, even though it might mainly be driven by the sample size.\n",
    "\n",
    "Although, we can propose some possible factors to explain why Indian actresses might be younger than the American actresses:\n",
    "\n",
    "- Cultural preferences: In some cultures, including Indian culture, youth and beauty are often prized and valued highly. This may lead to a preference for younger actresses in the film industry.\n",
    "\n",
    "- The demands of the film industry: Acting in movies can be physically demanding, and younger actresses may be better able to handle the demands of long shooting schedules and demanding roles.\n",
    "\n",
    "- Physical demands of acting: In some cases, certain roles may require actresses to have a certain appearance or physicality, which may be more common in younger actresses.\n",
    "\n",
    "It is also worth noting that there is a wide range of ages among actresses in Indian movies, and many actresses in India continue to work in the film industry well into their 40s, 50s, and beyond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_data = unique_actors_merged.groupby(['actor_ethnicity', 'country'], as_index=False)['actor_name'].agg({'count'})\n",
    "ethnicity_data = pd.DataFrame(ethnicity_data.to_records())\n",
    "ethnicity_data = ethnicity_data.set_index('actor_ethnicity')\n",
    "\n",
    "#separate the dataset per country\n",
    "ethnicity_data_india = ethnicity_data[ethnicity_data['country'] == 'India']\n",
    "ethnicity_data_usa = ethnicity_data[ethnicity_data['country'] == 'USA']\n",
    "\n",
    "# converting count into density\n",
    "ethnicity_data_india['count'] = ethnicity_data_india.loc[:,'count'].div(len(ethnicity_data_india)).copy(deep=True)\n",
    "ethnicity_data_usa['count'] = ethnicity_data_usa.loc[:,'count'].div(len(ethnicity_data_usa)).copy(deep=True)\n",
    "\n",
    "ethnicity_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,80))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Ethnicity of actors ranked per frequency for movies produced in India')\n",
    "sns.barplot(data = ethnicity_data_india[:50], y = ethnicity_data_india.index[:50],  x = 'count', orient='h', order=ethnicity_data_india[:50].sort_values(by = 'count', ascending=False).index)\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('Density')\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Ethnicity of actors ranked per frequency for movies produced in the USA')\n",
    "sns.barplot(data = ethnicity_data_usa[:50], y = ethnicity_data_usa.index[:50],  x = 'count', orient='h', order=ethnicity_data_usa[:50].sort_values(by = 'count', ascending=False).index)\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of ethnicities in Indian movies:',len(ethnicity_data_india), '\\nNumber of ethnicities in American movies:',len(ethnicity_data_usa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, most ethnicities represented in the American films are descendent of immigrants, and most ethnicities represented in Indian films are Indian or more generally south-Asian. \n",
    "\n",
    "Also unsurprisingly, there are a lot more different ethnicities represented in films produced in the US compared to films produced in India. This might be due to the US being a more cosmopolite country, and to the difference in amout of information we have in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try investigate further the differences in representations in the industies, looking at the ethnicities represented in both industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative values represent ethnicities more represented in the indian film industry, and vice versa\n",
    "compared_ethnicities = (ethnicity_data_usa['count'] - ethnicity_data_india['count']).dropna()\n",
    "\n",
    "plt.title('Relative difference in proportion of ethnicities between indian and american films')\n",
    "sns.barplot(y = compared_ethnicities.index,  x = compared_ethnicities.values, orient='h', order=compared_ethnicities.sort_values(ascending=False).index)\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('Relative density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of indian film actors we have every features for:', unique_actors_merged[unique_actors_merged['country'] == 'India'].dropna().shape[0])\n",
    "print('Number of american film actors we have every features for:', unique_actors_merged[unique_actors_merged['country'] == 'USA'].dropna().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of indian film actors we have everything but ethnicity for:', unique_actors_merged[unique_actors_merged['country'] == 'India']['actor_gender'].shape[0])\n",
    "print('Number of american film actors we have everything but ethnicity for:', unique_actors_merged[unique_actors_merged['country'] == 'USA']['actor_gender'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we consider only actors where we have all the available informations (gender, country the actors plays in, and ethnicity) we only get 354 indian film actors and 1967 american film actors. This is not enough to perform an analysis through time while taking into account actor ethnicity.\n",
    "\n",
    "On the other hand, we have substantially more data on gender so taking it into account could be interesting for the subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In how many films an actor/actress have played in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.suptitle('Number of films an actor plays in', size = 'xx-large')\n",
    "plt.subplot(2,2,1)\n",
    "sns.histplot(data = unique_actors_merged[unique_actors_merged['country'] == 'India'], bins = np.logspace(0,2, 10), x = 'number_of_films', hue = 'actor_gender', kde = True, stat = 'density', palette = 'pastel').set(xscale=\"log\")\n",
    "plt.title('Number of films per actor in indian movies, differenciated by gender')\n",
    "plt.subplot(2,2,2)\n",
    "sns.histplot(data = unique_actors_merged[unique_actors_merged['country'] == 'USA'], bins = np.logspace(0,2, 10), x = 'number_of_films', hue = 'actor_gender', kde = True, stat = 'density', palette = 'pastel').set(xscale=\"log\")\n",
    "plt.title('Number of films per actor in american movies, differenciated by gender')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.barplot(data = unique_actors_merged, y = 'number_of_films', x = 'country', hue= 'actor_gender', palette = 'pastel')\n",
    "plt.title('Resume of the differences in film numbers between countries, differentiated by gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the number of actors/actresses that have played in more than 100 movies\n",
    "unique_actors_merged[unique_actors_merged['number_of_films'] > 100].groupby(['country', 'actor_gender']).agg({'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably have a bias in our dataset in the quantity of information we have in our dataset regarding the American films. \n",
    "We are far more likely to have the names of actors that make a single brief aparition in an American film. \n",
    "However, regarding the other extreme, we can see that there a lot more ultra-prolific Indian film actors than American film actors.\n",
    "\n",
    "In both film industries we see however that most of the hyper-prolific actors are males, which is probably linked to the difference in carreer prospects with age.\n",
    "\n",
    "Also, there is some evidence to suggest that female actresses tend to have fewer opportunities to play leading roles in movies than male actors in both Hollywood and Bollywood. Indeed, in 2015, the Center for the Study of Women in Television and Film at San Diego State University published a report titled \"It's a Man's (Celluloid) World,\" which found that women made up just 12% of protagonists in the top 100 grossing films of 2014.\n",
    "\n",
    "This phenomenon, known as the \"gender gap\" or the \"female movie deficit,\" refers to the underrepresentation of women in the film industry, both in front of and behind the camera.\n",
    "\n",
    "There are also more factors that may contribute to the gender gap in the film industry, including societal and cultural biases, the lack of diverse and complex female characters in film scripts, and the limited number of female directors and producers.\n",
    "\n",
    "This is once again a angle that could be included in further analysis regarding trends and film success (ratings) prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics analysis in summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our data in Indian and American dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_indian = summaries[summaries['wikipedia_movie_id'].isin(cut_movies_indian['wikipedia_movie_id'])]\n",
    "summaries_indian = summaries_indian.reset_index(drop = True)\n",
    "summaries_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_american = summaries[summaries['wikipedia_movie_id'].isin(cut_movies_american['wikipedia_movie_id'])]\n",
    "summaries_american = summaries_american.reset_index(drop = True)\n",
    "summaries_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_topic = pd.concat([summaries_indian, summaries_american], ignore_index=True)\n",
    "\n",
    "summaries_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(summaries_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Topic Detection Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modelling is used to extract topics from a collection of documents, in our case summaries of movies.\n",
    "Topics are fundamentally a cluster of similar words. This help in the understanding of hidden semantic structure between words of a large number of the extensive texts, at an aggregate level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each NLP task requires some sort of data pre-processing to make data eligible for modeling. We will perform the following steps:\n",
    "\n",
    "- Removing punctuation\n",
    "- Tokenization: Splitting sentences into word-sized chunks, called tokens.\n",
    "- Stopwords removal: Stopwords are English words that don’t add any value to the analysis. Removing them will help the model to find patterns more easily.\n",
    "- First names removal : since we want the topics of the movies, including the names of the character did not make sense to analyze the topics for our context of analysis. We decided to removed them.\n",
    "- Words with fewer than three letters are removed.\n",
    "- Lemmatization: Converting words to their base using morphological analysis.\n",
    "- Make bigrams: a bigram is a sequence of two adjacent elements from a string that combines to generate a more understandable form (e.g., [“data” , “science”] => [“data science”]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk stop words\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#Remove commom names from the summaries (list of 18'000 names)\n",
    "names = pd.read_csv(data_folder + 'names.csv')\n",
    "\n",
    "#Save the names as dataframe\n",
    "names = pd.DataFrame(names)\n",
    "\n",
    "#Casefold the names\n",
    "names['names'] = names['names'].str.lower().astype('str')\n",
    "\n",
    "#Append some list of names that we saw in the movies summaries to make sure they are in the list\n",
    "list_names = {'names':['alex', 'bobby', 'jake', 'timmy', 'danny', 'nick', 'anna', 'benny', 'maggie', 'reggie', 'nicky', 'vincent', 'johnny', 'grace']}\n",
    "\n",
    "names = names.append(pd.DataFrame(list_names))\n",
    "\n",
    "#Append the stop words in the list of names, consider them as \"stopwords\" to be removed from the summaries\n",
    "stop = list(np.append(names['names'].values, ['from', 'subject', 're', 'edu', 'use']))\n",
    "\n",
    "#Finally, extend the stop_words from nltk with our customized stop list\n",
    "stop_words.extend(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare function that preprocess the sentences of the summaries (removing punctuations, transforming into lowercase tokens)\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform into lowercase tokens and removing punctuations\n",
    "summaries_words = list(sent_to_words(summaries_topic['summaries']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then decide to build and use bigrams to pursue our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram model\n",
    "bigram = gensim.models.Phrases(summaries_words, min_count=15, threshold=100) # higher threshold fewer phrases.\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams and lemmatization\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "#Remove the stopwords in the summaries data\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "#Make the bigrams out of the summaries data\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "#Lemmatize the summaries keeping only nouns, ajdectives, verbs and adverbs (ref: https://spacy.io/api/annotation)\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags and len(token)>3])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stopwords and first names\n",
    "summaries_words_no_stopwords = remove_stopwords(summaries_words)\n",
    "\n",
    "# Form bigrams\n",
    "summaries_words_bigrams = make_bigrams(summaries_words_no_stopwords)\n",
    "\n",
    "# Perform the lemmatization keeping only nouns, ajdectives, verbs and adverbs \n",
    "summaries_words_lemmatized = lemmatization(summaries_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pre-processing the summaries, let us create the dictionnary, the corpus and the term document frequency for the subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary\n",
    "id2word = corpora.Dictionary(summaries_words_lemmatized)\n",
    "\n",
    "# Remove rare and common tokens\n",
    "\n",
    "# Tokens are kept if they are contained in at least 15 documents \n",
    "min_wordcount = 15\n",
    "\n",
    "# Tokens are kept if they are containted in no more than 30 % of the documents \n",
    "max_freq = 0.3\n",
    "\n",
    "# Filter these extremes accordingly\n",
    "id2word.filter_extremes(no_below=min_wordcount, no_above=max_freq)\n",
    "\n",
    "# Create the corpus, using the bag-of-words (BoW) format: list of (token_id, token_count) tuples.\n",
    "texts = summaries_words_lemmatized\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to choose the number of topics ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize a function that computes coherences values based on several number of topics, so we can chose the optimal number of topics based on the best coherence value.\n",
    "\n",
    "The parameters of the function are : \n",
    "- dictionary : Gensim dictionary \n",
    "- corpus : Gensim corpus\n",
    "- texts : List of input texts\n",
    "- limit : Max num of topics\n",
    "- start : number of initial topics\n",
    "- step : number of step for the next topic\n",
    "\n",
    "The function returns :\n",
    "- model_list : the list of LDA topic models\n",
    "- coherence_values : the coherence value corresponding to the LDA model with its respective number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=2):\n",
    "    #Initialize seed\n",
    "    seed = 80699\n",
    "    #Initialize dict\n",
    "    base_models = dict()\n",
    "    #Initialize coherence values and model list \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    #Compute the LDA model for each num_topics in the start, limit, step range\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics, random_state=seed)\n",
    "        #Append the model to the list of models\n",
    "        model_list.append(model)\n",
    "        #Compute the coherence\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        #Append the coherence value\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us then use it with the number of topics going from 2 to 20, with a step of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary = id2word, corpus = corpus, texts = texts, start=2, limit=20, step=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot each coherence value for each model of LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=20; start=2; step=2\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics for American and Indian Films\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coherence score seems optimal for 12 topics number, we therefore chose this as the optimal LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[5]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the topics using plDAvis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data = pyLDAvis.gensim_models.prepare(topic_model = optimal_model, corpus = corpus, dictionary = id2word, sort_topics = False)\n",
    "pyLDAvis.display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation and explanation of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic Bubble:**\n",
    "\n",
    "- The representation includes topics distribution in the 2-dimensional space (left side panel). These topics are represented in the form of bubbles.\n",
    "\n",
    "- The larger the bubble, the more frequent is the topic in the documents.\n",
    "\n",
    "- Since we have a low number of topics (10), we have big non-overlapping bubbles, scattered throughout the chart.\n",
    "\n",
    "- The distance between the topics is an approximation of the semantic relationship between these latter.\n",
    "\n",
    "- The topics that share common words will be overlapping in comparison to the non-overlapping topics.\n",
    "\n",
    "**Horizontal Bar Graph:**\n",
    "\n",
    "- The bar graph shows the frequency distribution of the words in the documents (in blue color).\n",
    "\n",
    "- The red area describes the frequency of each word given a topic.\n",
    "\n",
    "- When selecting a topic (clicking on a topic bubble), the top 30 most relevant term for the topic are shown.\n",
    "\n",
    "- Hovering over the specific words (in the right panel), the bubbles containing the words grows bigger or smaller if they also have it. The size of the bubble in this scenario describes the weightage of the word on that topic. The higher the weight of the selected word, the larger will be the size of the bubble.\n",
    "\n",
    "**Relevance Metric:**\n",
    "\n",
    "- Rank words in topics based on their frequency by varying the relevance metric lambda parameter (top right slide bar), that goes from 0 to 1.\n",
    "\n",
    "- Decreasing the lambda parameter means increasing the weight of the ratio (Frequency of word given the topic / Overall frequency of the word in the documents). Decreasing the lambda parameters gives words that are more specific to the topic. Important words for the given topic then moves upward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the plot to put it in the website\n",
    "pyLDAvis.save_html(data, 'lda.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare our features, let us group each summaries (doc) with its respective percentage of contribution to each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=optimal_model, corpus=corpus):\n",
    "    # Initialize the output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get the number of topic, percentage of contribution and number the document for each summaries (document)\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            \n",
    "            # Here we append topic_num + 1 to number to match each topics accordingly to pLDAvis' graph\n",
    "            sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num+1), round(prop_topic,6), int(i)]), ignore_index=True)\n",
    "\n",
    "    sent_topics_df.columns = ['num_topic', 'topic_perc_contrib','num_document']\n",
    "\n",
    "    return(sent_topics_df)\n",
    "\n",
    "sent_topics_df = format_topics_sentences(ldamodel=optimal_model, corpus=corpus)\n",
    "\n",
    "# Show the documents and their topic contribution\n",
    "sent_topics_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then pivot the precedent data frame to have each columns as a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = sent_topics_df.copy()\n",
    "\n",
    "# Pivot the data frame\n",
    "df_topics = df_topics.pivot(index = 'num_document', columns='num_topic', values='topic_perc_contrib')\n",
    "\n",
    "# Replace every nan to 0 to interpret this a zero contribution to the topic\n",
    "df_topics = df_topics.replace(np.nan, 0)\n",
    "\n",
    "# Finally, join with the summaries to have the wikipedia id and the original text of the summaries\n",
    "df_topics = df_topics.join(summaries_topic)\n",
    "\n",
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us identify the topics and label them. To do that, we have observed every topic bubble and identified the keywords that made the most sense to describe the topic.\n",
    "\n",
    "This enable us to label in a specific manner each topic and not to give a general genre, since we already have that in our features. It was difficult to pinpoint a specific theme since movies' stories can be very broad and unique, so we decided to chose the keywords as the most relevant terms to describe the topics.\n",
    "\n",
    "We therefore came up with a small description for each topics:\n",
    "\n",
    "- Topic 1: We chose \"experiment, scientist, power, creature\" as relevant keywords. This is probabily related more to science fiction, with a topic related to experimentations and creating supernatural creatures. It seems to be linked to control and malificient forces (keywords power, world, use, destroy).\n",
    "\n",
    "- Topic 2: We chose \"body, vampire, child, night\" as the relevant keywords. Even though the topic of the family is present (keywords child, home, mother), it seems to be a topic that is in the supernatural register, with a horror part (keywords run, dead, death, attack, body, night). The effect of a glooming revelation seems also depicted by this topic with strong verbs (keywords reveal, discover, appear, realize).\n",
    "\n",
    "- Topic 3: \"money, steal, prisoner, bank, drug\" made the most sense to depicts the topic. It seems pretty straighforward that the movies in that topic talks about crimes like stealing, break-ins of banks, drug gangs, involving money in it. The consequences of the crime is also catched by the LDA (keywords prison, guard, prisoner, police, catch). There is also a supernatural component in that topic with the keywords dragon, stone and spell.\n",
    "\n",
    "- Topic 4: \"team, game, coach, player\" were the keywords chosen for this topic. It is also straighforward that the topic revolves around the universe of sport, as several sports name are mentioned in the keywords (basketball, football, hockey). The vocabulary of a game is also there (keywords win, lose, score, play, first, start, decide).\n",
    "\n",
    "- Topic 5: The keywords \"ship, alien, earth, attack\" are also pretty straighforwards to draw an idea of the topic. It seems more revolved into sci-fi movies, probabily involving space adventures (keywords ship, alien, earth), that has also conflict and violence (keywords attack, destroy, death, shoot, fire, use).\n",
    "\n",
    "- Topic 6: \"murder, police, gang, fight, crime\". It is also pretty straightforward that the subject revolves around killing (keywords murder, crime, gang, killer, death, shoot). The crime probabily involves family in it (keywords father, daughter, wife, brother, family, mother), so it would be more a psychological thriller rather than the topic 3 which involves more of an organization and money in it.\n",
    "\n",
    "- Topic 7: We chose \"agent, shoot, military, bomb\" as relevant keywords to depict the topic. This topic seems to be more revolved around the using of military forces (keywords military, soldier, bomb, fire, shoot), in order to maybe to protect an important entity (keywords president, plane, plan, decide, order) from a group or person that wants to harm (keywords group, attempt, bomb) this latter.\n",
    "\n",
    "- Topic 8: \"band, family, show, music, dream\" keywords seems describe stories revolved around music and pursuing a dream career in the music domain. The family theme is present (keywords family, mother, home), along with romance (keywords girlfriend, relationship, together). We also have the theme of the desire, probabily to succeed in music (keywords dream, want, career, start).\n",
    "\n",
    "- Topic 9: The \"family, father, mother, daughter, wedding\" keywords are also very straightforward, and movies that are in this topic revolves around the family, specially around romance and relationship between a man and a woman concretizing into mariage and founding a family together(keywords husband, wife, marry, wedding, pregnant, child). The professional world is also depicted (keywords work, money, business).\n",
    "\n",
    "- Topic 10 : \"home, school, night, parent, party, decide\" were the keywords that we chose to describe this topic. Although it is less straightforward than some of the previous topics, it seems to revolves around family (keywords mother, father, parent, home, family), probablily with a teenager (keywords school) and involving some conflicts or discussion around that (keywords party, ask, want, talk).\n",
    "\n",
    "- Topic 11: The kewyords \"escape, camp, attack, truck\" were chosen for that topic. This also depicts the usage of force and violence, so this topic will be found more in the action movies. The vocabulary of protecting something is also present (keywords fight, rescue, town, monster).\n",
    "\n",
    "- Topic 12 : This last topic's keywords are \"movie, woman, play, character, role\". This seems to talk about the life in the movie field (keywords role, character, play, movie, lead, story). The character involved seems to be more feminime (keyswords woman, girl, wife).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label each topics accordingly\n",
    "df_topics.columns = ['experiment_scientist_power_creature', 'body_vampire_child_night', 'money_steal_prisoner_bank_drug', 'team_game_coach_player', 'ship_alien_earth_attack', 'murder_police_gang_fight_crime', 'agent_shoot_military_bomb', 'band_family_show_music_dream', 'family_father_mother_daughter_wedding', 'home_school_night_parent_party_decide', 'escape_camp_attack_truck', 'movie_woman_play_character_role', 'wikipedia_movie_id', 'summaries']\n",
    "\n",
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_indian_actors = pd.DataFrame({'wikipedia_movie_id':[]})\n",
    "df_features_american_actors = pd.DataFrame({'wikipedia_movie_id':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ids of the movies from the summaries\n",
    "df_features_indian_actors['wikipedia_movie_id']=cut_movies_indian['wikipedia_movie_id']\n",
    "df_features_american_actors['wikipedia_movie_id']=cut_movies_american['wikipedia_movie_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the mean age per gender for indian and american films\n",
    "mean_male_actor_age_india = indian_film_male.groupby('wikipedia_movie_id', as_index=False)['actor_age_at_movie_release'].agg({'mean_male_actor_age': np.mean})\n",
    "mean_female_actor_age_india = indian_film_female.groupby('wikipedia_movie_id', as_index=False)['actor_age_at_movie_release'].agg({'mean_female_actor_age': np.mean})\n",
    "\n",
    "mean_male_actor_age_america = american_film_male.groupby('wikipedia_movie_id', as_index=False)['actor_age_at_movie_release'].agg({'mean_male_actor_age': np.mean})\n",
    "mean_female_actor_age_america = american_film_female.groupby('wikipedia_movie_id', as_index=False)['actor_age_at_movie_release'].agg({'mean_female_actor_age': np.mean})\n",
    "\n",
    "\n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, mean_male_actor_age_india, on = 'wikipedia_movie_id', how = 'left') \n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, mean_female_actor_age_india, on = 'wikipedia_movie_id', how = 'left')\n",
    "\n",
    "df_features_american_actors = pd.merge(df_features_american_actors, mean_male_actor_age_america, on = 'wikipedia_movie_id', how = 'left')\n",
    "df_features_american_actors = pd.merge(df_features_american_actors, mean_female_actor_age_america, on = 'wikipedia_movie_id', how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the number of films an actor played in with the rest of the film data\n",
    "all_american_actors_ext = all_american_actors.merge(all_american_actors.actor_name.value_counts().reset_index(), left_on = 'actor_name', right_on = 'index', how = 'left')\n",
    "all_american_actors_ext = all_american_actors_ext.groupby('wikipedia_movie_id', as_index=False)['actor_name_y'].agg({'average_number_of_films_actors_played_in': np.mean})\n",
    "\n",
    "all_indian_actors_ext = all_indian_actors.merge(all_indian_actors.actor_name.value_counts().reset_index(), left_on = 'actor_name', right_on = 'index', how = 'left')\n",
    "all_indian_actors_ext = all_indian_actors_ext.groupby('wikipedia_movie_id', as_index=False)['actor_name_y'].agg({'average_number_of_films_actors_played_in': np.mean})\n",
    "\n",
    "# merging with features\n",
    "df_features_american_actors = pd.merge(df_features_american_actors, all_american_actors_ext[['wikipedia_movie_id', 'average_number_of_films_actors_played_in']], on = 'wikipedia_movie_id', how = 'left')\n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, all_indian_actors_ext[['wikipedia_movie_id', 'average_number_of_films_actors_played_in']], on = 'wikipedia_movie_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the percent of actress in each movie\n",
    "def percent_female(x):\n",
    "    try:\n",
    "        return x.value_counts().to_dict()['F']/len(x)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "percent_female_american_films = all_american_actors.groupby('wikipedia_movie_id', as_index=False)['actor_gender'].apply(percent_female)\n",
    "percent_female_american_films.rename(columns = {'actor_gender':'percent_female_cast'}, inplace = True)\n",
    "percent_female_indian_films = all_indian_actors.groupby('wikipedia_movie_id', as_index=False)['actor_gender'].apply(percent_female)\n",
    "percent_female_indian_films.rename(columns = {'actor_gender':'percent_female_cast'}, inplace = True)\n",
    "\n",
    "# merging with features\n",
    "df_features_american_actors = pd.merge(df_features_american_actors, percent_female_american_films, on = 'wikipedia_movie_id', how = 'left')\n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, percent_female_indian_films, on = 'wikipedia_movie_id', how = 'left')\n",
    "\n",
    "# drop the rows with no wikipedia_movie_id\n",
    "df_features_american_actors.dropna(subset = ['wikipedia_movie_id'], inplace = True)\n",
    "df_features_indian_actors.dropna(subset = ['wikipedia_movie_id'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Topic Detection Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_features_indian = df_topics.copy()\n",
    "\n",
    "topic_features_indian = df_topics[df_topics['wikipedia_movie_id'].isin(cut_movies_indian['wikipedia_movie_id'])]\n",
    "\n",
    "topic_features_indian = topic_features_indian.reset_index().drop(columns = ['summaries', 'num_document'])\n",
    "\n",
    "topic_features_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_features_american= df_topics.copy()\n",
    "\n",
    "topic_features_american = df_topics[df_topics['wikipedia_movie_id'].isin(cut_movies_american['wikipedia_movie_id'])]\n",
    "\n",
    "topic_features_american = topic_features_american.reset_index().drop(columns = ['summaries', 'num_document'])\n",
    "\n",
    "topic_features_american.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Anaylsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The mean length of american summaries is {1:.2f} words and for indian summaries it is {0:.2f} words.'.format(\n",
    "    np.mean([len(ele.split(' ')) for ele in summaries_indian['summaries']]),\n",
    "    np.mean([len(ele.split(' ')) for ele in summaries_american['summaries']])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can take up to 3min to run\n",
    "\n",
    "#defining analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#computing sentiments for each summary\n",
    "indian_sentiments = pd.DataFrame([analyzer.polarity_scores(summary) for summary in summaries_indian['summaries']])\n",
    "american_sentiments = pd.DataFrame([analyzer.polarity_scores(summary) for summary in summaries_american['summaries']])\n",
    "\n",
    "#adding wikipedia id for future merges\n",
    "indian_sentiments['wikipedia_movie_id']=summaries_indian['wikipedia_movie_id']\n",
    "american_sentiments['wikipedia_movie_id']=summaries_american['wikipedia_movie_id']\n",
    "indian_sentiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "sns.histplot(american_sentiments['compound'], alpha =.5, stat = 'density', bins = 10)\n",
    "sns.histplot(indian_sentiments['compound'], alpha=.5, color = 'orange', stat = 'density', bins = 10)\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.xlabel('Movie sentiments\\nnegative value indicates negative sentiments ; positive value indicates positive sentiments')\n",
    "plt.title('Movie sentiments, differenciated by movie coutry')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, as we can see in the movie genres first analysis, more than a hundred differents genres describe movies. For simplicity's sake, we limit the number of genres by taking a list of the main genres on ImDB. \n",
    "\n",
    "Furthermore, some of them are classified in two genres like \"romantic drama\". We decide here to categorize those movies as \"romantic\" **and** \"drama\".\n",
    "\n",
    "Each movies is described by dummies where for each genre it will either have 1 if the genre is detected or 0 if not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genre_imdb =  pd.Series(['action','adventure','animation','biography','comedy','crime','documentary','drama','family',\n",
    "                              'fantasy','noir','history', 'horror','musical','mystery','romance','sci fi','short Film',\n",
    "                              'sport','superhero','thriller','war','western'])\n",
    "#suppress punctuation and words that wont be taken as a genre and that are in high numbers\n",
    "nope_words = [',', 'film', 'bollywood', 'world', 'cinema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in nope_words:\n",
    "    genre_indian['movie_genres'] = genre_indian['movie_genres'].str.replace(char, '')\n",
    "    genre_indian['movie_genres'] = genre_indian['movie_genres'].str.replace('  ', ' ')\n",
    "    genre_american['movie_genres'] = genre_american['movie_genres'].str.replace(char, '')\n",
    "    genre_american['movie_genres'] = genre_american['movie_genres'].str.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dummies variables for each movie for each genres\n",
    "genre_dummies_indian = pd.DataFrame()\n",
    "for char in movie_genre_imdb:\n",
    "    genre_dummies_indian[char] = pd.Series(genre_indian['movie_genres'].apply(lambda x: pd.Series(x).str.contains(char[:3]).any().astype('int')))\n",
    "    \n",
    "genre_dummies_american = pd.DataFrame()\n",
    "for char in movie_genre_imdb:\n",
    "    genre_dummies_american[char] = pd.Series(genre_american['movie_genres'].apply(lambda x: pd.Series(x).str.contains(char[:3]).any().astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the wikipedia ID for merging\n",
    "genre_dummies_indian['wikipedia_movie_id'] = genre_indian['wikipedia_movie_id']\n",
    "genre_dummies_american['wikipedia_movie_id'] = genre_american['wikipedia_movie_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_american_actors = pd.merge(df_features_american_actors, american_sentiments[['wikipedia_movie_id', 'compound']], on = 'wikipedia_movie_id', how = 'left')\n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, indian_sentiments[['wikipedia_movie_id', 'compound']], on = 'wikipedia_movie_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian = pd.merge(genre_dummies_indian, df_features_indian_actors, on= 'wikipedia_movie_id', how = 'right')\n",
    "features_american = pd.merge(genre_dummies_american, df_features_american_actors, on= 'wikipedia_movie_id', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_indian = cut_movies_indian.dropna(subset = 'averageRating')[['wikipedia_movie_id', 'averageRating']]\n",
    "rating_american = cut_movies_american.dropna(subset = 'averageRating')[['wikipedia_movie_id', 'averageRating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian = pd.merge(features_indian, topic_features_indian, on= 'wikipedia_movie_id', how = 'left')\n",
    "features_american = pd.merge(features_american, topic_features_american, on= 'wikipedia_movie_id', how = 'left')\n",
    "features_indian = pd.merge(features_indian, rating_indian, on= 'wikipedia_movie_id', how = 'left')\n",
    "features_american = pd.merge(features_american, rating_american, on= 'wikipedia_movie_id', how = 'left')\n",
    "features_indian = pd.merge(features_indian, test_indian[['wikipedia_movie_id', 'movie_release_date']], on= 'wikipedia_movie_id', how = 'left')\n",
    "features_american = pd.merge(features_american, test_american[['wikipedia_movie_id', 'movie_release_date']], on= 'wikipedia_movie_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian.dropna(subset='experiment_scientist_power_creature', inplace = True)\n",
    "features_american.dropna(subset='experiment_scientist_power_creature', inplace = True)\n",
    "features_indian.iloc[:,0:23] = features_indian.iloc[:,0:23].fillna(0) ; features_indian.iloc[:,24:29] = features_indian.iloc[:,24:29].fillna(features_indian.iloc[:,24:29].mean())\n",
    "features_american.iloc[:,0:23] = features_american.iloc[:,0:23].fillna(0) ; features_american.iloc[:,24:29] = features_american.iloc[:,24:29].fillna(features_american.iloc[:,24:29].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "features_indian.to_csv('features_indian.csv', index = False)\n",
    "features_american.to_csv('features_american.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugo and Lucas Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian = pd.read_csv('features_indian.csv')\n",
    "features_american = pd.read_csv('features_american.csv')\n",
    "features = pd.concat([features_indian, features_american], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian_train = features_indian.drop(['wikipedia_movie_id', 'movie_release_date', 'averageRating'], axis = 1).copy()\n",
    "features_american_train = features_american.drop(['wikipedia_movie_id', 'movie_release_date', 'averageRating'], axis = 1).copy()\n",
    "\n",
    "american_ratings = features_american[['averageRating', 'movie_release_date']]\n",
    "indian_ratings = features_indian[['averageRating', 'movie_release_date']]\n",
    "#standardize the data\n",
    "features_indian_train.iloc[:,23:] = (features_indian_train.iloc[:,23:] - features_indian_train.iloc[:,23:].mean())/features_indian_train.iloc[:,23:].std()\n",
    "features_american_train.iloc[:,23:] = (features_american_train.iloc[:,23:] - features_american_train.iloc[:,23:].mean())/features_american_train.iloc[:,23:].std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouped genres frequency"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION** A partir d'ici j'enlève la colonne 'compound' !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_american.drop(columns='compound', inplace=True)\n",
    "features_indian.drop(columns='compound', inplace=True)\n",
    "features_indian_train.drop(columns='compound', inplace=True)\n",
    "features_american_train.drop(columns='compound', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the frequency of each genre\n",
    "genres_indian = pd.DataFrame(features_indian.iloc[:,:23].sum()/features_indian.shape[0], index=features_indian.columns[:23], columns=['frequency']).sort_values('frequency', ascending=False)\n",
    "genres_american = pd.DataFrame(features_american.iloc[:,:23].sum()/features_american.shape[0], index=features_american.columns[:23], columns=['frequency']).sort_values('frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(10, 10),sharex = True, constrained_layout=True)\n",
    "fig.suptitle('Movie genres frequency in American and Indian movies')\n",
    "ax[0].set_title('America')\n",
    "ax[1].set_title('India')\n",
    "\n",
    "sns.barplot(ax = ax[0],y = genres_american.index, x = genres_american['frequency'], label=\"American\", color=\"b\")\n",
    "sns.barplot(ax = ax[1], y = genres_indian.index, x = genres_indian['frequency'], label=\"Indian\", color=\"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "\n",
    "In this section we run t-SNE on standardized values of topics prevalence and mean actor data (mean male/female actor age, average number of film played per actor, percent female actor). Then, we isolate one specific genre and used K-Means on the two t-SNE features to cluster the movies in K cluster. We chose an adequate K by looking at the data and estimating the number of clusters that would make sense. \n",
    "\n",
    "On the first plot, you can see all the movies of our dataset on the period 1980-2010 of the genre of interest. \n",
    "You can switch between 2 colors: the first one simply shows the country of origin of the movies, the second one shows you to which cluster belongs each movie. \n",
    "\n",
    "On the second plot we analyze each cluster.\n",
    "You can switch between 3 panels: \n",
    "- On the first panel, you can visualize the standardized mean prevalence of each topic for each cluster. A positive value indicates that on average in this cluster the topic is more present than the average on our whole dataset. \n",
    "- On the second panel, you can visualize if a country is over-represented in a cluster compared to the proportion of movies in our dataset for the studied genre. For this purpose, we simply normalize by dividing each proportion of each cluster by its proportion in the genre. \n",
    "- Finally, on the last panel you can observe the means of the different actor data we computed. Those values are not normalized as they are already self explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running t-sne on the topics and actor data\n",
    "tsne = TSNE(n_components=2, random_state=0, learning_rate='auto', init = 'pca')\n",
    "features_tsne = pd.DataFrame(tsne.fit_transform(pd.concat([features_indian_train.iloc[:,:23], features_american_train.iloc[:,:23]])), columns=['tsne1', 'tsne2'])\n",
    "features_indian_tsne = features_tsne.iloc[:features_indian_train.shape[0], :].reset_index(drop=True)\n",
    "features_american_tsne = features_tsne.iloc[features_indian_train.shape[0]:, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use dummies for the genres and non standardized values for actor data...\n",
    "feats_indian = features_indian.copy().drop(columns=['movie_release_date', 'wikipedia_movie_id' ,'averageRating']).reset_index(drop=True)\n",
    "feats_american = features_american.copy().drop(columns=['movie_release_date', 'wikipedia_movie_id' ,'averageRating']).reset_index(drop=True)\n",
    "\n",
    "# ...and z-score for the topics prevalence\n",
    "feats_indian.iloc[:,27:]=features_indian_train.iloc[:,27:]\n",
    "feats_american.iloc[:,27:]=features_american_train.iloc[:,27:]\n",
    "\n",
    "#features = pd.concat([feats_indian, feats_american]).reset_index(drop=True)\n",
    "colors_country = np.append(np.repeat('orange', feats_indian.shape[0]), np.repeat('blue', feats_american.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre='comedy'\n",
    "n=4\n",
    "colors = []\n",
    "random.seed(0)\n",
    "\n",
    "#generating random colors for the clusters\n",
    "for i in range(n):\n",
    "    colors.append('#%06X' % random.randint(0, 0xFFFFFF))\n",
    "\n",
    "#running kmeans on the features from tsne\n",
    "kmeans = KMeans(n_clusters=n, random_state=3).fit(features_tsne[features[genre]==1])\n",
    "\n",
    "country = np.append(np.repeat(1, sum(feats_indian[genre]==1)) , np.repeat(0,sum(feats_american[genre]==1)))\n",
    "cols=np.append(feats_indian.columns[23:], ['Indian', 'American'])\n",
    "\n",
    "#finding movies with the corresponding genre\n",
    "feats_topics = np.append(feats_indian[feats_indian[genre]==1].iloc[:,23:].values, feats_american[feats_american[genre]==1].iloc[:,23:].values, axis=0)\n",
    "ratio_country = np.mean(country)\n",
    "\n",
    "#computing the mean of each feature for each cluster\n",
    "res = pd.DataFrame(np.zeros((n, len(cols))), columns=cols, dtype=float)\n",
    "for i in range(n):\n",
    "    res.iloc[i, :]=np.append(np.mean(feats_topics[kmeans.labels_==i, :], axis=0), [np.mean(country[kmeans.labels_==i]==1)/ratio_country, np.mean(country[kmeans.labels_==i]==0)/(1-ratio_country)])\n",
    "\n",
    "res['percent_female_cast']*=100\n",
    "\n",
    "#reshaping the dataframe for the plotly plot\n",
    "res2 = pd.DataFrame({'cluster':np.array([np.repeat(i, res.shape[1]) for i in range(n)]).flatten().astype(int), 'feature':np.tile(res.columns, n).astype(str), 'value':res.values.flatten().astype(float)})\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "#adding the scatter plot\n",
    "fig.add_scatter(x=features_tsne.loc[features[genre]==1, 'tsne1'], y=features_tsne.loc[features[genre]==1,'tsne2'], mode='markers', marker = dict(color = colors_country[features[genre]==1], size = 5), name='Country')\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=900,\n",
    "    autosize=False,\n",
    "    margin=dict(t=0, b=0, l=0, r=0),\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "#adding a button to switch between countries and kmeans coloring\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type = \"buttons\",\n",
    "            direction = \"left\",\n",
    "            buttons=list([\n",
    "                dict(\n",
    "                    args=[\"marker\", dict(color = colors_country[features[genre]==1], size = 5)],\n",
    "                    label=\"Country\",\n",
    "                    method=\"restyle\"\n",
    "                ),\n",
    "                dict(\n",
    "                    args=[\"marker\", dict(color=np.array(colors)[kmeans.labels_], size=5)],\n",
    "                    label=\"KMeans\",\n",
    "                    method=\"restyle\"\n",
    "                )\n",
    "            ]),\n",
    "            pad={\"r\": 10, \"t\": 10},\n",
    "            showactive=True,\n",
    "            x=0.11,\n",
    "            xanchor=\"left\",\n",
    "            y=1.1,\n",
    "            yanchor=\"top\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "#adding an annotation\n",
    "fig.update_layout(\n",
    "    annotations=[\n",
    "        dict(text=\"Color:\", showarrow=False,\n",
    "                             x=-50, y=1.08, yref=\"paper\", align=\"left\")\n",
    "    ],\n",
    "    title=dict(text=genre+ ' : t-SNE', x=0.5, y=0.97, xanchor='auto', yanchor='top', font=dict(size=30)),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['experiment_scientist_power_creature', 'body_vampire_child_night', 'money_steal_prisoner_bank_drug', 'team_game_coach_player', 'ship_alien_earth_attack', 'murder_police_gang_fight_crime', 'agent_shoot_military_bomb', 'band_family_show_music_dream', 'family_father_mother_daughter_wedding', 'home_school_night_parent_party_decide', 'escape_camp_attack_truck', 'movie_woman_play_character_role']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "#adding figures related to topics\n",
    "for i in topics:\n",
    "    fig.add_bar(x=res2.loc[res2['feature']==i, 'cluster'], y=res2.loc[res2['feature']==i, 'value'], marker_color=colors, name=i)\n",
    "#adding figures related to countries\n",
    "for i in ['Indian', 'American']:\n",
    "    fig.add_bar(x=res2.loc[res2['feature']==i, 'cluster'], y=res2.loc[res2['feature']==i, 'value'], marker_color=colors, name=i, visible=False)\n",
    "#adding features related to actor data\n",
    "for i in res2['feature'][:4]:\n",
    "    fig.add_bar(x=res2.loc[res2['feature']==i, 'cluster'], y=res2.loc[res2['feature']==i, 'value'], marker_color=colors, name=i, visible=False)\n",
    "\n",
    "# creating buttons to interact with the plot\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            active=0,\n",
    "            buttons=list([\n",
    "                dict(label=\"Topics\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": list(np.append(np.repeat(True, 12), np.repeat(False, 6)))}]),\n",
    "                dict(label=\"Countries\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": list(np.append(np.repeat(False, 12), np.append(np.repeat(True, 2), np.repeat(False, 4))))}]),\n",
    "                dict(label=\"Actor data\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": list(np.append(np.repeat(False, 14), np.repeat(True, 4)))}]),\n",
    "            ]),\n",
    "        )\n",
    "    ],\n",
    "    barmode='group', title=dict(text=genre+ ' : topic, country and gender representation', x=0.5, y=0.97, xanchor='auto', yanchor='top', font=dict(size=30)))\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus = 2\n",
    "clus2 = 3\n",
    "pvalues_topics = pd.DataFrame(st.ttest_ind(feats_topics[kmeans.labels_==clus, 4:], feats_topics[kmeans.labels_==clus2, 4:]).pvalue, columns = ['pvalue of t-test'], index=topics)\n",
    "\n",
    "pvalues_topics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explaination of the table:** Here we test the null hypothesis that the 2 cluster have identical average topic prevalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(n):\n",
    "    chi = st.chisquare([np.sum(country[kmeans.labels_==c]==1), np.sum(country[kmeans.labels_==c]==0)], f_exp=[round(sum(country)/len(country)*sum(kmeans.labels_==c), 0),round(sum(country==0)/len(country)*sum(kmeans.labels_==c), 0)]).pvalue\n",
    "    print(f'The p-value for the null hypothesis that the distribution of the country in cluster {c} is the same as the distribution of the country in the whole dataset of {genre} is {chi}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We deduce from those statistical tests that clusters 2 and 3 are significantly unbalanced and are more represented by one of the 2 countries. Additionaly, we notice many differences in topics representation that are statistically significant. Hence, we can say that those 2 clusters are probabily separate sub-genres with their own identity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordclouds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are interested in finding the words that occur the most often in the Indian and American romantic movies summaries and underlying the differences between the two countries. We use the same pre-processing steps as in the LDA topic detection analysis and then use the wordcloud library to plot the wordclouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre='romance'\n",
    "\n",
    "# filter indian and american summaries with only romantic films\n",
    "indian_summaries_genre = summaries_indian.merge(features_indian[['wikipedia_movie_id', genre]], on = 'wikipedia_movie_id')\n",
    "indian_summaries_genre = indian_summaries_genre[indian_summaries_genre[genre] == 1].drop(columns=genre)\n",
    "\n",
    "american_summaries_genre = summaries_american.merge(features_american[['wikipedia_movie_id', genre]], on = 'wikipedia_movie_id')\n",
    "american_summaries_genre = american_summaries_genre[american_summaries_genre[genre] == 1].drop(columns=genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of stopwords and add missing words ; we add the word 'film'\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'film'])\n",
    "counter = CountVectorizer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** We add the word 'film' to the stopwords list because it is present in many summaries and often used in sentences like 'The film is about...' and is not relevant to the context of the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wordcloud(df, country):\n",
    "    # Create bigram models for nlp\n",
    "    words = list(sent_to_words(df['summaries']))\n",
    "    global bigram \n",
    "    bigram = gensim.models.Phrases(words, min_count=15, threshold=100) # higher threshold fewer phrases.\n",
    "    global bigram_mod \n",
    "    bigram_mod= gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "    # Apply NLP pipeline : remove stopwords, make bigrams, lemmatize\n",
    "    words = remove_stopwords(words)\n",
    "    words = make_bigrams(words)\n",
    "    words = lemmatization(words, allowed_postags=['NOUN', 'ADJ'])\n",
    "\n",
    "    # create bag of words matrix\n",
    "    count_matrix = counter.fit_transform((pd.Series(words, dtype = str)))\n",
    "    feature_array = np.array(counter.get_feature_names_out())\n",
    "\n",
    "    # average BOW for each word\n",
    "    avg_count = np.mean(count_matrix, axis=0)\n",
    "    w = {feature_array[i]: avg_count[0,i] for i in range(0, count_matrix.shape[1])}\n",
    "\n",
    "    # generate the mask and color generator for wordcloud\n",
    "    if (country=='india'):\n",
    "        mask_ = np.array(Image.open('./img/india.png'))\n",
    "        mask = np.array(list(map(lambda x: [255, 255, 255, 255] if x < 2 else [0,0,0,255] ,mask_.flatten())))\n",
    "        mask = mask.reshape(mask_.shape[0], mask_.shape[1], 4)\n",
    "        coloring = ImageColorGenerator(np.array(Image.open(\"./img/india_flag.jpg\")))\n",
    "    elif (country=='usa'):\n",
    "        mask_ = np.array(Image.open('./img/usa.png'))\n",
    "        mask = np.array(list(map(lambda x: [255, 255, 255, 255] if x == 1 else [0,0,0,255] ,mask_.flatten())))\n",
    "        mask = mask.reshape(mask_.shape[0], mask_.shape[1], 4)\n",
    "        coloring = ImageColorGenerator(np.array(Image.open(\"./img/usa_flag.jpg\")))\n",
    "    else:\n",
    "        assert 1==0, 'country should be India or USA'\n",
    "    \n",
    "    # generate the wordcloud\n",
    "    wordcloud = WordCloud(color_func = coloring, background_color=\"white\", max_words = 300, width = 1000, height = 800, stopwords=STOPWORDS, mask=mask).generate_from_frequencies(w)\n",
    "    \n",
    "    return wordcloud.to_image()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_wordcloud(indian_summaries_genre, 'india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_wordcloud(american_summaries_genre, 'usa')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We notice that the notion of time is very important in American movies whereas it is not the case at all in India. It is also suprising to see that the word woman is more important than the word girl in the US whereas it is the opposite in India. This can maybe be put in perspective with what we observed in the previous section : the mean female actor age in American-dominated cluster of romantic movies is 33 years old whereas it is 27 years old in Indian-dominated clusters (6 years gap!). Moreover, the topics of family and marriage is also much more important in Indian romance than Americans."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6ff92366812eff0585597bdff8203f3dca47fc152c7f8518e1cf16bc394b74b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
