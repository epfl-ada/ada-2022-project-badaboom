{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy.stats as st\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_palette(\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the recipe for the perfect movie in **BOLLYWOOD** vs. in **HOLLYWOOD**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the loading, we do a simple pre-processing work where we remove punctuation and capitalization from words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie metadata\n",
    "This dataset contains the basics informations of differents movies. Here, you have the name of the differents informations and their definition.\n",
    "\n",
    "| Column name          | Description                                                                                                                                                                                       |\n",
    "|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| wikipedia_movie_id | ID of the movie from wikipedia                                                                                                                                                 |\n",
    "| freebase_movie_id| ID of the movie from freebas                                                                                                                                            |\n",
    "| movie_name | Name of the movie                                                                                                                                                |\n",
    "| movie_release_date  | Date the movie was released                                                                                                                                      |\n",
    "| movie_box_office_revenue  | Revenue of the movie box office                                                                                                                           \n",
    "| movie_runtime  | Run time of the movie                                                                                                                                                 |\n",
    "| movie_languages | Languages of the movie                                                                                                                                                  |\n",
    "| movie_countries | Countries where the movie were created                                                                                                                                  |   |   |   |\n",
    "| movie_genres   | Genre of the movie                                                                                                                                              |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/'\n",
    "\n",
    "names = ['wikipedia_movie_id','freebase_movie_id', 'movie_name', 'movie_release_date', 'movie_box_office_revenue', \n",
    "        'movie_runtime', 'movie_languages', 'movie_countries', 'movie_genres']\n",
    "\n",
    "movies_data = pd.read_csv(data_folder + 'movie.metadata.tsv', names = names, sep = '\\t', )\n",
    "\n",
    "movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']]= movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].applymap(lambda x: str.lower(x))\n",
    "\n",
    "#character that we delete\n",
    "#note: we don't delete ',' because we use it to split our columns\n",
    "spec_char = ['{', '}', '\"', ':']\n",
    "\n",
    "for char in spec_char:\n",
    "        movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']] = movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].replace(char, '', regex = True)\n",
    "#removing the reference where we already have the info we need\n",
    "movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']] = movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].applymap(lambda s: re.sub('\\B\\/\\w+', '',s))\n",
    "movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']] = movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].applymap(lambda s: re.sub('\\B\\/\\w+', '',s))\n",
    "movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']] = movies_data[['movie_name', 'movie_languages', 'movie_countries', 'movie_genres']].applymap(lambda s: s.strip())\n",
    "movies_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the dataset is complete except for the categories move_box_office_revenue that are often unavailable and the movie_runtime.\n",
    "\n",
    "To complete our data, we will use the title.ratings.tsv.gz and title.basics.tsv.gz datasets from IMDb that contain respectivly the ratings  and informations (like the runtime) about them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMdb datasets (ratings, runtimes, isAdult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(data_folder + 'title.ratings.tsv.gz', sep='\\t', compression='gzip')\n",
    "titles = pd.read_csv(data_folder + 'title.basics.tsv.gz', sep='\\t', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging IMdb dataset with title, isAdult and runtimeMinutes with dataset with averageRating on movie ID (tconst)\n",
    "rates = titles.merge(ratings, how='left', on='tconst')[['averageRating', 'numVotes', 'originalTitle', 'isAdult', 'runtimeMinutes']]\n",
    "\n",
    "#putting all titles to lower case to match the CMU dataset movie names and dropping column with upper cases\n",
    "rates['movie_name'] = [ele.lower() for ele in rates['originalTitle'].astype(str)]\n",
    "rates=rates.drop(columns='originalTitle')\n",
    "\n",
    "#dropping all rows that have a movie name appearing multiple times so the merging on movie name with the CMU dataset is precise\n",
    "rates = rates.drop_duplicates('movie_name', keep=False)\n",
    "\n",
    "#converting runtimeMinutes to float and changing '\\\\N' to NaN to match the format in CMU dataset\n",
    "rates['runtimeMinutes']=list(map(lambda x: float(x) if x!='\\\\N' else None , rates['runtimeMinutes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging CMU dataset with the IMdb dataset\n",
    "movies_data_merged = movies_data.merge(rates, how = 'left', on='movie_name')\n",
    "\n",
    "#completing the NaN values in movie_runtime of the CMU dataset with the available ones of the IMdb dataset.\n",
    "#we trust more the CMU dataset than the IMdb one so we give priority to the runtime values of the CMU dataset\n",
    "# to the IMdb ones and use the IMdb only if the value is missing in the CMU.\n",
    "#finally we drop the column with the IMdb runtimes.\n",
    "movies_data_merged.loc[movies_data_merged['movie_runtime'].isna(), 'movie_runtime']=movies_data_merged.loc[movies_data_merged['movie_runtime'].isna(), 'runtimeMinutes']\n",
    "movies_data_merged=movies_data_merged.drop(columns='runtimeMinutes')\n",
    "movies_data_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further analysis, as we want to analyze indian and american movies, we will select the films that are only form both countries and separate in two dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_indian = movies_data_merged[movies_data_merged['movie_countries'] == 'india'].reset_index()\n",
    "movies_american = movies_data_merged[movies_data_merged['movie_countries'] == 'united states of america'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are %d indian films and %d american films in the dataset' % (len(movies_indian), len(movies_american)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Film summaries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = pd.read_csv(data_folder + 'plot_summaries.txt', sep = '\\r', names = ['summaries'])\n",
    "summaries = summaries['summaries'].str.split(\"\\t\", expand = True)\n",
    "summaries = summaries.rename(columns= {0:'wikipedia_movie_id',1: 'summaries'})\n",
    "summaries['summaries'] = summaries['summaries'].str.lower()\n",
    "summaries['wikipedia_movie_id'] = summaries['wikipedia_movie_id'].astype(int)\n",
    "summaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characters metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column name          | Description                                                                                                                                                                                       |\n",
    "|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| wikipedia_movie_id | ID of the movie from wikipedia                                                                                                                                                 |\n",
    "| freebase_movie_id| ID of the movie from freebase                                                                                                                                            |\n",
    "| movie_release_date | Date the movie was released                                                                                                                                                |\n",
    "| character_name  | Name of the character played                                                                                                                        \n",
    "| actor_dob  | Date of birth of the actor                                                                                                                                                 |\n",
    "| actor_gender | Actor gender (F or M)                                                                                                                                                  |\n",
    "| actor_height | Actor height (in [m])                                                                                                                                  |   |   |   |\n",
    "| actor_ethnicity   | Actor ethnicity (in freebase ID)                                                                                                                                             |\n",
    "| actor_name | Actor name                                                                                                                                                 |\n",
    "| actor_age_at_movie_release | Age of the actor at the movie release                                                                                                                                                 |\n",
    "| char_act_id | Actor ID                                                                                                                                                 |\n",
    "| freebase_character_id | ID of the character from freebase                                                                                                                                                  |\n",
    "| freebase_actor_id | ID of the actor from freebase                                                                                                                                                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['wikipedia_movie_id', 'freebase_movie_id', 'movie_release_date', 'character_name', 'actor_dob', 'actor_gender', 'actor_height', 'actor_ethnicity', 'actor_name', 'actor_age_at_movie_release', 'char_act_id', 'freebase_character_id', 'freebase_actor_id']\n",
    "characters_data = pd.read_csv(data_folder + 'character.metadata.tsv', names = names, sep = '\\t')\n",
    "characters_data[['character_name', 'actor_name']] = characters_data[['character_name', 'actor_name']].applymap(lambda x: x if type(x)!=str else x.lower())\n",
    "characters_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including ethnicities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the automatic query system from wikidata, we are able to retrieve the ethnicity of the actors based on the freebase ID in the actor_ethnicity column. For that we just map the matching id to the string-representation of the ethnicity for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_ethnicities = pd.read_csv('data/ethnicities.csv')[['freebaseID', 'name']]\n",
    "actor_ethnicities = dict(zip(actor_ethnicities.freebaseID, actor_ethnicities.name))\n",
    "characters_data['actor_ethnicity'] = characters_data['actor_ethnicity'].map(actor_ethnicities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First analysis of difference between India and America"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers of Indian vs American movies per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_years_indian = movies_indian.copy()\n",
    "\n",
    "#slice the movie release date column to only have the years, and transform them as integer again\n",
    "movies_years_indian['movie_release_date'] = movies_indian['movie_release_date'].dropna().astype('str').apply(lambda s: s[0:4]).astype('int')\n",
    "\n",
    "#count the numbers of movies per year there are for indian movies\n",
    "n_movie_per_year_indian = movies_years_indian.groupby('movie_release_date')['movie_name'].agg(['count'])\n",
    "\n",
    "#change the movie release date as a column\n",
    "n_movie_per_year_indian = pd.DataFrame(n_movie_per_year_indian).reset_index()\n",
    "\n",
    "#sort the values\n",
    "n_movie_per_year_indian['movie_release_date'] = n_movie_per_year_indian['movie_release_date'].sort_values()\n",
    "\n",
    "n_movie_per_year_indian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_years_american = movies_american.copy()\n",
    "\n",
    "#slice the movie release date column to only have the years, and transform them as integer again\n",
    "movies_years_american['movie_release_date'] = movies_years_american['movie_release_date'].dropna().astype('str').apply(lambda s: s[0:4]).astype('int')\n",
    "\n",
    "#count the numbers of movies per year there are for american movies\n",
    "n_movie_per_year_american = movies_years_american.groupby('movie_release_date')['movie_name'].agg(['count'])\n",
    "\n",
    "#change the movie release date as a column\n",
    "n_movie_per_year_american = pd.DataFrame(n_movie_per_year_american).reset_index()\n",
    "\n",
    "#sort the values\n",
    "n_movie_per_year_american['movie_release_date'] = n_movie_per_year_american['movie_release_date'].sort_values()\n",
    "\n",
    "n_movie_per_year_american"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us slice the data to have the same time frame: from 1912 to 2014 for both Indian and American movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice the data to have same time frame for both Indian and American movies data sets\n",
    "n_movie_per_year_american = n_movie_per_year_american.query('movie_release_date <= 2014 & movie_release_date >= 1912')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot both Indian and American numbers of movies per year\n",
    "sns.lineplot(data= n_movie_per_year_indian, x='movie_release_date', y = 'count', label='indian')\n",
    "sns.lineplot(data= n_movie_per_year_american, x='movie_release_date', y = 'count', label='american')\n",
    "plt.title('Indian vs American movies per year ')\n",
    "plt.xlabel('Movie release year')\n",
    "plt.ylabel('Number of movies per year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe a peak starting to grow from the 2000 years for both Hollywood and Bollywood movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zoom in during the peak of Indian and American released movie years\n",
    "sns.lineplot(data= n_movie_per_year_indian, x='movie_release_date', y = 'count', label='indian')\n",
    "sns.lineplot(data= n_movie_per_year_american, x='movie_release_date', y = 'count', label='american')\n",
    "plt.title('Indian vs American movies per year, from the 2000s')\n",
    "plt.xlabel('Movie release year')\n",
    "plt.ylabel('Number of movies per year')\n",
    "plt.axis([2000, 2014, 0, 1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The peak of released movies are at 2006 for Hollywood and 2008 Bollywood respectively.\n",
    "\n",
    "At 2014 it goes back to nearly 0 films released, but we should investigate carefully the data set that explain this lack of data.\n",
    "\n",
    "Thus we begin the data set in 1950 for both Hollywood and Bollywood movies and cut the data set to 2006 for both Hollywood and Bollywood movies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the movie release date column to only have the years, and transform them as integer again\n",
    "movies_indian['movie_release_date'] = movies_indian['movie_release_date'].dropna().astype('str').apply(lambda s: s[0:4]).astype('int')\n",
    "movies_american['movie_release_date'] = movies_american['movie_release_date'].dropna().astype('str').apply(lambda s: s[0:4]).astype('int')\n",
    "\n",
    "# Cut the data from 1950 to 2010 to have the same time frame for both Indian and American movies data sets\n",
    "cut_movies_american = movies_american.query('movie_release_date <= 2010 & movie_release_date >= 1980')\n",
    "cut_movies_indian = movies_indian.query('movie_release_date <= 2010 & movie_release_date >= 1980')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.3f percent of indian movies have a runtime and %.3f percent of american movies have a runtime' %\n",
    "(100-np.sum(cut_movies_indian['movie_runtime'].isna())/cut_movies_indian.shape[0]*100, 100-np.sum(cut_movies_american['movie_runtime'].isna())/cut_movies_american.shape[0]*100))\n",
    "\n",
    "print('Average runtime of indian movies : %.3f \\tAverage runtime of american movies : %.3f' %\n",
    "(cut_movies_indian['movie_runtime'].mean(), cut_movies_american['movie_runtime'].mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of movie runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_runtime = pd.DataFrame({'USA': cut_movies_american.query('movie_runtime < 10000')['movie_runtime'], 'India': cut_movies_indian.query('movie_runtime < 10000')['movie_runtime']})\n",
    "sns.histplot(data = data_runtime)\n",
    "plt.yscale('log')\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.title(f'Distribution of runtimes (outlier of removed)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot we can see that we have a few outliers in both datasets. Looking at most of the films that are longer than 1000 minutes (16 hours), we decided that they could be discarted as they are either errors or not pertinent to our analysis (series of films instead of single film)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of films longer than 16 hours:', len(cut_movies_indian.query('movie_runtime > 1000')) + len(cut_movies_american.query('movie_runtime > 1000')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting 8 films that are very likely to be errors shouldn't make default to our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining number of bins to get roughly equal width between the 2 histograms\n",
    "data_runtime = pd.DataFrame({'USA': cut_movies_american['movie_runtime'], 'India': cut_movies_indian['movie_runtime']})\n",
    "#plotting\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "sns.histplot(cut_movies_american['movie_runtime'], alpha =.5, stat = 'density', bins = 100, binrange= [0,1000])\n",
    "sns.histplot(cut_movies_indian['movie_runtime'], alpha=.5, color = 'orange', stat = 'density', bins = 100, binrange= [0,1000])\n",
    "plt.yscale('log')\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.xlabel('Movie runtime')\n",
    "plt.title('Movie runtime, differenciated by movie coutry')\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.violinplot(data = data_runtime)\n",
    "plt.ylabel('Minutes')\n",
    "plt.title(f'Distribution of runtimes (outlier of removed)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('median runtime difference:', np.nanmedian(cut_movies_american['movie_runtime'] - cut_movies_indian['movie_runtime']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some global informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.3f percent of indian movies have a rating and %.3f percent of american movies have a rating' %\n",
    "(100-np.sum(cut_movies_indian['averageRating'].isna())/cut_movies_indian.shape[0]*100, 100-np.sum(cut_movies_american['averageRating'].isna())/cut_movies_american.shape[0]*100))\n",
    "\n",
    "print('Average rating of indian movies : %.3f \\tAverage rating of american movies : %.3f' %\n",
    "(np.mean(cut_movies_indian['averageRating']), np.mean(cut_movies_american['averageRating'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions of movie ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,3))\n",
    "sns.histplot(x='averageRating', data=cut_movies_american, alpha=0.5, label='American', stat = 'density', binrange=[0,10], bins = 20, kde=True)\n",
    "sns.histplot(x='averageRating', data=cut_movies_indian, alpha=0.5, color='orange', stat = 'density', label='Indian', binrange=[0,10], bins = 20, kde=True)\n",
    "plt.title('Distribution of movies ratings')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('P-value for normality test of american ratings : %.10f \\tP-value for normality test of indian ratings : %.10f ' \n",
    "      % (st.normaltest(cut_movies_american['averageRating'], nan_policy='omit').pvalue, st.normaltest(cut_movies_indian['averageRating'], nan_policy='omit').pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indian and american movies get similar distributions of ratings. This will allow us to use more easily the ratings as an unbiased tool to estimate the success of a movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of number of votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(2,2,1)\n",
    "sns.histplot(cut_movies_american['numVotes'], bins=np.logspace(0,7,50), alpha =.5, binrange=[0., 1e7], stat = 'density')\n",
    "sns.histplot(cut_movies_indian['numVotes'], bins=np.logspace(0,7,50), alpha=.5, binrange=[0., 1e7], color = 'orange', stat = 'density')\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of votes')\n",
    "plt.title('Number of votes per film, differenciated by movie coutry')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(data = pd.DataFrame({'USA': cut_movies_american['numVotes'], 'India': cut_movies_indian['numVotes']}))\n",
    "plt.yscale('log')\n",
    "plt.title('Distribution of votes per film, differenciated by movie coutry')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot we can see that the distributions follow similar patterns, except in the extrems. Proportionally, indian movies have more films with few votes (less than 100 votes), and, inversly, american movies have a movies that exceed the maximum number of votes any indian film obtains\n",
    "\n",
    "In average, american films receive more votes, but Indian films receive enough votes so that we can deem their ratings reliable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centering the data around each means for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#center data on mean\n",
    "cut_movies_indian.loc[:,'centeredRating']=cut_movies_indian['averageRating'].copy()-np.mean(cut_movies_indian['averageRating'])\n",
    "cut_movies_american.loc[:,'centeredRating']=cut_movies_american['averageRating'].copy()-np.mean(cut_movies_american['averageRating'])\n",
    "print('Centered average rating of indian movies : %.3f \\tCentered average rating of american movies : %.3f' %\n",
    "(np.mean(cut_movies_indian['centeredRating']), np.mean(cut_movies_american['centeredRating'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_indian = cut_movies_indian.copy()\n",
    "#remove films without genre\n",
    "genre_indian = genre_indian.query(\"movie_genres != ''\")\n",
    "\n",
    "genre_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all genres and count each genre number of apparation\n",
    "all_genres_listed_indian = genre_indian['movie_genres'].str.split(pat=\",\")\n",
    "\n",
    "ls = []\n",
    "for i in all_genres_listed_indian:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_genres_indian = pd.Series(ls)\n",
    "all_genres_indian = all_genres_indian.str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the first 50 genres\n",
    "first_genres_indian = all_genres_indian[:50]\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(y = first_genres_indian.index, x = first_genres_indian).set_title('Movie genres apparition in indian movies')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_american = cut_movies_american.copy()\n",
    "\n",
    "#remove films without genre\n",
    "genre_american = genre_american.query(\"movie_genres != ''\")\n",
    "genre_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all genres and count each genre number of apparation\n",
    "all_genres_listed_american = genre_american['movie_genres'].str.split(pat=\",\")\n",
    "\n",
    "ls = []\n",
    "for i in all_genres_listed_american:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_genres_american = pd.Series(ls)\n",
    "all_genres_american = all_genres_american.str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the first 50 genres\n",
    "first_genres_american = all_genres_american[:50]\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(y = first_genres_american.index, x = first_genres_american).set_title('Movie genres apparition in American movies')\n",
    "sns.despine(left=True, bottom=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare them with each other, we calculate the frequency of movie genre in each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate frequencies of movie genre in each production\n",
    "all_genres_american_frequency = all_genres_american/len(cut_movies_american)\n",
    "first_genres_american_frequency = all_genres_american_frequency[:50]\n",
    "all_genres_indian_frequency = all_genres_indian/len(cut_movies_indian)\n",
    "first_genres_indian_frequency = all_genres_indian_frequency[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the first 50 genres\n",
    "fig, ax = plt.subplots(1,2,figsize=(10, 10),sharex = True, constrained_layout=True)\n",
    "fig.suptitle('Movie genres frequency in american and indian films')\n",
    "ax[0].set_title('America')\n",
    "ax[1].set_title('India')\n",
    "\n",
    "sns.barplot(ax = ax[0],y = first_genres_american_frequency.index, x = first_genres_american_frequency, label=\"American\", color=\"b\")\n",
    "sns.barplot(ax = ax[1], y = first_genres_indian_frequency.index, x = first_genres_indian_frequency, label=\"Indian\", color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Indian movies have a total of %d different movies genres and american have %d\" %(len(all_genres_indian.index), len(all_genres_american.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the plots show, \"drama\" is the prominent movie genre in both american and indian movies. However, american movies seems to have a better distribution of different genres than indian that are clearly more focused around \"drama\".\n",
    "\n",
    "Furthermore, both of them have a large number of different movie genres which can make the analysis difficult. Moreover, genres like \"silent film\" or \"world cinema\" are not specific theme to categorize the movies. In the other hand, it seems that some genres are similar to each other or some of them include other genres (e.g. \"action/aventure\" can include \"aventure\"). In conclusion, for further analysis, it could be interesting to select a restricted group of movie genres that allows better and more precises results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Languagues in Indian movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_languages= cut_movies_indian.copy()\n",
    "\n",
    "#remove the films without any languages\n",
    "indian_languages = indian_languages.query(\"movie_languages != ''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list with all languages\n",
    "all_languages_listed_indian = indian_languages['movie_languages'].str.split(pat=\",\")\n",
    "\n",
    "#Drop the NAs\n",
    "all_languages_listed_indian = all_languages_listed_indian.dropna()\n",
    "\n",
    "#Create a list with all the languages in it\n",
    "ls = []\n",
    "for i in all_languages_listed_indian:\n",
    "    ls.extend(i)\n",
    " \n",
    "#Count the total number of languages that are in the movies for each one of the languages\n",
    "all_languages_indian = pd.Series(ls)\n",
    "\n",
    "#Strip the strings and count the numbers of occurence of each languages\n",
    "all_languages_indian = all_languages_indian.str.strip().value_counts()\n",
    "\n",
    "all_languages_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_languages_indian_code = all_languages_indian.copy()\n",
    "\n",
    "#Put it as data frame\n",
    "all_languages_indian_code= pd.DataFrame(all_languages_indian_code)\n",
    "\n",
    "#Reset the index to have the index as column\n",
    "all_languages_indian_code = all_languages_indian_code.reset_index()\n",
    "\n",
    "#Rename the columns correctly\n",
    "all_languages_indian_code = all_languages_indian_code.rename(columns={\"index\": \"languages\", 0:\"count\"})\n",
    "\n",
    "#Only take the top 20 languages to plot it \n",
    "top_20_ind = all_languages_indian_code.iloc[:20]\n",
    "\n",
    "top_20_ind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting top 20 languages (39 in total for indian languages)\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(data = top_20_ind,y = 'languages', x = 'count').set_title('Languages apparition in Indian movies')\n",
    "ax.set_xscale('log')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Languagues in American movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_languages = cut_movies_american.copy()\n",
    "\n",
    "#Remove films without languages\n",
    "american_languages = american_languages.query(\"movie_languages != ''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list with all languages\n",
    "all_languages_listed_american = american_languages['movie_languages'].str.split(pat=\",\")\n",
    "\n",
    "#Drop the NAs\n",
    "all_languages_listed_american = all_languages_listed_american.dropna()\n",
    "\n",
    "#Create a list with all the languages in it\n",
    "ls = []\n",
    "for i in all_languages_listed_american:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_languages_american = pd.Series(ls)\n",
    "\n",
    "#Count the total number of languages that are in the movies for each one of the languages\n",
    "all_languages_american = all_languages_american.str.strip().value_counts()\n",
    "\n",
    "all_languages_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_languages_american_code =  all_languages_american.copy()\n",
    "\n",
    "#Put it as data frame\n",
    "all_languages_american_code = pd.DataFrame(all_languages_american_code)\n",
    "\n",
    "#Reset the index to have the index as column\n",
    "all_languages_american_code = all_languages_american_code.reset_index()\n",
    "\n",
    "#Rename the columns correctly\n",
    "all_languages_american_code = all_languages_american_code.rename(columns={\"index\": \"languages\", 0:\"count\"})\n",
    "\n",
    "#Only take the top 20 languages to plot it \n",
    "top_20_american = all_languages_american_code.iloc[:20]\n",
    "\n",
    "top_20_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting top 20 languages (111 in total for American movies)\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(data = top_20_american, y = 'languages', x = 'count').set_title('Languages apparition in American movies')\n",
    "ax.set_xscale('log')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the frequency of top 20 for the American and Indian languages\n",
    "all_languages_american_code['frequency'] = all_languages_american_code['count'] / all_languages_american_code['count'].sum()\n",
    "first_languages_american_frequency = all_languages_american_code[:20]\n",
    "\n",
    "all_languages_indian_code['frequency'] = all_languages_indian_code['count']/all_languages_indian_code['count'].sum()\n",
    "first_languages_indian_frequency = all_languages_indian_code[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting taking the first 20 languages for American films and Indian movies\n",
    "fig, ax = plt.subplots(1,2,figsize=(10, 10),sharex = True, constrained_layout=True)\n",
    "fig.suptitle('Top 20 movie languages frequency in American and Indian movies')\n",
    "ax[0].set_title('American movies')\n",
    "ax[1].set_title('Indian movies')\n",
    "\n",
    "sns.barplot(ax = ax[0],data = first_languages_american_frequency, y = 'languages', x = 'frequency', label=\"American\", color=\"b\")\n",
    "\n",
    "sns.barplot(ax = ax[1], data = first_languages_indian_frequency, y = 'languages', x = 'frequency', label=\"Indian\", color=\"r\")\n",
    "\n",
    "#Setting logarithmic scale \n",
    "ax[0].set_xscale('log')\n",
    "ax[1].set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many languages per movies there are, on average ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the number of ':' that represent the number of languages there are in each row for American movies\n",
    "american_languages['n_languages'] = american_languages.movie_languages.str.count(',')\n",
    "\n",
    "#Compute the number of ':' that represent the number of languages there are in each row for Indian movies\n",
    "indian_languages['n_languages'] = indian_languages.movie_languages.str.count(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the movies that do not have any languages\n",
    "n_indian_lan = indian_languages['n_languages'].dropna()\n",
    "\n",
    "n_american_lan = american_languages['n_languages'].dropna()\n",
    "\n",
    "#Compute the t-test to compare the number of available languages per movies for Indian and American movies\n",
    "t_test_languages = st.ttest_ind(n_indian_lan, n_american_lan)\n",
    "\n",
    "print('p-value for languages: ',t_test_languages.pvalue, '\\t', 'p-value is smaller than 0.05: ', t_test_languages.pvalue <0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant difference of the numbers of languages spoken in American vs Indian movies, so it could be that there are underlying effects, like Hollywood are more exported abroad than Bollywood movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the dataset in two\n",
    "# all_american_actors can contain duplicate actors, it deals with the films \n",
    "# and who plays in it, the age they have when the film is produced\n",
    "#\n",
    "# all_indian_actors contains data about individual actors, it doesn't contain duplicates\n",
    "\n",
    "all_american_actors = characters_data[characters_data['wikipedia_movie_id'].isin(cut_movies_american['wikipedia_movie_id'])]\n",
    "all_indian_actors = characters_data[characters_data['wikipedia_movie_id'].isin(cut_movies_indian['wikipedia_movie_id'])]\n",
    "\n",
    "unique_american_actor = all_american_actors.drop_duplicates('actor_name')\n",
    "unique_indian_actor = all_indian_actors.drop_duplicates('actor_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add a column indicating the country the actor/actress works in before concatenating the datasets\n",
    "unique_american_actor = unique_american_actor.assign(country = np.full(len(unique_american_actor), 'USA'))\n",
    "unique_indian_actor = unique_indian_actor.assign(country = np.full(len(unique_indian_actor), 'India'))\n",
    "\n",
    "all_american_actors = all_american_actors.assign(country = np.full(len(all_american_actors), 'USA'))\n",
    "all_indian_actors = all_indian_actors.assign(country = np.full(len(all_indian_actors), 'India'))\n",
    "\n",
    "\n",
    "#unique_indian_actor['country'] = np.full(len(unique_indian_actor), 'India')\n",
    "\n",
    "# We make sure to only keep actors with positive age to get rid of the errors \n",
    "all_american_actors = all_american_actors[all_american_actors['actor_age_at_movie_release'] > 0.]\n",
    "all_indian_actors = all_indian_actors[all_indian_actors['actor_age_at_movie_release'] > 0.]\n",
    "\n",
    "feature_list_all_actors = ['actor_gender', 'actor_age_at_movie_release', 'country']\n",
    "all_actors_merged = pd.concat([all_american_actors[feature_list_all_actors], all_indian_actors[feature_list_all_actors]], axis = 0)\n",
    "\n",
    "feature_list_unique_actors = ['actor_name', 'actor_gender', 'actor_ethnicity', 'country']\n",
    "unique_actors_merged = pd.concat([unique_american_actor[feature_list_unique_actors], unique_indian_actor[feature_list_unique_actors]], axis = 0)\n",
    "\n",
    "# Adding a column to the dataset of the features of single actors for the number of films in our dataset they appear in\n",
    "dict_number_of_film = characters_data['actor_name'].value_counts().to_dict()\n",
    "unique_actors_merged['number_of_films'] = unique_actors_merged['actor_name'].map(dict_number_of_film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actors_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_actors_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do analysis on age, it makes sense to count the same actors multiple times as they play in different films, we will thus not drop the duplicates for this part of the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_american_actors.actor_age_at_movie_release.describe())\n",
    "print(all_indian_actors.actor_age_at_movie_release.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mean age is similar in both cases, as well as the standard deviation. Looking at the different quartiles we cannot see significant distribution difference between the two groups. \n",
    "\n",
    "We can note, however, that we have significantly more available ages available for actors in american films as for actors in indian films (137'073 versus 31'201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_ind(all_american_actors.actor_age_at_movie_release, all_indian_actors.actor_age_at_movie_release, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reject the null hypothesis, that is, that the mean actor age from american and indian movies are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = all_american_actors['actor_age_at_movie_release'], stat = 'density', discrete=True, color = 'blue', kde=True)\n",
    "sns.histplot(data = all_indian_actors['actor_age_at_movie_release'], stat = 'density',discrete=True, color='red', kde=True)\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.xlabel('Actor age')\n",
    "plt.title('Distribution of actor age in indian and american movies')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be more teenagers cast in american films, this can be due to the popularity of 'teen movies' in the western world, but is more likely to be simply due to a bias in quantity of information about american movies. The wikipedia pages of american movies might be more detailed about american films, containing even information about characters that may have relatively low screen time, like the daughter of a secondary character etc..\n",
    "\n",
    "Otherwise the distributions seem similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We separate the datasets containing all actors by gender\n",
    "# For american films\n",
    "american_film_female = all_american_actors[all_american_actors['actor_gender'] == 'F']\n",
    "american_film_male = all_american_actors[all_american_actors['actor_gender'] == 'M']\n",
    "\n",
    "# And for indian films\n",
    "indian_film_female = all_indian_actors[all_indian_actors['actor_gender'] == 'F']\n",
    "indian_film_male = all_indian_actors[all_indian_actors['actor_gender'] == 'M']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of american film actors we have the gender of is {0}, of which {1:.0%} are female'.format(\n",
    "    len(american_film_male) + len(american_film_female), len(american_film_female)/(len(american_film_male) + len(american_film_female))))\n",
    "\n",
    "print('Number of indian film actors we have the gender of is {0}, of which {1:.0%} are female'.format(\n",
    "    len(indian_film_male) + len(indian_film_female), len(indian_film_female)/(len(indian_film_male) + len(indian_film_female))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.suptitle('Comparaison of actor gender and age in American and Indian films', size = 'xx-large')\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "sns.histplot(data = all_american_actors, x = 'actor_age_at_movie_release', hue = 'actor_gender', stat = 'density', discrete=True, kde=True)\n",
    "plt.xlabel('Actor/actress age')\n",
    "plt.title('Distribution of american film actor age with respect to gender')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.histplot(data = all_indian_actors, x = 'actor_age_at_movie_release', hue = 'actor_gender', stat = 'density', discrete=True, kde=True)\n",
    "\n",
    "plt.xlabel('Actor/actress age')\n",
    "plt.title('Distribution of indian film actor age with respect to gender')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.histplot(data = all_american_actors[all_american_actors['actor_gender'] == 'F'], x = 'actor_age_at_movie_release', stat = 'density', discrete=True, color='orange', kde=True)\n",
    "sns.histplot(data = all_indian_actors[all_indian_actors['actor_gender'] == 'F'], x = 'actor_age_at_movie_release', stat = 'density', discrete=True, kde=True)\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.title('Distribution of actress age, differenciated by country')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "sns.histplot(data = all_american_actors[all_american_actors['actor_gender'] == 'M'], x = 'actor_age_at_movie_release', stat = 'density', discrete=True, color='orange', kde=True)\n",
    "sns.histplot(data = all_indian_actors[all_indian_actors['actor_gender'] == 'M'], x = 'actor_age_at_movie_release', stat = 'density', discrete=True, kde=True)\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.title('Distribution of actor age, differenciated by country')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the same phenomenon using boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = all_actors_merged, y = 'actor_age_at_movie_release', x = 'country', hue= 'actor_gender')\n",
    "plt.title('Other visualization of the differences in age distribution by gender and country of movie production')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are very little differences between the distributions of actor age between the two movie industries, but a big difference between the distribution of actresses' age. We can see that in indian movies there is a big density peak in the low twenties and a rapid decline from the thirties onward. \n",
    "\n",
    "This difference is very stark and should be investigated further in the rest of our analysis, regarding time-wise changes and the prediction of movie success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the significance of the difference between the mean age of actors and actresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st.ttest_ind(all_american_actors.loc[all_american_actors.actor_gender == 'F']['actor_age_at_movie_release'],all_american_actors.loc[all_american_actors.actor_gender == 'M']['actor_age_at_movie_release']))\n",
    "print(st.ttest_ind(all_indian_actors.loc[all_indian_actors.actor_gender == 'F']['actor_age_at_movie_release'],all_indian_actors.loc[all_indian_actors.actor_gender == 'M']['actor_age_at_movie_release']))\n",
    "print(st.ttest_ind(all_american_actors.loc[all_american_actors.actor_gender == 'F']['actor_age_at_movie_release'],all_indian_actors.loc[all_indian_actors.actor_gender == 'F']['actor_age_at_movie_release']))\n",
    "print(st.ttest_ind(all_american_actors.loc[all_american_actors.actor_gender == 'M']['actor_age_at_movie_release'],all_indian_actors.loc[all_indian_actors.actor_gender == 'M']['actor_age_at_movie_release']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All null hypotheses can be rejected at the alpha = 0.05 level, although the effects might mainly be driven by sample size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_data = unique_actors_merged.groupby(['actor_ethnicity', 'country'], as_index=False)['actor_name'].agg({'count'})\n",
    "ethnicity_data = pd.DataFrame(ethnicity_data.to_records())\n",
    "ethnicity_data = ethnicity_data.set_index('actor_ethnicity')\n",
    "\n",
    "#separate the dataset per country\n",
    "ethnicity_data_india = ethnicity_data[ethnicity_data['country'] == 'India']\n",
    "ethnicity_data_usa = ethnicity_data[ethnicity_data['country'] == 'USA']\n",
    "\n",
    "# converting count into density\n",
    "ethnicity_data_india['count'] = ethnicity_data_india.loc[:,'count'].div(len(ethnicity_data_india)).copy(deep=True)\n",
    "ethnicity_data_usa['count'] = ethnicity_data_usa.loc[:,'count'].div(len(ethnicity_data_usa)).copy(deep=True)\n",
    "\n",
    "ethnicity_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,80))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Ethnicity of actors ranked per frequency for movies produced in India')\n",
    "sns.barplot(data = ethnicity_data_india, y = ethnicity_data_india.index,  x = 'count', orient='h', order=ethnicity_data_india.sort_values(by = 'count', ascending=False).index)\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('Density')\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Ethnicity of actors ranked per frequency for movies produced in the USA')\n",
    "sns.barplot(data = ethnicity_data_usa, y = ethnicity_data_usa.index,  x = 'count', orient='h', order=ethnicity_data_usa.sort_values(by = 'count', ascending=False).index)\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, most ethnicities represented in the american films are descendent of immigrants, and most ethnicities represented in indian films are indian or more generally south-Asian. Also unsurprisingly, There are a lot more different ethnicities represented in films produced in the US compared to films produced in India. This might be due to the US being a more cosmopolite country, and to the difference in amout of information we have in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try investigate further the differences in representations in the industies, looking at the ethnicities represented in both industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative values represent ethnicities more represented in the indian film industry, and vice versa\n",
    "compared_ethnicities = (ethnicity_data_usa['count'] - ethnicity_data_india['count']).dropna()\n",
    "\n",
    "plt.title('Relative difference in proportion of ethnicities between indian and american films')\n",
    "sns.barplot(y = compared_ethnicities.index,  x = compared_ethnicities.values, orient='h', order=compared_ethnicities.sort_values(ascending=False).index)\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('Relative density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of indian film actors we have every features for:', unique_actors_merged[unique_actors_merged['country'] == 'India'].dropna().shape[0])\n",
    "print('Number of american film actors we have every features for:', unique_actors_merged[unique_actors_merged['country'] == 'USA'].dropna().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of indian film actors we have everything but ethnicity for:', unique_actors_merged[unique_actors_merged['country'] == 'India']['actor_gender'].shape[0])\n",
    "print('Number of american film actors we have everything but ethnicity for:', unique_actors_merged[unique_actors_merged['country'] == 'USA']['actor_gender'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we consider only actors where we have all the available informations (gender, country the actors plays in, and ethnicity) we only get 354 indian film actors and 1967 american film actors. This is not enough to perform an analysis through time while taking into account actor ethnicity.\n",
    "\n",
    "On the other hand, we have substantially more data on gender so taking it into account could be interesting for time-wise analysis for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In how many films an actor played in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.suptitle('Number of films an actor plays in', size = 'xx-large')\n",
    "plt.subplot(2,2,1)\n",
    "sns.histplot(data = unique_actors_merged[unique_actors_merged['country'] == 'India'], bins = np.logspace(0,2, 10), x = 'number_of_films', hue = 'actor_gender', kde = True, stat = 'density').set(xscale=\"log\")\n",
    "plt.title('Number of films per actor in indian movies, differenciated by gender')\n",
    "plt.subplot(2,2,2)\n",
    "sns.histplot(data = unique_actors_merged[unique_actors_merged['country'] == 'USA'], bins = np.logspace(0,2, 10), x = 'number_of_films', hue = 'actor_gender', kde = True, stat = 'density').set(xscale=\"log\")\n",
    "plt.title('Number of films per actor in american movies, differenciated by gender')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.barplot(data = unique_actors_merged, y = 'number_of_films', x = 'country', hue= 'actor_gender')\n",
    "plt.title('Resume of the differences in film numbers between countries, differentiated by gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the number of actors/actresses\n",
    "unique_actors_merged[unique_actors_merged['number_of_films'] > 100].groupby(['country', 'actor_gender']).agg({'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably have a bias in our dataset in the quantity of information we have in our dataset regarding the american films. We are far more likely to have the names of actors that make a single brief aparition in an american film. However regarding the other extreme, we can see that there a lot more ultra-prolific indian film actors than american film actors.\n",
    "\n",
    "In both film industries we see however that most of the hyper-prolific actors are males, which is probably linked to the difference in carreer prospects with age.\n",
    "\n",
    "This is once again a angle that could be included in further analysis regarding trends through time and film succes (ratings) prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics analysis in summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we split our data in indian and american dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_indian = summaries[summaries['wikipedia_movie_id'].isin(cut_movies_indian['wikipedia_movie_id'])]\n",
    "summaries_indian = summaries_indian.reset_index(drop = True)\n",
    "summaries_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_american = summaries[summaries['wikipedia_movie_id'].isin(cut_movies_american['wikipedia_movie_id'])]\n",
    "summaries_american = summaries_american.reset_index(drop = True)\n",
    "summaries_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_topic = pd.concat([summaries_indian, summaries_american], ignore_index=True)\n",
    "\n",
    "summaries_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Topic Detection Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modelling is used to extract topics from a collection of documents, in our case summaries of movies.\n",
    "Topics are fundamentally a cluster of similar words. This help in the understanding of hidden semantic structure between words of a large number of the extensive texts, at an aggregate level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each NLP task requires some sort of data pre-processing to make data eligible for modeling. We will perform the following steps:\n",
    "\n",
    "- Removing punctuation\n",
    "- Tokenization: Splitting sentences into word-sized chunks, called tokens.\n",
    "- Stopwords removal: Stopwords are English words that dont add any value to the analysis. Removing them will help the model to find patterns more easily.\n",
    "- First names removal : since we want the topics of the movies, including the names of the character did not make sense to analyze the topics for our context of analysis. We decided to removed them.\n",
    "- Words with fewer than three letters are removed.\n",
    "- Lemmatization: Converting words to their base using morphological analysis.\n",
    "- Make bigrams: a bigram is a sequence of two adjacent elements from a string that combines to generate a more understandable form (e.g., [data , science] => [data science]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in python console\n",
    "import nltk; nltk.download('stopwords')\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#Remove commom names from the summaries (list of 18'000 names)\n",
    "names = pd.read_csv(data_folder + 'names.csv')\n",
    "\n",
    "#Save the names as dataframe\n",
    "names = pd.DataFrame(names)\n",
    "\n",
    "#Casefold the names\n",
    "names['names'] = names['names'].str.lower().astype('str')\n",
    "\n",
    "#Append some list of names that we saw in the movies summaries to make sure they are in the list\n",
    "list_names = {'names':['alex', 'bobby', 'jake', 'timmy', 'danny', 'nick', 'anna', 'benny', 'maggie', 'reggie', 'nicky', 'vincent', 'johnny', 'grace']}\n",
    "\n",
    "names = names.append(pd.DataFrame(list_names))\n",
    "\n",
    "#Append the stop words in the list of names, consider them as \"stopwords\" to be removed from the summaries\n",
    "stop = list(np.append(names['names'].values, ['from', 'subject', 're', 'edu', 'use']))\n",
    "\n",
    "#Finally, extend the stop_words from nltk with our customized stop list\n",
    "stop_words.extend(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare function that preprocess the sentences of the summaries (removing punctuations, transforming into lowercase tokens)\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform into lowercase tokens and removing punctuations\n",
    "summaries_words = list(sent_to_words(summaries_topic['summaries']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then decide to build and use bigrams to pursue our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram model\n",
    "bigram = gensim.models.Phrases(summaries_words, min_count=15, threshold=100) # higher threshold fewer phrases.\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams and lemmatization\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "#Remove the stopwords in the summaries data\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "#Make the bigrams out of the summaries data\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "#Lemmatize the summaries keeping only nouns, ajdectives, verbs and adverbs (ref: https://spacy.io/api/annotation)\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags and len(token)>3])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stopwords and first names\n",
    "summaries_words_no_stopwords = remove_stopwords(summaries_words)\n",
    "\n",
    "# Form bigrams\n",
    "summaries_words_bigrams = make_bigrams(summaries_words_no_stopwords)\n",
    "\n",
    "# Perform the lemmatization keeping only nouns, ajdectives, verbs and adverbs \n",
    "summaries_words_lemmatized = lemmatization(summaries_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pre-processing the summaries, let us create the dictionnary, the corpus and the term document frequency for the subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary\n",
    "id2word = corpora.Dictionary(summaries_words_lemmatized)\n",
    "\n",
    "# Remove rare and common tokens\n",
    "\n",
    "# Tokens are kept if they are contained in at least 15 documents \n",
    "min_wordcount = 15\n",
    "\n",
    "# Tokens are kept if they are containted in no more than 30 % of the documents \n",
    "max_freq = 0.3\n",
    "\n",
    "# Filter these extremes accordingly\n",
    "id2word.filter_extremes(no_below=min_wordcount, no_above=max_freq)\n",
    "\n",
    "# Create the corpus, using the bag-of-words (BoW) format: list of (token_id, token_count) tuples.\n",
    "texts = summaries_words_lemmatized\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to choose the number of topics ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize a function that computes coherences values based on several number of topics, so we can chose the optimal number of topics based on the best coherence value.\n",
    "\n",
    "The parameters of the function are : \n",
    "- dictionary : Gensim dictionary \n",
    "- corpus : Gensim corpus\n",
    "- texts : List of input texts\n",
    "- limit : Max num of topics\n",
    "- start : number of initial topics\n",
    "- step : number of step for the next topic\n",
    "\n",
    "The function returns :\n",
    "- model_list : the list of LDA topic models\n",
    "- coherence_values : the coherence value corresponding to the LDA model with its respective number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel # spaCy for preprocessing\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=2):\n",
    "    #Initialize seed\n",
    "    seed = 80699\n",
    "    #Initialize dict\n",
    "    base_models = dict()\n",
    "    #Initialize coherence values and model list \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    #Compute the LDA model for each num_topics in the start, limit, step range\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics, random_state=seed)\n",
    "        #Append the model to the list of models\n",
    "        model_list.append(model)\n",
    "        #Compute the coherence\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        #Append the coherence value\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us then use it with the number of topics going from 2 to 20, with a step of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary = id2word, corpus = corpus, texts = texts, start=2, limit=20, step=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot each coherence value for each model of LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=20; start=2; step=2\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics for American and Indian Films\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coherence score seems optimal for 10 topics number, we therefore chose this as the optimal LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[5]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the topics using plDAvis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "data = pyLDAvis.gensim_models.prepare(topic_model = optimal_model, corpus = corpus, dictionary = id2word, sort_topics = False)\n",
    "pyLDAvis.display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation and explanation of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic Bubble:**\n",
    "\n",
    "- The representation includes topics distribution in the 2-dimensional space (left side panel). These topics are represented in the form of bubbles.\n",
    "\n",
    "- The larger the bubble, the more frequent is the topic in the documents.\n",
    "\n",
    "- Since we have a low number of topics (10), we have big non-overlapping bubbles, scattered throughout the chart.\n",
    "\n",
    "- The distance between the topics is an approximation of the semantic relationship between these latter.\n",
    "\n",
    "- The topics that share common words will be overlapping in comparison to the non-overlapping topics.\n",
    "\n",
    "**Horizontal Bar Graph:**\n",
    "\n",
    "- The bar graph shows the frequency distribution of the words in the documents (in blue color).\n",
    "\n",
    "- The red area describes the frequency of each word given a topic.\n",
    "\n",
    "- When selecting a topic (clicking on a topic bubble), the top 30 most relevant term for the topic are shown.\n",
    "\n",
    "- Hovering over the specific words (in the right panel), the bubbles containing the words grows bigger or smaller if they also have it. The size of the bubble in this scenario describes the weightage of the word on that topic. The higher the weight of the selected word, the larger will be the size of the bubble.\n",
    "\n",
    "**Relevance Metric:**\n",
    "\n",
    "- Rank words in topics based on their frequency by varying the relevance metric lambda parameter (top right slide bar), that goes from 0 to 1.\n",
    "\n",
    "- Decreasing the lambda parameter means increasing the weight of the ratio (Frequency of word given the topic / Overall frequency of the word in the documents). Decreasing the lambda parameters gives words that are more specific to the topic. Important words for the given topic then moves upward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the plot to put it in the website\n",
    "pyLDAvis.save_html(data, 'lda.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare our features, let us group each summaries (doc) with its respective percentage of contribution to each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=optimal_model, corpus=corpus):\n",
    "    # Initialize the output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get the number of topic, percentage of contribution and number the document for each summaries (document)\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            \n",
    "            # Here we append topic_num + 1 to number to match each topics accordingly to pLDAvis' graph\n",
    "            sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num+1), round(prop_topic,6), int(i)]), ignore_index=True)\n",
    "\n",
    "    sent_topics_df.columns = ['num_topic', 'topic_perc_contrib','num_document']\n",
    "\n",
    "    return(sent_topics_df)\n",
    "\n",
    "sent_topics_df = format_topics_sentences(ldamodel=optimal_model, corpus=corpus)\n",
    "\n",
    "# Show the documents and their topic contribution\n",
    "sent_topics_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then pivot the precedent data frame to have each columns as a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = sent_topics_df.copy()\n",
    "\n",
    "# Pivot the data frame\n",
    "df_topics = df_topics.pivot(index = 'num_document', columns='num_topic', values='topic_perc_contrib')\n",
    "\n",
    "# Replace every nan to 0 to interpret this a zero contribution to the topic\n",
    "df_topics = df_topics.replace(np.nan, 0)\n",
    "\n",
    "# Finally, join with the summaries to have the wikipedia id and the original text of the summaries\n",
    "df_topics = df_topics.join(summaries_topic)\n",
    "\n",
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us identify the topics and label them. To do that, we have observed every topic bubble and identified the keywords that made the most sense to describe the topic.\n",
    "\n",
    "This enable us to label in a specific manner each topic and not to give a general genre, since we already have that in our features. It was difficult to pinpoint a specific theme since movies' stories can be very broad and unique, so we decided to chose the keywords as the most relevant terms to describe the topics.\n",
    "\n",
    "We therefore came up with a small description for each topics:\n",
    "\n",
    "- Topic 1: We chose \"experiment_scientist_power_creature\" as relevant keywords. \n",
    "\n",
    "- Topic 2: We chose \"body_vampire_child_night\" as the relevant keywords. \n",
    "\n",
    "- Topic 3: \"money_steal_prisoner_bank_drug\" made the most sense to depicts the topic. \n",
    "\n",
    "- Topic 4: \"team_game_coach_player\" were the most sense-making keywords chosen for this topic. \n",
    "\n",
    "- Topic 5: The keywords \"ship_alien_earth_attack\" are also pretty straighforwards to draw an idea of the topic. It seems more revolved into fantasy sci-fi movies, probabily involving space adventures, involving also conflict and violence (keywords slave, use, destroy, escape, attack).\n",
    "\n",
    "- Topic 6: \"murder_police_gang_fight_crime\".It is also pretty straightforward that the subject is about criminality (keywords murder, crime, drug, gang) and the investigation story that follows. The consequences of the crime are also present: guilty going to prison for his/her acts (keywords prison, officer, guard, release) and possibly trying to escape (keywords plan, escape). \n",
    "\n",
    "- Topic 7: We chose \"agent_shoot_military_bomb\" as relevant keywords to depict the topic. \n",
    "\n",
    "- Topic 8: \"band_family_show_music_dream\" keywords seems describe a school or college environment, with the relationships and stories that grow within. The family seems to be very represented (keywords brother, family, sister, mother, daughter, husband, child, parent). \n",
    "\n",
    "- Topic 9: \"family_father_mother_daughter_wedding\" keywords.\n",
    "\n",
    "- Topic 10 : \"home_school_night_parent_party_decide\" were the keywords that we chose to describe this topic.\n",
    "\n",
    "- Topic 11: \"escape_camp_attack_truck\"\n",
    "\n",
    "- Topic 12 : \"movie_woman_play_character_role\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label each topics accordingly\n",
    "df_topics.columns = ['experiment_scientist_power_creature', 'body_vampire_child_night', 'money_steal_prisoner_bank_drug', 'team_game_coach_player', 'ship_alien_earth_attack', 'murder_police_gang_fight_crime', 'agent_shoot_military_bomb', 'band_family_show_music_dream', 'family_father_mother_daughter_wedding', 'home_school_night_parent_party_decide', 'escape_camp_attack_truck', 'movie_woman_play_character_role', 'wikipedia_movie_id', 'summaries']\n",
    "\n",
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_indian_actors = pd.DataFrame({'wikipedia_movie_id':[]})\n",
    "df_features_american_actors = pd.DataFrame({'wikipedia_movie_id':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ids of the movies from the summaries\n",
    "df_features_indian_actors['wikipedia_movie_id']=cut_movies_indian['wikipedia_movie_id']\n",
    "df_features_american_actors['wikipedia_movie_id']=cut_movies_american['wikipedia_movie_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the mean age per gender for indian and american films\n",
    "mean_male_actor_age_india = indian_film_male.groupby('wikipedia_movie_id', as_index=False)['actor_age_at_movie_release'].agg({'mean_male_actor_age': np.mean})\n",
    "mean_female_actor_age_india = indian_film_female.groupby('wikipedia_movie_id', as_index=False)['actor_age_at_movie_release'].agg({'mean_female_actor_age': np.mean})\n",
    "\n",
    "mean_male_actor_age_america = american_film_male.groupby('wikipedia_movie_id', as_index=False)['actor_age_at_movie_release'].agg({'mean_male_actor_age': np.mean})\n",
    "mean_female_actor_age_america = american_film_female.groupby('wikipedia_movie_id', as_index=False)['actor_age_at_movie_release'].agg({'mean_female_actor_age': np.mean})\n",
    "\n",
    "\n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, mean_male_actor_age_india, on = 'wikipedia_movie_id', how = 'left') \n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, mean_female_actor_age_india, on = 'wikipedia_movie_id', how = 'left')\n",
    "\n",
    "df_features_american_actors = pd.merge(df_features_american_actors, mean_male_actor_age_america, on = 'wikipedia_movie_id', how = 'left')\n",
    "df_features_american_actors = pd.merge(df_features_american_actors, mean_female_actor_age_america, on = 'wikipedia_movie_id', how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the number of films an actor played in with the rest of the film data\n",
    "all_american_actors_ext = all_american_actors.merge(all_american_actors.actor_name.value_counts().reset_index(), left_on = 'actor_name', right_on = 'index', how = 'left')\n",
    "all_american_actors_ext = all_american_actors_ext.groupby('wikipedia_movie_id', as_index=False)['actor_name_y'].agg({'average_number_of_films_actors_played_in': np.mean})\n",
    "\n",
    "all_indian_actors_ext = all_indian_actors.merge(all_indian_actors.actor_name.value_counts().reset_index(), left_on = 'actor_name', right_on = 'index', how = 'left')\n",
    "all_indian_actors_ext = all_indian_actors_ext.groupby('wikipedia_movie_id', as_index=False)['actor_name_y'].agg({'average_number_of_films_actors_played_in': np.mean})\n",
    "\n",
    "# merging with features\n",
    "df_features_american_actors = pd.merge(df_features_american_actors, all_american_actors_ext[['wikipedia_movie_id', 'average_number_of_films_actors_played_in']], on = 'wikipedia_movie_id', how = 'left')\n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, all_indian_actors_ext[['wikipedia_movie_id', 'average_number_of_films_actors_played_in']], on = 'wikipedia_movie_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the percent of actress in each movie\n",
    "def percent_female(x):\n",
    "    try:\n",
    "        return x.value_counts().to_dict()['F']/len(x)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "percent_female_american_films = all_american_actors.groupby('wikipedia_movie_id', as_index=False)['actor_gender'].apply(percent_female)\n",
    "percent_female_american_films.rename(columns = {'actor_gender':'percent_female_cast'}, inplace = True)\n",
    "percent_female_indian_films = all_indian_actors.groupby('wikipedia_movie_id', as_index=False)['actor_gender'].apply(percent_female)\n",
    "percent_female_indian_films.rename(columns = {'actor_gender':'percent_female_cast'}, inplace = True)\n",
    "\n",
    "# merging with features\n",
    "df_features_american_actors = pd.merge(df_features_american_actors, percent_female_american_films, on = 'wikipedia_movie_id', how = 'left')\n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, percent_female_indian_films, on = 'wikipedia_movie_id', how = 'left')\n",
    "\n",
    "# drop the rows with no wikipedia_movie_id\n",
    "df_features_american_actors.dropna(subset = ['wikipedia_movie_id'], inplace = True)\n",
    "df_features_indian_actors.dropna(subset = ['wikipedia_movie_id'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Topic Detection Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_features_indian = df_topics.copy()\n",
    "\n",
    "topic_features_indian = df_topics[df_topics['wikipedia_movie_id'].isin(cut_movies_indian['wikipedia_movie_id'])]\n",
    "\n",
    "topic_features_indian = topic_features_indian.reset_index().drop(columns = ['summaries', 'num_document'])\n",
    "\n",
    "topic_features_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_features_american= df_topics.copy()\n",
    "\n",
    "topic_features_american = df_topics[df_topics['wikipedia_movie_id'].isin(cut_movies_american['wikipedia_movie_id'])]\n",
    "\n",
    "topic_features_american = topic_features_american.reset_index().drop(columns = ['summaries', 'num_document'])\n",
    "\n",
    "topic_features_american.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Anaylsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The mean length of american summaries is {1:.2f} words and for indian summaries it is {0:.2f} words.'.format(\n",
    "    np.mean([len(ele.split(' ')) for ele in summaries_indian['summaries']]),\n",
    "    np.mean([len(ele.split(' ')) for ele in summaries_american['summaries']])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can take up to 3min to run\n",
    "\n",
    "#defining analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#computing sentiments for each summary\n",
    "indian_sentiments = pd.DataFrame([analyzer.polarity_scores(summary) for summary in summaries_indian['summaries']])\n",
    "american_sentiments = pd.DataFrame([analyzer.polarity_scores(summary) for summary in summaries_american['summaries']])\n",
    "\n",
    "#adding wikipedia id for future merges\n",
    "indian_sentiments['wikipedia_movie_id']=summaries_indian['wikipedia_movie_id']\n",
    "american_sentiments['wikipedia_movie_id']=summaries_american['wikipedia_movie_id']\n",
    "indian_sentiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "sns.histplot(american_sentiments['compound'], alpha =.5, stat = 'density', bins = 10)\n",
    "sns.histplot(indian_sentiments['compound'], alpha=.5, color = 'orange', stat = 'density', bins = 10)\n",
    "plt.legend(labels=[\"American movies\",\"Indian movies\"])\n",
    "plt.xlabel('Movie sentiments\\nnegative value indicates negative sentiments ; positive value indicates positive sentiments')\n",
    "plt.title('Movie sentiments, differenciated by movie coutry')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indian = cut_movies_indian.copy()\n",
    "\n",
    "#remove films without genre\n",
    "test_indian = test_indian.query(\"movie_genres != ''\")\n",
    "\n",
    "test_indian.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all genres and count each genre number of apparation\n",
    "all_genres_listed_indian = test_indian['movie_genres'].str.split(pat=\",\")\n",
    "#passing by a list is faster for iteration\n",
    "ls = []\n",
    "for i in all_genres_listed_indian:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_genres_indian = pd.Series(ls)\n",
    "all_genres_indian = all_genres_indian.str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the first 50 genres\n",
    "first_genres_indian = all_genres_indian[:50]\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(y = first_genres_indian.index, x = first_genres_indian).set_title('Movie genres apparition in indian movies')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_american = cut_movies_american.copy()\n",
    "#remove films without genre\n",
    "test_american = test_american.query(\"movie_genres != ''\")\n",
    "test_american.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all genres and count each genre number of apparation\n",
    "all_genres_listed_american = test_american['movie_genres'].str.split(pat=\",\")\n",
    "\n",
    "ls = []\n",
    "for i in all_genres_listed_american:\n",
    "    ls.extend(i)\n",
    " \n",
    "all_genres_american = pd.Series(ls)\n",
    "all_genres_american = all_genres_american.str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the first 50 genres\n",
    "first_genres_american = all_genres_american[:50]\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(y = first_genres_american.index, x = first_genres_american).set_title('Movie genres apparition in American movies')\n",
    "sns.despine(left=True, bottom=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare them with each other, we calculate the frequency of movie genre in each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate frequencies of movie genre in each production\n",
    "all_genres_american_frequency = all_genres_american/len(test_american)\n",
    "first_genres_american_frequency = all_genres_american_frequency[:50]\n",
    "all_genres_indian_frequency = all_genres_indian/len(test_indian)\n",
    "first_genres_indian_frequency = all_genres_indian_frequency[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the first 50 genres\n",
    "fig, ax = plt.subplots(1,2,figsize=(10, 10),sharex = True, constrained_layout=True)\n",
    "fig.suptitle('Movie genres frequency in american and indian films')\n",
    "ax[0].set_title('America')\n",
    "ax[1].set_title('India')\n",
    "\n",
    "sns.barplot(ax = ax[0],y = first_genres_american_frequency.index, x = first_genres_american_frequency, label=\"American\", color=\"b\")\n",
    "sns.barplot(ax = ax[1], y = first_genres_indian_frequency.index, x = first_genres_indian_frequency, label=\"Indian\", color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''test_american['movie_genres'] = test_american['movie_genres'].replace('\"','', regex = True)\n",
    "test_american['movie_genres'] = test_american['movie_genres'].apply(lambda s: re.sub('\\B\\/\\w+', '',s))\n",
    "test_american['movie_genres'] = test_american['movie_genres'].apply(lambda s: re.sub('\\B\\/\\w+', '',s))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_american['movie_genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genre_imdb =  pd.Series(['action','adventure','animation','biography','comedy','crime','documentary','drama','family',\n",
    "                              'fantasy','noir','history', 'horror','musical','mystery','romance','sci fi','short Film',\n",
    "                              'sport','superhero','thriller','war','western'])\n",
    "#suppress punctuation and words that wont be taken as a genre and that are in high numbers\n",
    "nope_words = [',', 'film', 'bollywood', 'world', 'cinema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in nope_words:\n",
    "    test_indian['movie_genres'] = test_indian['movie_genres'].str.replace(char, '')\n",
    "    test_indian['movie_genres'] = test_indian['movie_genres'].str.replace('  ', ' ')\n",
    "    test_american['movie_genres'] = test_american['movie_genres'].str.replace(char, '')\n",
    "    test_american['movie_genres'] = test_american['movie_genres'].str.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dummies_indian = pd.DataFrame()\n",
    "for char in movie_genre_imdb:\n",
    "    genre_dummies_indian[char] = pd.Series(test_indian['movie_genres'].apply(lambda x: pd.Series(x).str.contains(char[:3]).any().astype('int')))\n",
    "    \n",
    "genre_dummies_american = pd.DataFrame()\n",
    "for char in movie_genre_imdb:\n",
    "    genre_dummies_american[char] = pd.Series(test_american['movie_genres'].apply(lambda x: pd.Series(x).str.contains(char[:3]).any().astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dummies_indian['wikipedia_movie_id'] = test_indian['wikipedia_movie_id']\n",
    "genre_dummies_american['wikipedia_movie_id'] = test_american['wikipedia_movie_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_american_actors = pd.merge(df_features_american_actors, american_sentiments[['wikipedia_movie_id', 'compound']], on = 'wikipedia_movie_id', how = 'left')\n",
    "df_features_indian_actors = pd.merge(df_features_indian_actors, indian_sentiments[['wikipedia_movie_id', 'compound']], on = 'wikipedia_movie_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian = pd.merge(genre_dummies_indian, df_features_indian_actors, on= 'wikipedia_movie_id', how = 'right')\n",
    "features_american = pd.merge(genre_dummies_american, df_features_american_actors, on= 'wikipedia_movie_id', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_indian = cut_movies_indian.dropna(subset = 'averageRating')[['wikipedia_movie_id', 'averageRating']]\n",
    "rating_american = cut_movies_american.dropna(subset = 'averageRating')[['wikipedia_movie_id', 'averageRating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian = pd.merge(features_indian, topic_features_indian, on= 'wikipedia_movie_id', how = 'left')\n",
    "features_american = pd.merge(features_american, topic_features_american, on= 'wikipedia_movie_id', how = 'left')\n",
    "features_indian = pd.merge(features_indian, rating_indian, on= 'wikipedia_movie_id', how = 'right')\n",
    "features_american = pd.merge(features_american, rating_american, on= 'wikipedia_movie_id', how = 'right')\n",
    "features_indian = pd.merge(features_indian, test_indian[['wikipedia_movie_id', 'movie_release_date']], on= 'wikipedia_movie_id', how = 'left')\n",
    "features_american = pd.merge(features_american, test_american[['wikipedia_movie_id', 'movie_release_date']], on= 'wikipedia_movie_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_indian.dropna(subset='experiment_scientist_power_creature', inplace = True)\n",
    "features_american.dropna(subset='experiment_scientist_power_creature', inplace = True)\n",
    "features_indian.iloc[:,0:23] = features_indian.iloc[:,0:23].fillna(0) ; features_indian.iloc[:,24:29] = features_indian.iloc[:,24:29].fillna(features_indian.iloc[:,24:29].mean())\n",
    "features_american.iloc[:,0:23] = features_american.iloc[:,0:23].fillna(0) ; features_american.iloc[:,24:29] = features_american.iloc[:,24:29].fillna(features_american.iloc[:,24:29].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "features_indian.to_csv('features_indian.csv', index = False)\n",
    "features_american.to_csv('features_american.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugo and Lucas Part"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87259b15c3afccf059722440ab90a1874d985996384e98fcc7aa5e93528035d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
